<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DyCon Blog</title>
    <description>Welcome to the web interface of DyCon Toolbox, the computational platform developed within the &lt;a href='https://cmc.deusto.eus/dycon/' target='_blank'&gt;ERC DyCon - Dynamic Control&lt;/a&gt; project.</description>
    <link>https://deustotech.github.io/DyCon-Blog/</link>
    <atom:link href="https://deustotech.github.io/DyCon-Blog/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 31 Mar 2020 22:42:55 +0200</pubDate>
    <lastBuildDate>Tue, 31 Mar 2020 22:42:55 +0200</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>Control of reaction-diffusion under state constraints - Barriers</title>
        <description>This tutorial is focused on the understanding of of the problem



The solutions for $a=0$ constitute an intrinsic obstruction to the controllability with state-constraints due to the comparison principle [1]. Indeed, for any control function $0\leq a(x,t)\leq 1$
the solution of the problem:



where $u$ is an elliptic nontrivial solution satisfies that $v(x,t)\geq u(x)$. Therefore, we cannot expect to control to any function below $u$.

This is why the understanding of the existence or non-existence of nontrivial solutions is of main importance for the controllability under state-constraints.

Non-trivial solutions around the boundary value $a=\theta$ do not constitute an intrinsic obstruction to the controllability because the boundary value $\theta$ is not in the border of the admissible set. However, the existence of such solutions create a technical difficulty for achieving the controllability to the steady state $w\equiv \theta$ which can be solved by constructing paths of steady states (See this blog entry ).

Elliptic nontrivial solutions with boundary value 1 do not exist. This can be related to the fact that the traveling waves for the Cauchy problem in the real line are approaching the steady state $w\equiv 1$ [2]

The existence of non-trivial solutions can be done either by comparison principles or by understanding the critical points of a functional (see [3]).

Any critical point of the functional:





is a weak solution of the main equation.

In order to guarantee that the solution will be between $0$ and $1$, one can extend $f$ by $0$ outside of the interval $[0,1]$.

Restricting ourselves in the one dimensional case (the argument also holds in several dimensions) and making the spatial change fo variables $x\to \frac{x}{L}$, where $L$ is the length of the domain the functional reads:



In the expression above we see that if $L$ is small the convex part dominates while if $L$ is large and $\int_0^1f(s)ds&amp;gt;0$ it might not be convex.

In the videos below one can see the evolution of the functional depending on the parameter $\lambda=L^2$. The representation is the evaluation of the functional along the first and the third eigenfunction, i.e. $e_1=\sin(\pi x)$ and $e_3=\sin(3\pi x)$,



Here, one can see the evolution of the functional for $a=0$ and for $a=\theta=1/3$ for values of $\alpha$ and $\beta$.


    
        
            
            
                
        
         
            
            
            
               
    

Figure 1. Animation of the functional $J$ for diferent values of $\lambda=L^2$. At the left the boundary value is $0$ while at the right the boundary value is $\theta$.

In the next figure a qualitative bifurcation diagram is represented, the red curve represents the nontrivial solutions with boundary value $\theta$ and the blue one the boundary value $0$. $\lambda^\ast$ is the minimum $\lambda=L^2$ for which a nontrivial solution around $0$ exists, analogously $\lambda^*_\theta$.




Figure 2. Bifurcation diagram . The blue line represents the maximum of the nontrivial solutions with boundary value $0$. The red curve represents some nontrivial solutions with boundary value $\theta$, the red line is the maximum of the nontrivial solution whenever the line is above $\theta$ and represents the minimum when the red line is below $\theta$.

The value $\frac{\lambda_1}{f’(\theta)}$ is the critical value for which the stationary solution $\theta$ becomes unstable. After this situation we have a nontrivial solution above and below $\theta$.

There will be further bifurcations around the boundary value $\theta$ when we increase $\lambda$. These bifuractions will lead to oscillatory nontrivial solutions that can be well understood in the phase-plane, see [2].

Here one can see different non-trivial solutions for different boundary values. The green curve corresponds to a section of the nontrivial solution in the whole $\mathbb{R}$:






Figure 3. Several nontrivial solutions, in blue the ones with boundary value $0$, the red ones have boundary value $\theta$ and the green one is the solution in the whole $\mathbb{R}$. $\theta_1$ is the number such that $\int_0^{\theta_1} f(s)ds = 0 $.

References:

[1] M.H. Protter and H.F. Weinberger, Maximum principles in differential equations, Springer Science &amp;amp; Business Media, 2012.

[2] D.  Ruiz-Balet  and  E.  Zuazua. Control of certain parabolic models from biology and social sciences.   Preprint  available  at https://cmc.deusto.eus/domenec-ruiz-balet/.

[3]  P.L. Lions, On the existence of positive solutions of semilinear elliptic equations, SIAM Rev. 24 (1982), no. 4, 441–467.

</description>
        <pubDate>Tue, 31 Mar 2020 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp03/P0006</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp03/P0006</guid>
        
        
        <category>tutorial</category>
        
        <category>WP03</category>
        
      </item>
    
      <item>
        <title>Control of reaction-diffusion under state constraints - Application of the staircase method</title>
        <description>In this tutorial, we will present how to generate admissible paths of steady states for the homogeneous reaction-diffusion equation:



This a key argument for ensuring controllability that has been studied in [2,3,4,5].

Stair-case method
The stair-case method (see [1]) guarantees the following:

If we have an admissible continuous path of steady states, for any initial datum in the path, any target function in the path and for $T&amp;gt;0$ sufficiently large, there exists a function $a$ such that drives the system from the initial datum to the target fulfilling the state-constraints along the trajectory.

Extension to ball, and the phase-plane analysis

We will restrict ourselves to the construction of paths that connect the steady state $w\equiv 0$ with the steady state $w\equiv \theta$. For doing such example with our model bistable equation.

In order to construct the paths we will use phase-plane techniques for which we use radial coordinates. Our original domain might not be a ball, for this reason we extend it to a ball and firstly construct the path there.




Figure 1. Extension of our domain to a ball.

Remind that the important issue is to be able to guarantee that for every domain $w\equiv0$ and $w\equiv\theta$ are connected in an admissable way and this is seen in the phase plane representation of the elliptic equation.



Now, considering the energy


where $F(u)=\int_0^u f(s)ds$, one can see that the radial ODE dissipates.

Define the following region:



Let $\theta_1$ be defined as:



Note that the region defined by



Note that $\Gamma\subset D$.

Take $(u_0,0)\in \Gamma$, then the solution of radial equation with initial
datum $(u_0,0)$ satisfies:



So $(u,v)\in\Gamma$ for all $r&amp;gt;0$.

We have that the blue line (the border of $\Gamma$) in the following figure determines a positively invariant region.

Then, making $a$ change continuously from $0$ to $\theta$ we generate a continuous path (by the Gromwall inequality) that is admissible since the invariant region $\Gamma$ is inside the admissible set.




Figure 2. Invariant region and construction of the path.

Animation of the path



  


Figure 3. Path of steady states.

If our domain is not a ball we restrict our path to the original domain to obtain the desired path.

Other features

General existence of admisible paths is not true due to the comparison principle. Non-trivial steady states can exist that block any possibility to control (See this blog entry ).

Here we restrict ourselves in the one dimensional case. In the following figure one can see how can we connect the steady state $w\equiv 0$ with the first nontrivial solution with boundary value $0$.




    
        
            
        
         
            
                           
    



Figure 4. Path of steady states.

However, since this path touches the boundary of the admissible set controllability cannot be guaranteed due to the comparison principle.

Another important remark to be mentioned is that if we forget about the state constraints, more paths can be generated, provided that the ODE representation of the elliptic equation does not blow up. The following figure is an example of a path connecting $w\equiv 0$ with $w\equiv 1$ that violates the constraints:



    
        
            
        
         
            
                           
    


Figure 5. Path of steady states violating constraints.

References:

[1] D. Pighin, E. Zuazua, Controllability under positivity constraints of multi-d wave equations, in:
Trends in Control Theory and Partial Differential Equations, Springer, 2019, pp. 195–232.

[2] J.-M. Coron, E. Trélat, Global steady-state controllability of one-dimensional semilinear heat equa-
tions, SIAM J. Control. Optim. 43 (2) (2004) 549–569.

[3] C. Pouchol, E. Trélat, E. Zuazua, Phase portrait control for 1d monostable and bistable reac-
635
tion–diffusion equations, Nonlinearity 32 (3) (2019) 884–909.

[4]   D.  Ruiz-Balet  and  E.  Zuazua. Controllability  under  constraints  for  reaction-diffusionequations:   The  multi-dimensional  case.   Preprint  available  athttps://cmc.deusto.eus/domenec-ruiz-balet/.

[5] D.  Ruiz-Balet  and  E.  Zuazua. Control of certain parabolic models from biology and social sciences.   Preprint  available  at https://cmc.deusto.eus/domenec-ruiz-balet/.

</description>
        <pubDate>Mon, 30 Mar 2020 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp03/P0005</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp03/P0005</guid>
        
        
        <category>tutorial</category>
        
        <category>WP03</category>
        
      </item>
    
      <item>
        <title>POD and DMD Reduced Order Models for a 2D Burgers Equation</title>
        <description>Burgers equation

For a given viscosity parameter $\nu$ and for time $t&amp;gt;0$, we consider the 2D Burgers equation on the unit square



with zero Neumann boundary conditions and initial condition



and its numerical approximation using


  Finite Elements in space and Runge-Kutta in time,
  a POD reduction of the FEM model, and
  a DMD reduced order model.


We present the basic ideas and how they are realized in a basic Python script.

0. The Setup

Please download and run the python file burgers.py to check the
implementation, to reproduce the presented results, and to the behavior of the
routines for different parameters.

Here is the start of the script that lists the modules on which the
implementation bases on.

import dolfin

import scipy.linalg as spla
import matplotlib.pyplot as plt
import numpy as np

from scipy.integrate import solve_ivp
from spacetime_galerkin_pod.ldfnp_ext_cholmod import SparseFactorMassmat


The code uses dolfin which is the python interface to
FEniCS while the other modules scipy, numpy,
and matplotlib are standard in python, I would say. The module
ldfnp_ext_cholmod is a little wrapper for the sparsity optimizing Cholesky
decomposition of sksparse.
It is available from my github
repository and falls back
to numpy routines, in the case that sksparse is not available.

1. The FEM Discretization

The spatial discretization in FEniCS

First, the mesh is defined – here a uniform triangulation of the unit square
controlled by the parameter N. For the value N=80 and for globally smooth
and piecewise quadratic ansatz functions, the resulting dimension of the system
is 51842.

# The mesh

pone = dolfin.Point(-1, -1)
ptwo = dolfin.Point(1, 1)
mesh = dolfin.RectangleMesh(pone, ptwo, N, N)

V = dolfin.VectorFunctionSpace(mesh, 'CG', 2)

### The FENICS FEM Discretization

v = dolfin.TestFunction(V)
u = dolfin.TrialFunction(V)


Next, the discrete linear operators are defined and exported as a SciPy sparse
matrix. Also, we factorize the mass matrix mmat for later use and define the
norm that is weighted with the mass matrix as this is the discrete $L^2$ norm.

# ## the mass matrix

mform = dolfin.inner(v, u)*dolfin.dx
massm = dolfin.assemble(mform)
mmat = dolfin.as_backend_type(massm).sparray()
mmat.eliminate_zeros()

# factorize it for later


mfac = SparseFactorMassmat(mmat)

# norm induced by the mass matrix == discrete L2-norm

def mnorm(uvec):
    return np.sqrt(np.inner(uvec, mmat.dot(uvec)))

# ## the stiffness matrix
# as a form in FEniCS

aform = nu*dolfin.inner(dolfin.grad(v), dolfin.grad(u))*dolfin.dx
aassm = dolfin.assemble(aform)

# as a sparse matrix

amat = dolfin.as_backend_type(aassm).sparray()
amat.eliminate_zeros()


Then we define the convective term as function of the velocity u both in terms
of an FE-function and as a function of the associated coefficient vector.

# ## the convective term

# as a function in FEniCS

def burgers_nonl_func(ufun):
    cform = dolfin.inner(dolfin.grad(ufun)*ufun, v)*dolfin.dx
    cass = dolfin.assemble(cform)
    return cass

# as a vector to form map

def burgers_nonl_vec(uvec):
    ufun = dolfin.Function(V)
    ufun.vector().set_local(uvec)
    bnlform = burgers_nonl_func(ufun)
    bnlvec = bnlform.get_local()
    return bnlvec


The Runge-Kutta Time Integration

To apply standard time integration schemes (here, RK23 turned out to be most
efficient), we define the right hand side $f_h$ of the spatially discretized problem



In this case the right hand side is an application of the discrete diffusion
and convection operator and the inverse of the mass matrix that, simply
speaking, maps a (discrete) form onto a discrete function. Note that there is no
explicit time dependency in the Burgers equation, but SciPy’s solve_ivp
requires this parameter. Also, we define the initial value here. The time grid
is used to store the solution for the snapshots needed later, but the time
integrator uses his internal time grid.

inivstrg = 'exp(-3.*(x[0]*x[0]+x[1]*x[1]))'
inivexpr = dolfin.Expression((inivstrg, inivstrg), degree=2)
inivfunc = dolfin.interpolate(inivexpr, V)
inivvec = inivfunc.vector().get_local()

burgsol = solve_ivp(brhs, (t0, tE), inivvec, t_eval=timegrid, method='RK23')
fullsol = burgsol.y


Here is the result. Note the sharp front that develops towards the end of the time
integration.


Solution snapshots of the full FEM model 

2. POD Reduced Model

If one has snapshots of the solution $v _ h$ at some time instances $t _ i$ one
may well think that the span of the matrix of snapshots



is a good candidate for a space in which the solution evolves in. One may even
go further and look for a low-dimensional basis of this space. The span of a
matrix is best approximated by its dominant singular vectors. And this is the idea of
Proper Orthogonal Decomposition (POD) – use the leading singular vectors as a
basis for the solution space.

We use the Nts=101 snapshots of the FEM solutions to setup the matrix of
measurements $X$ and to compute the POD modes as $M^{-1/2}v _ k$, where $v _ k$
is the $k$-th leading left singular vector of $M^{1/2}X$. This procedure gives a
low-dimensional orthogonal (in the discrete $L^2$ inner product) basis that
optimally parametrizes the subspace of $L^2$ that is spanned by the solution
snapshots1. In this example, we use the poddim=25 leading singular vectors
to define the reduced model.

snapshotmat = mfac.Ft.dot(burgsol.y)
podmodes, svals, _ = spla.svd(snapshotmat, full_matrices=False)
selected_podmodes = podmodes[:, :poddim]
podvecs = mfac.solve_Ft(selected_podmodes)

In this implementation we use a sparse factor of the mass matrix instead of the
square root. The singular values (in particular those that correspond to the
discarded directions) give an indication of how good the approximation is.


The singular values of the snapshot matrix 

Here, the decay is comparatively slow, so that a one should not expect a good
low dimensional approximation by POD.

For the simulation, the state is parametrized by $u_h (t) \approx V \tilde
u_h(t)$ where $V$ is the matrix of the POD modes (in the code $V$ denoted by
podvecs), which gives a system in $\tilde u _ h$ with 25 degrees of freedom
(as opposed to the 51842 of the full order model).

redamat = podvecs.T.dot(amat.dot(podvecs))  # the projected stiffness

def redbrhs(time, redvec):
    inflatedv = podvecs.dot(redvec)
    redconv = podvecs.T.dot(burgers_nonl_vec(inflatedv))
    return -redamat.dot(redvec) - redconv.flatten()


Here we define the projected stiffness matrix and the reduced nonlinearity
through


  inflating the reduced state to full dimension
  applying the nonlinearity
  projecting down the result.


This means that our model is not completely independent of the full dimension.
For this problem there are hyperreduction techiques like DEIM.

Thus, the right hand side is readily defined the more that the projected mass
matrix is the identity. Why?

Finally, the initial value is projected into the reduced coordinates and the
reduced system is integrated in time.

redburgsol = solve_ivp(redbrhs, (t0, tE), prjinivvec,
                       t_eval=timegrid, method='RK23')
podredsol = redburgsol.y


In the solution we see that the reduced order model gives a decent approximation
in the smooth regime in the beginning and has its troubles approximating the front as can be seen in the error (log) plot.




Snapshots of the solution of the reduced system 


Snapshots of the log of the error between the full and the POD solution

3. DMD Reduced Model

POD is partially data driven – it uses data to create a basis but still
uses (a projection of) the model. If only snapshots but no model is given, one
may use the method of Dynamic Mode Decomposition2 (DMD) that tries to identify
a matrix $A$ that evolves the state like



In practice, one uses a set of snapshots and the two measurement matrices



and



Note that $X’$ is basically $X$ shifted by one time step.

Then the DMD matrix can be found by solving the linear regression problem



For the reduced DMD model we use the same snapshot matrix as for the POD. The
regression problem is solved via SVD to compute the needed pseudo inverse since
this naturally allows for a rank reduction and a factored representation of the
DMD matrix.

# ### dmd using truncated svd inverse

fburgsol = burgsol.y
Xmat = fburgsol[:, :-1]
Xdsh = fburgsol[:, 1:]
ux, sx, vxh = spla.svd(Xmat, full_matrices=False)
uxr, sxr, vxhr = ux[:, :poddim], sx[:poddim], vxh[:poddim, :]

# compute the dmd matrix in factored form: `dmda = dmdaone * dmdatwo`

dmdaone = Xdsh.dot(vxhr.T)
dmdatwo = np.linalg.solve(np.diag(sxr), uxr.T)


Once the DMD matrix $A$ is determined, the simulation of the DMD reduced model
is only a repeated multiplication by $A$.

# simulation of the dmd reduced model

dmdxo = inivvec
dmdsol = [dmdxo]
for k in np.arange(Nts):
    dmdsol.append(dmdaone.dot(dmdatwo.dot(dmdsol[-1])))

dmdsol = np.array(dmdsol).T


As can be seen from the results and the error plots, DMD does a good job in the
initial phase but fails in the region with the sharp front.


Snapshots of the DMD solution


4. Remarks

It is commonly accepted that POD does not work well for transport dominated
problems – like the current case with the low viscosity parameter nu=1e-4.

So, I think that the results for POD are quite good noting that the reduced
order model has 25 degrees of freedom whereas the full model has 51842.
Nonetheless, in my tests, increasing the number of basis functions did not help
much. One can use a larger nu to get better POD approximations.

The DMD approach shows a similar performance. If compared to POD, the
qualitative approximation looks less good but the numbers are slightly better.
All in all, the DMD approximation seems less reliable as for some parameter
choices, the performance severely deteriorated.

Differential Equations.* arXiv:1611.04050

Decomposition: Theory and Applications* arXiv:1312.0041

  
    
      See, e.g., Lemma 2.5 of Baumann, Benner, and Heiland (2018): *Space-Time Galerkin POD with Application in Optimal Control of Semi-linear Parabolic Partial &amp;#8617;
    
    
      See, e.g., Tu, Rowley, Luchtenburg, Brunton, Kutz (2013): *On Dynamic Mode &amp;#8617;
    
  

</description>
        <pubDate>Sat, 07 Mar 2020 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0009</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0009</guid>
        
        
        <category>tutorial</category>
        
        <category>WP04</category>
        
      </item>
    
      <item>
        <title>Inverse design for the one-dimensional Burgers equation</title>
        <description>The problem

We consider the following one-dimensional Burgers equation



where $u$ is the state, $u_0$ is the initial state and  the flux function $f$ is defined by $f(u)=\frac{u^2}{2}$. Kruzkov’s theory  provides existence and uniqueness of a  solution  of \eqref{eq} with initial datum $u_0 \in L^{\infty}(\mathbb R)$. This solution is called a weak-entropy solution, denoted by $(t,x) \to S_t^+(u_0)(x)$. For a given target function $u^T$, we introduce the backward entropy  solution $(t,x) \to S^-_{t}(u^T)(x)$  as follows: 
for every $t\in [0,T]$, for a.e $x\in \mathbb R$,



We study the problem of inverse design for \eqref{eq}. This problem consists in  identifying the set of initial data evolving to a given target at a final time.

Due to the time-irreversibility of the Burgers equation, some target functions are unattainable from weak-entropy solutions of this equation, making the inverse problem under consideration ill-posed. To get around this issue, we introduce the following  optimal control problem



where $u^T$ is a given target function and the class of admissible initial data $\mathcal{U}^0_{\text{ad}}$ in \eqref{opt2} is defined by



Above,  stands for functions of bounded variation and  $C&amp;gt;0$ is a constant large enough. The study of \eqref{opt2} is motivated by the minimization of the sonic boom effects generated by supersonic aircrafts [2].

To solve the optimal control problem \eqref{opt2}, some difficulties arise from a  theoretical  and  numerical point of view.

  Since the  entropy solution $u$ of \eqref{eq} may contain shocks even if the initial datum is a smooth function, this generates important added difficulties that have been the object of intensive study in the past, see  [3,4] and the references therein. In particular, the authors make sense of the derivative of $J_0$ in \eqref{opt2} in a weak way by requiring  strong conditions on the set of initial data. This leads to require that entropy solutions of \eqref{eq} have a finite number of non-interacting jumps.
  When $J_0$ is weakly differentiable,  gradient descent  methods have been implemented in [1,5,6] to solve numerically the optimal problem \eqref{opt2}. In the cases where it was applied successfully, only one possible initial datum emerges, namely the backward entropy solution $S_T^-(u^T)$. This is mainly due to the numerical viscosity that numerical schemes introduce to gain stability. To find some multiple minimizers, the authors in  [8]  use a filtering step in the backward adjoint solution.


Dans [9], we fully characterize the set of minimizers of the optimal control problem \eqref{opt2}.

Theorem 1.  Let $u^T\in BV(\mathbb R)$. The optimal control problem \eqref{opt2}  admits multiple optimal solutions. Moreover, for a.e $T&amp;gt;0$, the initial datum $u_0\in BV(\mathbb R)$ is an optimal solution of \eqref{opt2} if and only if $u_0 \in BV(\mathbb R)$ verifies $S_T^+(u_0)=S_T^+ (S_T^-(u^T))$.

A characterisation of the set  is given in [7]. An illustration of Theorem 1. is given in Figure 1.


Figure 1: The backward-forward  solution $S_T^+(S_T^-(u^T))$ is the projection of $u^T$ onto the set of attainable target functions. The shaded area in red at time $t=0$ represents the set of minimizers of \eqref{opt2} 

The proof of Theorem 1 is structured as follows. From [7, Theorem 3.1, Corollary 3.2] or [8, Corollary 1], there exists $u_0\in BV(\mathbb R)$ such that  if and only if  satisfies  the one-sided Lipschitz condition, i.e 

 Thus, the optimal problem \eqref{opt2} can be rewritten as  follows.



where the admissible set $\mathcal{U}^T_{\text{ad}}$ is defined by



Above, $K_1$ an open bounded interval large enough.  Note that the optimal problem \eqref{opt5} is not related to the PDE model \eqref{eq}. We prove that $q=S_T^+ (S_T^-(u^T))$ is a critical point of \eqref{opt5} using the first-order optimality conditions applied to \eqref{opt5} and the full characterization of the set  given in [9, Theorem A.2].

Numerical simulations

In [9,Section 3], we  implement a wave-front tracking algorithm to construct numerically the set of  minimizers of \eqref{opt2}.  We consider for instance, a target function   defined by



From Theorem 1,  the backward solution  is an  optimal solution of \eqref{opt2} and   is an optimal solution of \eqref{opt2} if and only if  . In Figure 2, the target function , the backward solution  and  the backward-forward solution  are plotted.



    
        
        
        
        
        
        
    
    
        
        $x\to S^{-}_T(u^T)(x)$ 
        
        
        $(t,x)\to S^{+}_t(S^{-}_T(u^T))(x)$ 
         
    




$u^T$  and $\color{red}{x\to S^{+}_T(S^{-}_T(u^T))(x)}$ 
$ $
Figure 2. Plotting of the target function $u^T$ defined in \eqref{uT}, the optimal solution $S_T^-(u^T)$ and the backward-forward solution $\color{red}{S^{+}_T(S^{-}_T(u^T))}$.

Note that  has four different shocks located at $x=1.1$, $x=3.1$, $x=5.3$ and $x=7.2$. If we use a conservative numerical method as Godunov scheme,  the approximate solution of  doesn’t have shocks because of numerical viscosity that numerical schemes introduced, see Video 1.



    
        
            
        
        
            
        
    


Video 1. Approximate solution of $S_T^+(u_0)$ with $u_0$ an $N$-wave constructed with $ \color{red}{\text{a wave-front tracking algorithm}}$ and $\color{blue}{\text{a Godunov scheme}}$ 

This implies that only one minimizer of \eqref{opt2} can be constructed using a Godunov scheme, which is the backward entropy solution $S_T^-(u^T)$. When a wave-front tracking algorithm is implemented, the approximate solution of $S_T^+(S_T^-(u^T))$ has shocks since we track the possible discontinuities from $u^T$ to  $S_T^+(S_T^-(u^T))$. This implies that all initial data $u_0$ that coincide with the approximate solution of $S_T^+ (S_T^-(u^T))$ can be recovered, see [9,Section 3].

In Video 2, we show that the weak-entropy solution of \eqref{eq}  with initial data $S_T^-(u^T)$ coincides with $S_T^+ (S_T^-(u^T))$ at time $T$.


Video 2. Approximate solution of $(t,x) \to S_t^+(S_T^-(u^T))(x)$  using a wave-front tracking algorithm. 

In Video 3, three other approximate optimal solutions $u_0$ of \eqref{opt2} are constructed. In particular, we show that  $S_T^+ (u_0)=S_T^+ (S_T^-(u^T))$.



    
        
            
        
        
            
        
    

    
                
            
    
    



Video 3. Three approximate optimal solutions of \eqref{opt2} constructed using a wave-front tracking algorithm 

[1] Navid Allahverdi,  Alejandro Pozo and Enrique Zuazua. Numerical aspects of large-time optimal control of Burgers equation. ESAIM: Mathematical Modelling and Numerical Analysis, 50 (5):1371-1401,2016.

[2]  Navid Allahverdi,  Alejandro Pozo and Enrique Zuazua. Numerical aspects of sonic-boom minimization. A panorama of Mathematics: Pure and Applied, 658:267,2016.

[3] François Bouchut and François James. One-dimensional transport equations with discontinuous coefficients. Nonlinear Analysis, 32(7):891,1998.

[4] Alberto Bressan and Andrea Marson. A maximum principle for optimally controlled systems of conservation laws. Rendiconti del Seminario Matematico della Universita di Padova, 94:79-94, 1995.

[5] Carlos Castro, Francisco Palacios and Enrique Zuazua. An alternating descent method for the optimal control of the inviscid Burgers equation in the presence of shocks. Mathematical Models and Methods in Applied Sciences, 18(03):369-416,2008.

[6] Carlos Castro, Francisco Palacios and Enrique Zuazua. Optimal control and vanishing viscosity for the Burgers equation. In Integral Methods in Science and Engineering, Volume 2, pages 65-90. Springer, 2010.

[7] Rinaldo Colombo and Vincent Perrollaz. Initial data identification in conservation laws and Hamilton-Jacobi equations. arXiv preprint arXiv:1903.06448,2019.

[8] Laurent Gosse and Enrique Zuazua. Filtered gradient algorithms for inverse design problems of one-dimensional Burgers equation. In Innovative algorithm and analysis, pages 197-227. Springer, 2017.

[9] Thibault Liard and Enrique Zuazua. Inverse design for the one-dimensional Burgers equation. Submitted (2019).
</description>
        <pubDate>Mon, 02 Mar 2020 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0007</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0007</guid>
        
        
        <category>tutorial</category>
        
        <category>WP04</category>
        
      </item>
    
      <item>
        <title>An eulerian-lagrangian scheme for the problem of the inverse design of hyperbolic transport equations</title>
        <description>The inverse design of hyperbolic transport equations can be addressed by using gradient-adjoint methodologies. Recently, Morales-Hernandez and Zuazua [1] investigated the convenience of using low order numerical schemes for the adjoint resolution in the gradient-adjoint method. They focused on hyperbolic transport scalar equations with an heterogeneous time-independent vector field.

Morales-Hernandez and Zuazua analysed the numerical resolution of the adjoint equation by means of two methods: a First Order Upwind $(FOU)$ scheme and a Second Order Upwind $(SOU)$ scheme. They concluded that the $FOU$ scheme is the best choice when dealing with smooth functions once the $SOU$ scheme introduces some spurious oscillations. In addition, the $FOU$ scheme requires shorter computational time than the $SOU$ scheme. The non-linear transport problems in which sharp interfaces or discontinuities may appear in the functions has remained to be studied.

The numerical scheme for the adjoint equation determines the direction of descent in the iteration procedure, and consequently the $CPU$ time consumed by the solver. As the $CPU$ time is a decisive factor, we propose an eulerian-lagrangian scheme that uses the Modified Method of Characteristics ($MMOC$) [2] for solving the transport and adjoint equations. The $MMOC$ method is based on the characteristic curves, and so very computationally competitive for linear hyperbolic transport equations. The $MMOC$ was initially developed performing the resolution in a forward sense. In this work, the eulerian-lagrangian scheme is used for the transport and adjoint resolution, employing it in both forward and backward senses.

We perform numerical tests in order to investigate the accuracy and efficiency of the eulerian-lagrangian scheme to solve the problem of inverse design of linear and non-linear hyperbolic transport scalar equations.

The gradient-adjoint method

Consider the following hyperbolic transport scalar equation with a vector flux function ${\bf f} (u)$:

\begin{equation}\label{eq1}
\frac{\partial u}{\partial t} + \nabla \cdot {\bf f} (u) = 0, ~ ~ u({\bf x},0) = u_0.
\end{equation}

Given a target function $u^* \in \bf H$, $\bf H$ being a Hilbert space, the problem of inverse design consists of achieving $u_0 \in \bf H$ such that the solution of the former evolution equation satisfies $u(T) = u^*$. This problem is solved via the minimization of the functional

\begin{equation}\label{eq2}
J(u_0) = \frac{1}{2} \int_{0}^{T} \int_{\Omega} (u(T) - u^*)^2 d\Omega dt
\end{equation}

by means of the gradient descent method:

\begin{equation}\label{eq3}
{u_0}^{k+1} = {u_0}^k -  \epsilon {\nabla J}^k,
\end{equation}

where $\epsilon$ is the step size, and the gradient $\nabla J = \sigma (0)$, in which $\sigma$ is the adjoint variable . The gradient $\sigma (0)$ is achieved by solving the adjoint equation:



The gradient-adjoint method is based on iterating a loop, where the transport equation (\ref{eq1}) is solved in a forward sense, while the adjoint equation (\ref{eq4}), which is of hyperbolic nature as well, is solved backwards in time.

The $MMOC$ in forward sense

Eulerian-lagrangian approaches provide computationally efficient techniques for approximating the solution of hyperbolic transport equations. Douglas and Russel [2] introduced an eulerian-lagrangian method based on the characteristic curve - the $MMOC$ - to develop fast solvers for hyperbolic transport equations. Despite the $MMOC$ does not provide a local conservation of the identity associated with the function, it present good performance for linear hyperbolic transport equations.

We use the $MMOC$ method for solving the transport and adjoint equations in the context of the problem of inverse design of hyperbolic transport equations. In this problem, the adjoint equation is always a linear differencial equation, worthing the use of the eulerian-lagrangian scheme. The gradient-adjoint iteration requires the adjoint equation to be solved in backward sense. We employ an eulerian-lagrangian scheme that uses the $MMOC$, considering procedures in forward and backward senses.

Consider a scalar hyperbolic transport equation determining the initial value problem

\begin{equation}\label{eq5}
\frac{\partial u}{\partial t} + \nabla \cdot {\bf f} (u) = 0, ~ ~ u({\bf x},0) = u_0 ,
\end{equation}

where ${\bf f} (u)$ is a vector flux function. Rewriting the Eq. (\ref{eq5}) in nondivergence form,

\begin{equation}\label{eq6}
\frac{\partial u}{\partial t} + {\bf f}^\prime (u) \cdot \nabla u  = 0 .
\end{equation}

The solution of Eq. (\ref{eq6}) is essentially along the characteristic curves of the transport operator $\partial / \partial t + {\bf f}^\prime (u) \cdot \nabla$, so that it is appropriate to introduce differentiation in this characteristic direction. Let

\begin{equation}\label{eq7}
\partial / \partial t + {\bf f}^\prime (u) \cdot \nabla = \psi \frac{\partial}{\partial \tau} , ~~\psi (u) = \sqrt {1 + {\left \lVert {\bf f}^\prime (u) \right \rVert}^2} , 
\end{equation}

in which the direction $\tau$ depends on $\bf x$.

Let us consider the discretization of  Eq. (\ref{eq6}) in time. Denote the time step $\Delta t &amp;gt; 0$ and consider the approximation of the solution at times $t^n = n \Delta t$. In the standard $MMOC$, the characteristic derivative is approximated by

\begin{equation}\label{eq8}
\psi \frac{\partial u}{\partial \tau} \approx \psi (u({\bf x}, t^{n-1})) \frac {u({\bf x}, t^{n}) - u(\overline {\bf x}^n, t^{n-1})}{\sqrt {\left \lVert {\bf x} - \overline {\bf x}^n \right \rVert^2 + (\Delta t)^2 }} =  \frac {u({\bf x}, t^{n}) - u(\overline {\bf x}^n, t^{n-1})}{\Delta t} ,
\end{equation}

where

\begin{equation}\label{eq9}
\overline {\bf x}^n =  \overline {\bf x}^n ({\bf x}) = {\bf x} - {\bf f}^\prime (u({\bf x}, t^{n-1}) \Delta t .
\end{equation}

Let $U^n ({\bf x})$ denote the approximations to $u({\bf x},t^n)$. For a predecessor position

\begin{equation}\label{eq10}
\overline {\bf X}^n ({\bf x}) = {\bf x} - {\bf f}^\prime (U^{n-1} ({\bf x})) \Delta t,
\end{equation}

the transported function is defined as

\begin{equation}\label{eq11}
\overline {U}^n ({\bf x}) =  u (\overline {\bf X}^n ({\bf x}), t^{n-1}) .
\end{equation}

As the continuous in space approximation for Eq. (\ref{eq6}) is

\begin{equation}\label{eq12}
\frac{U^n ({\bf x}) - \overline U^{n} ({\bf x})}{\Delta t} = 0 ,
\end{equation}

the $MMOC$ scheme is given by



Preliminary results

The performance of the $MMOC$ scheme is checked in numerical tests, where two hyperbolic transport problems are considered. The results by $MMOC$ are compared with the ones by the Lax-Wendroff ($LW$), which is a second-order central scheme.

2D Doswell frontogenesis

The first test case symbolizes the presence of horizontal temperature gradients and fronts in the context of meteorological dynamics. In this linear problem the flux function is

\begin{equation}
{\bf f} (u) =  {\bf v} (x,y)~ u ,
\end{equation}

where ${\bf v} (x,y)= g~(-y,~x)$, $g = \frac{1}{r}2.59807~sech^2(r)~tanh(r)$, and $r = \sqrt{x^2 + y^2}$. The exact solution of this problem is given by

\begin{equation}
u (x,y,t) = tanh(y~cos(gt) - x~sin(gt)).
\end{equation}

The domain $\Omega = [-5,5]^2$ is discretized in 40000 square cells, a step size $\epsilon = 0.5$ is selected and the Courant number is set to $CFL = 1.0$. The results are shown in Fig.1 for the initial condition and target function at $T = 4s$. The target function in a vortex-type profile is presented by both the $LW$ and $MMOC$ schemes.



    
        
            
        
        
            
        
    
    
        
            
        
        
            
        
    



 Figure 1. The initial condition and target function by $LW$ (top) and MMOC (bottom).   


Results of $CPU$ time and $L_2$ norm of the numerical initial condition with respect to the exact initial condition are displayed in Table [1]. The results are quite the same for the $LW$ and $MMOC$, since we have a linear transport equation.




    
		  $Scheme$ 
    
    
         $CPU~ time~ (s)$ 
    
    
        $L_2~ norm$ 
    




        
		  $LW$ 
    
    
         49.0
    
    
        4.07
    


        
		  $MMOC$ 
    
    
         80.8
    
    
        3.96
    




Table 1. Performance for initial condition in the Doswell frontogenesis.

Inviscid Burgers equation

We consider the Burgers equation with zero viscosity term which is called the inviscid Burgers equation. This equation is one of the most useful formulation of the behaviour of the shock waves in which nonlinear advection can be observed. In this nonlinear problem the flux function is

\begin{equation}
f (u) =  \frac{1}{2} u^2 .
\end{equation}

The exact solution of this problem is given by

\begin{equation}
u(x,t) = sin(x - ut) .
\end{equation}

The domain $\Omega = [0,32]^2$ is discretized in 4096 square cells, a step size $\epsilon = 0.01$ is selected and the Courant number is set to $CFL = 0.1$. The exact and $MMOC$ initial conditions are shown in Fig 2 considering zero values as a guess initial condition. Only with the $MMOC$ scheme the numerical solver was able to converge to the initial condition for the selected step size.


    
    
        
    
    
        
    
    

     Figure 2.The exact (left) and $MMOC$ (right) initial conditions.


In order to observe the convergence to the initial condition, we set $u_0(x) = \beta sin(x)$ as a guess initial condition, where $\beta$ is a constant. As $\beta$ is next to one, the guess initial conditions is closer to the exact initial condition. Table 2 displays the $CPU$ time and $L_2$ norm of the numerical initial condition with respect to the exact initial condition for several $\beta$ values. The numerical solver using $MMOC$ scheme converged for any $\beta$ value, showing that the norm is smaller as the $\beta$ is increased.



    
        $\beta$    $LW$  $MMOC$
    
    
        0.1    3.68  3.39
    
    
        0.5    2.82  2.70
        
    
        0.9    0.95  1.19
    




Table 2. Performance for initial condition by $MMOC$ in the Burgers problem.


Conclusions

The results achieved and presented here are preliminary ones. The $MMOC$ is a promising eulerian-lagrangian scheme for the problem of inverse design of nonlinear transport equations. More complex problems and another eulerian-lagrangian scheme are to be tested. The next steps are the follows:


  simulate and investigate the Buckley-Leverett problem;
  simulate and investigate the miscible tracer flow; and
  use the $LCELM$ eulerian-lagrangian scheme [3].


References

[1] M. Morales-Hernandez, E. Zuazua, Adjoint computational methods for 2d inverse design of linear transport equations on unstructured grids, Computational and Applied Mathematics (2019)

[2] J. Douglas, T. F. Russell, Numerical methods for convection dominated diffusion problems based on combining the method of characteristics with finite element or finite difference procedures, SIAM J.
Numer. Anal. (1982)

[3] J. Douglas, F. Pereira, L.-M. Yeh, A locally conservative euleriana lagrangian numerical method and its application to nonlinear transport in porous media, Computational Geosciences (2000)
</description>
        <pubDate>Tue, 18 Feb 2020 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0008</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0008</guid>
        
        
        <category>tutorial</category>
        
        <category>WP04</category>
        
      </item>
    
      <item>
        <title>Stabilization of a double pendulum on a cart with DyCon Toolbox</title>
        <description>The finite-dimensional dynamical system given by a pendulum on a cart (cartpole) is widely considered as a benchmark for comparing the performance of different control strategies. In this blog post, we consider a double pendulum on a cart and we solve the problem of swinging up the pendulum from the downward position to the upward position using optimal control techniques.

Equations of motion



  Figure 1. Scheme of system dynamics


The physical system defined by the double pendulum in a cart can be modelled as a system of six ordinary differential equations, whose state at each instant of time $t \geq 0$ is the vector $y(t) = \left( x(t), \theta_{1}(t), \theta_{2}(t), v(t), \omega_{1}(t), \omega_{2}(t) \right)$, where:


  $x(t) \in \mathbb{R}$ is the position of the cart.
  $\theta_{i}(t) \in [0, 2\pi]$ is the angle of the $i$-th pendulum.
  $v(t) \in \mathbb{R}$ is the velocity of the cart.
  $\omega_{i}(t) \in \mathbb{R}$ is the angular velocity of the $i$-th pendulum.


The equations of motion of the system can be derived using the Lagrangian formalism of classical mechanics and are given by:



where, for each $t \geq 0$, we define:



and



We have the fixed parameters:


  $d_{i} \in [0,1]$ are damping coefficients.
  $m &amp;gt; 0$ is the mass of the cart and $m_{i} &amp;gt; 0$ is the mass of the $i$-th pendulum.
  $l_{i} &amp;gt; 0$ is the length of the $i$-th pendulum.


The function $u \in L^{\infty}(0,\infty; \mathbb{R})$ is a time-dependent control that acts on the acceleration term $\dot{v}(t)$ of the cart, and can thus be interpreted as a force that is exerted on the cart.

This dynamical system shows chaotic behaviour. The following animation displays the evolution of the double pendulum on a cart with control $u = 0$ and starting at the two different initial conditions










  Figure 2. Chaotics behaviour


  Optimal Control Problem 

We will solve the problem of steering the state of the pendulum from the downward position $y_{0} = (0, \pi, \pi, 0, 0, 0)$ to the upward position $z = (0, 0, 0, 0, 0, 0)$ in a fixed time horizon $T &amp;gt; 0$ using a control $u(t)$.

One way to look for solutions to this problem is to minimize the following functional:



Where $\alpha &amp;gt;0$ is a fixed parameter, the state vector $y(t)$ is subject to the system of differential equations (1) and $y(0) = y_0$.

  Numerical simulation 

We start by implementing the dynamical system defined in (1) as a MATLAB function. We fix the lengths $l_{i} = 1$, and the mass of the cart $M = 50$. The damping coefficients are set to $d_{i} = 0.1$.

  &amp;gt;&amp;gt; type cartpole_dynamics.m

function ds = cartpole_dynamics(t,s,u,params)
    L1 = 1;    L2 = 1;    g = 9.8;
    m1 = params.m1;    m2 = params.m2;
    M = 50;
    d1 = 1e-1;    d2 = 1e-1;    d3 = 1e-1;
    %%%%%%%%%%%%%%%%%%%%%5%%%
    ds = zeros(6,1,class(s));
    %
    q      = s(1);    theta1 = s(2);
    theta2 = s(3);    dq     = s(4);
    dtheta1= s(5);    dtheta2= s(6); 
    % q
    ds(1) = dq -q;
    % theta 1
    ds(2) = dtheta1;
    % theta 2
    ds(3) = dtheta2;
    %
    Mt = [ M+m1+m2                  L1*(m1+m2)*cos(theta1)     m2*L2*cos(theta2) ; ...
          L1*(m1+m2)*cos(theta1)     L1^2*(m1+m2)             L1*L2*m2*cos(theta1-theta2) ; ...
          L2*m2*cos(theta2)          L1*L2*m2*cos(theta1-theta2)  L2^2*m2        ];
    % v
    f1 = L1*(m1+m2)*dtheta1^2*sin(theta1) + m2*L2*theta2^2*sin(theta2)      - d1*dq + u  ;
    f2 = -L1*L2*m2*dtheta2^2*sin(theta1-theta2) + g*(m1+m2)*L1*sin(theta1)  - d2*dtheta1;
    f3 =  L1*L2*m2*dtheta1^2*sin(theta1-theta2) + g*L2*m2*sin(theta2)       - d3*dtheta2; 

    ds(4:6) = Mt\[f1;f2;f3];
end


This optimal control problem is solved using CasADi with the IPOPT solver. MATLAB’s symbolic toolbox has been used to implement the system dynamics in CasADi.

The time horizon is set to $T = 10$ and the system (1) has been discretized using a Crank-Nicolson scheme. The use of an implicit discretization method with good behaviour with respect to the number of mesh points has been crucial to speed up the optimization process.

import casadi.*
% define optimal 

Ss = SX.sym('x',6,1);As = SX.sym('u',1,1);ts = SX.sym('t');
%
EvolutionFcn = Function('f',{ts,Ss,As},{ cartpole_dynamics(ts,Ss,As,params) });
%
dynamics_obj = ode(EvolutionFcn,Ss,As,tspan);
dynamics_obj.InitialCondition = s0;
%
PathCost  = Function('L'  ,{ts,Ss,As},{ (  (Ss.'*Ss) + 1e-3*(As.'*As) ) });
FinalCost = Function('Psi',{Ss}      ,{ (  (Ss.'*Ss) ) });

ocp_obj = ocp(dynamics_obj,PathCost,FinalCost);
%
U0 =0*tspan;
[OptControl ,OptState] = IpoptSolver(ocp_obj,U0,'integrator','CrankNicolson');



The following animation displays the resulting evolution of the system’s state:






  Figure 3. Optimal solution 


Interestingly, due to the chaotic character of system (1), the IPOPT routine yields different controlled trajectories if we change the initial guess of the control:






  Figure 4. Several initial guess of optimization

</description>
        <pubDate>Thu, 13 Feb 2020 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp01/P0008</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp01/P0008</guid>
        
        
        <category>tutorial</category>
        
        <category>WP01</category>
        
      </item>
    
      <item>
        <title>Optimal Control of the Fokker-Planck Equation with CasADi</title>
        <description>In this tutorial, we present an optimal control problem related to the Fokker-Planck equation.

Description of the problem

The Fokker Planck Equation

Let $\Omega$ be an open, bounded, regular subset of $\mathbb{R}^{n}$. Let $T&amp;gt;0$ and denote by $u\in L^2(0,T;H^{1}(\Omega))^n$ a time-dependent vector field in $\Omega$. Consider a particle in $\Omega$ that moves with velocity $u(x,t)$ at each point $x\in\Omega$ in time $t\in(0,T)$. Suppose furthermore that the particle is subject to additive Brownian noise.

Let $p_0(x)$ be the probability density of the position of the particle at time $t=0$. Then, at every time $t&amp;gt;0$, the probability density $p(x,t)$ of the particle satisfies the Fokker-Planck equation [1]:



Where $\mathrm{n}$ is the outward unit normal vector field on $\partial\Omega$.

Fix a positive real number $a&amp;gt;0$ and introduce the family of admissible controls:



For every non-negative initial data $p_0\in H^{1}(\Omega)$ and every admissible control $u\in\mathcal{U}_{\mathrm{ad}}$, there is a unique solution $p\in\mathcal{C}([0,T];L^{2}(\Omega))\cap L^{2}(0,T;H^{1}(\Omega))$ to the previous problem such that $p(x,t)\geq 0$ for every $t\geq 0$ and almost every $x\in\Omega$ [2].

If, besides, $\int_{\Omega}p_{0}(x)dx=1$, then integrating by parts it’s easy to check that $\int_{\Omega}p(x,t)dx=1$ for every $t\geq 0$, so $p(.,t)$ is indeed a probability density on $\Omega$ for every $t\geq 0$.

Optimal Control

Fix a smooth reference trajectory $z:[0,T]\rightarrow\Omega$. Our objective is to find an admissible control $u\in\mathcal{U}_{\mathrm{ad}}$ that minimizes the following functional:



subject to:



where $\alpha,\beta$ and $\gamma$ are non-negative real 
numbers. In [2] it is proven that there always exists a $u^{*}\in\mathcal{U}_{\mathrm{ad}}$ minimizing the previous functional among the family of admissible controls.

Numerical Simulation

In the numerical example that we will present in this post, we will work over the one-dimensional domain $\Omega = (-6,6)$ with time horizon $T = 5$, and the oscillating reference trajectory $z(t) = 4\sin(2t)$. We also fix $\alpha=\beta=\gamma=1$, so that our objective will be to minimize the functional:



subject to





We consider the initial probability density function



where $C&amp;gt;0$ is chosen so that $\int_{-6}^{6}p_0(x)dx=1$.



We start by defining the mesh sizes and parameters. We discretize the spatial domain with $20$ points and the temporal domain with $80$ points.

%% mesh sizes and parameters

% spatial mesh
X_max = 6; % length of space domain
Nx = 20; % number of mesh points
x_line = linspace(-X_max,X_max,Nx); % discretization of the space domain
dx = x_line(2) - x_line(1); % space increment

% temporal mesh
T = 5; % time horizon
Nt = 80; % number of mesh points
t_line = linspace(0,T,Nt); % discretization of the time domain
dt = t_line(2) - t_line(1); % time increment

% parameters
k = dt/(dx^2);
b = dt/(2*dx);


We define the reference trajectory $z(t)=4\sin(2t)$:

%% reference trajectory

ref = 4*sin(2*t_line);


We define the initial probability density $p_0(x) = \frac{1}{C}\exp(-2x^2)$. We compute $C$ using $C = \int_{-6}^{6}\exp(-2x^2)dx = \sqrt{\frac{\pi}{2}}\mathrm{erf}(6\sqrt{2})$, where $\mathrm{erf}$ is the error function.

%% initial density

y0 = exp(-2*x_line.^2);

C = sqrt(pi/2)*erf(sqrt(2)*X_max); % normalizing constant
y0 = (1/C) * y0'; % normalized initial density


The uncontrolled evolution of this probability density is given by the following heat equation with Neumann boundary conditions:



We discretize and solve this equation:

%% uncontrolled solution

Yf = zeros(Nx,Nt);
Yf(:,1) = y0;

for n = 1 : Nt-1
    for j = 2 : Nx-1
        % euler step
        Yf(j,n+1) = Yf(j,n) +  k * (Yf(j+1,n) - 2*Yf(j,n) + Yf(j-1,n));
    end
    % zero flux boundary conditions
    Yf(Nx,n+1) = Yf(Nx-1,n+1); 
    Yf(1,n+1) = Yf(2,n+1);
end

We display the uncontrolled solution:


  
      
        
      
      
        
      
  


The solution $p(x,t)$ of the Heat equation (2) is the probability density associated to a one-dimensional Brownian motion on the real line. This is a particular case of a more general phenomenon: there is a correspondence between certain second order parabolic equations and solutions of stochastic ordinary differential equations [3]. Using the computed value of $p(x,t)$, we can simulate sample paths of a Brownian motion on the real line: the following animation displays the evolution of $100$ Brownian particles without control:





We now set up the optimal control problem in CasADi:

%% optimal control problem

opti = casadi.Opti();
Y = opti.variable(Nx,Nt); % state variable
U = opti.variable(Nx,Nt); % control variable


We specify the system dynamics, discretizing the Fokker-Planck equation using central differences for the spatial derivatives and a forward Euler scheme for the time derivative:

%% system dynamics

for n = 1 : Nt-1
    for j = 2 : Nx-1
        term1 = k*(Y(j+1,n)-2*Y(j,n)+Y(j-1,n));
        term2 = b*Y(j,n)*(U(j+1,n)-U(j-1,n));
        term3 = b*U(j,n)*(Y(j+1,n)-Y(j-1,n));
        opti.subject_to(Y(j,n+1) == Y(j,n) + term1 - term2 - term3);
    end
end


We now set the initial condition and zero flux boundary conditions as constraints:

%% initial conditions and zero flux boundary conditions

% initial condition
opti.subject_to(Y(:,1) == y0); 

% zero flux boundary conditions
for n = 2 : Nt
    opti.subject_to(Y(Nx,n) == Y(Nx-1,n)/(1-dx*U(Nx,n)));
    opti.subject_to(Y(1,n) == Y(2,n)/(1+dx*U(1,n)));
end


We set the constraints on the control, taking $a = 2$:

%% admissible control constraints

opti.subject_to(-2&amp;lt;=U(:)&amp;lt;=2);


We declare the cost functional:

%% cost functional

cost = 0;

% running cost
for n = 1 : Nt 
    for i = 1 : Nx
        cost = cost + (x_line(i)-ref(n))^2*Y(i,n);
    end
end

% terminal cost
for i = 1 : Nx 
    cost = cost + (x_line(i)-ref(n))^2*Y(i,Nt);
end

% control cost
for n = 1 : Nt % control cost
    for i = 1 : Nx
        cost = cost + Y(i,n)*U(i,n)^2;
    end
end


We solve the optimization problem using the IPOPT software:

%% solution of the optimization problem

% set optimization objective
opti.minimize(cost);

% solution of the optimization problem
p_opts = struct('expand',true);
s_opts = struct('max_iter',1000); 
opti.solver('ipopt',p_opts,s_opts); 

tic
sol = opti.solve(); 
toc


Obtaining the following display:

This is Ipopt version 3.12.3, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:    10448
Number of nonzeros in inequality constraint Jacobian.:     1600
Number of nonzeros in Lagrangian Hessian.............:     6204

Total number of variables............................:     3200
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:     1600
Total number of inequality constraints...............:     1600
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:     1600
        inequality constraints with only upper bounds:        0

Number of Iterations....: 39

                                   (scaled)                 (unscaled)
Objective...............:  7.2472498957747769e+002   9.6893349411152292e+002
Dual infeasibility......:  1.0060574595627259e-010   1.3450657609300798e-010
Constraint violation....:  1.1102230246251565e-016   1.1102230246251565e-016
Complementarity.........:  2.5059036929760477e-009   3.3503108849024674e-009
Overall NLP error.......:  2.5059036929760477e-009   3.3503108849024674e-009


Number of objective function evaluations             = 40
Number of objective gradient evaluations             = 40
Number of equality constraint evaluations            = 40
Number of inequality constraint evaluations          = 40
Number of equality constraint Jacobian evaluations   = 40
Number of inequality constraint Jacobian evaluations = 40
Number of Lagrangian Hessian evaluations             = 39
Total CPU secs in IPOPT (w/o function evaluations)   =      1.062
Total CPU secs in NLP function evaluations           =      0.047

EXIT: Optimal Solution Found.
      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval
       nlp_f  |   3.00ms ( 75.00us)   3.00ms ( 75.00us)        40
       nlp_g  |  14.00ms (350.00us)  13.99ms (349.85us)        40
  nlp_grad_f  |   5.00ms (121.95us)   5.00ms (121.90us)        41
  nlp_hess_l  |  10.00ms (256.41us)  10.01ms (256.74us)        39
   nlp_jac_g  |  15.00ms (365.85us)  15.98ms (389.78us)        41
       total  |   1.11 s (  1.11 s)   1.11 s (  1.11 s)         1
Elapsed time is 1.561797 seconds.


The following pictures display the temporal evolution of the controlled solution. The solution follows an oscillatory pattern similar to the one given by the reference trajectory:


  
      
        
      
      
        
      
  


Again, by the correspondence between second order parabolic equations and solutions to stochastic ordinary differential equations, the solution $p(x,t)$ to equation (2) is the probability density of a brownian particle on the real line that is subject to the velocity field $u(x,t)$. We use the values of $p(x,t)$ that we have just computed to simulate sample paths of this controlled brownian motion: the following animation displays the evolution of $100$ Brownian particles subject to the control $u(x,t)$:




References

[1] Hannes Risken, Till Frank. The Fokker-Planck Equation: Methods of Solution and Applications, Second Edition. Springer-Verlag Berlin Heidelberg, 1996

[2] Roy, S., Annunziato, M., Borzì, A., and Klingenberg, C. (2018). A Fokker–Planck approach to control collective motion. Computational Optimization and Applications, 69(2), 423-459.

[3] Stroock, Daniel W., Varadhan, S.R.S. Multidimensional Diffusion Processes. Springer-Verlag Berlin Heidelberg, Reprint of the 1997 Edition (Grundlehren der mathematischen Wissenschaften, Vol. 233).

</description>
        <pubDate>Thu, 19 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0013</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0013</guid>
        
        
        <category>tutorial</category>
        
        <category>WP05</category>
        
      </item>
    
      <item>
        <title>Inverse design for the one-dimensional Burgers equation</title>
        <description>The problem

We consider the following one-dimensional Burgers equation



where $u$ is the state, $u_0$ is the initial state and  the flux function $f$ is defined by $f(u)=\frac{u^2}{2}$. Kruzkov’s theory  provides existence and uniqueness of a  solution  of \eqref{eq} with initial datum $u_0 \in L^{\infty}(\mathbb R)$. This solution is called a weak-entropy solution, denoted by $(t,x) \to S_t^+(u_0)(x)$. For a given target function $u^T$, we introduce the backward entropy  solution $(t,x) \to S^-_{t}(u^T)(x)$  as follows: 
for every $t\in [0,T]$, for a.e $x\in \mathbb R$,



We study the problem of inverse design for \eqref{eq}. This problem consists in  identifying the set of initial data evolving to a given target at a final time.

Due to the time-irreversibility of the Burgers equation, some target functions are unattainable from weak-entropy solutions of this equation, making the inverse problem under consideration ill-posed. To get around this issue, we introduce the following  optimal control problem



where $u^T$ is a given target function and the class of admissible initial data $\mathcal{U}^0_{\text{ad}}$ in \eqref{opt2} is defined by



Above,  stands for functions of bounded variation and  $C&amp;gt;0$ is a constant large enough. The study of \eqref{opt2} is motivated by the minimization of the sonic boom effects generated by supersonic aircrafts [2].

To solve the optimal control problem \eqref{opt2}, some difficulties arise from a  theoretical  and  numerical point of view.

  Since the  entropy solution $u$ of \eqref{eq} may contain shocks even if the initial datum is a smooth function, this generates important added difficulties that have been the object of intensive study in the past, see  [3,4] and the references therein. In particular, the authors make sense of the derivative of $J_0$ in \eqref{opt2} in a weak way by requiring  strong conditions on the set of initial data. This leads to require that entropy solutions of \eqref{eq} have a finite number of non-interacting jumps.
  When $J_0$ is weakly differentiable,  gradient descent  methods have been implemented in [1,5,6] to solve numerically the optimal problem \eqref{opt2}. In the cases where it was applied successfully, only one possible initial datum emerges, namely the backward entropy solution $S_T^-(u^T)$. This is mainly due to the numerical viscosity that numerical schemes introduce to gain stability. To find some multiple minimizers, the authors in  [8]  use a filtering step in the backward adjoint solution.


Dans [9], we fully characterize the set of minimizers of the optimal control problem \eqref{opt2}.

Theorem 1.  Let $u^T\in BV(\mathbb R)$. The optimal control problem \eqref{opt2}  admits multiple optimal solutions. Moreover, for a.e $T&amp;gt;0$, the initial datum $u_0\in BV(\mathbb R)$ is an optimal solution of \eqref{opt2} if and only if $u_0 \in BV(\mathbb R)$ verifies $S_T^+(u_0)=S_T^+ (S_T^-(u^T))$.

A characterisation of the set  is given in [7]. An illustration of Theorem 1. is given in Figure 1.


Figure 1: The backward-forward  solution $S_T^+(S_T^-(u^T))$ is the projection of $u^T$ onto the set of attainable target functions. The shaded area in red at time $t=0$ represents the set of minimizers of \eqref{opt2} 

The proof of Theorem 1 is structured as follows. From [7, Theorem 3.1, Corollary 3.2] or [8, Corollary 1], there exists $u_0\in BV(\mathbb R)$ such that  if and only if  satisfies  the one-sided Lipschitz condition, i.e 

 Thus, the optimal problem \eqref{opt2} can be rewritten as  follows.



where the admissible set $\mathcal{U}^T_{\text{ad}}$ is defined by



Above, $K_1$ an open bounded interval large enough.  Note that the optimal problem \eqref{opt5} is not related to the PDE model \eqref{eq}. We prove that $q=S_T^+ (S_T^-(u^T))$ is a critical point of \eqref{opt5} using the first-order optimality conditions applied to \eqref{opt5} and the full characterization of the set  given in [9, Theorem A.2].

Numerical simulations

In [9,Section 3], we  implement a wave-front tracking algorithm to construct numerically the set of  minimizers of \eqref{opt2}.  We consider for instance, a target function   defined by



From Theorem 1,  the backward solution  is an  optimal solution of \eqref{opt2} and   is an optimal solution of \eqref{opt2} if and only if  . In Figure 2, the target function , the backward solution  and  the backward-forward solution  are plotted.



    
        
        
        
        
        
        
    
    
        
        $x\to S^{-}_T(u^T)(x)$ 
        
        
        $(t,x)\to S^{+}_t(S^{-}_T(u^T))(x)$ 
         
    




$u^T$  and $\color{red}{x\to S^{+}_T(S^{-}_T(u^T))(x)}$ 
$ $
Figure 2. Plotting of the target function $u^T$ defined in \eqref{uT}, the optimal solution $S_T^-(u^T)$ and the backward-forward solution $\color{red}{S^{+}_T(S^{-}_T(u^T))}$.

Note that  has four different shocks located at $x=1.1$, $x=3.1$, $x=5.3$ and $x=7.2$. If we use a conservative numerical method as Godunov scheme,  the approximate solution of  doesn’t have shocks because of numerical viscosity that numerical schemes introduced, see Video 1.



    
        
            
        
        
            
        
    


Video 1. Approximate solution of $S_T^+(u_0)$ with $u_0$ an $N$-wave constructed with $ \color{red}{\text{a wave-front tracking algorithm}}$ and $\color{blue}{\text{a Godunov scheme}}$ 

This implies that only one minimizer of \eqref{opt2} can be constructed using a Godunov scheme, which is the backward entropy solution $S_T^-(u^T)$. When a wave-front tracking algorithm is implemented, the approximate solution of $S_T^+(S_T^-(u^T))$ has shocks since we track the possible discontinuities from $u^T$ to  $S_T^+(S_T^-(u^T))$. This implies that all initial data $u_0$ that coincide with the approximate solution of $S_T^+ (S_T^-(u^T))$ can be recovered, see [9,Section 3].

In Video 2, we show that the weak-entropy solution of \eqref{eq}  with initial data $S_T^-(u^T)$ coincides with $S_T^+ (S_T^-(u^T))$ at time $T$.


Video 2. Approximate solution of $(t,x) \to S_t^+(S_T^-(u^T))(x)$  using a wave-front tracking algorithm. 

In Video 3, three other approximate optimal solutions $u_0$ of \eqref{opt2} are constructed. In particular, we show that  $S_T^+ (u_0)=S_T^+ (S_T^-(u^T))$.



    
        
            
        
        
            
        
    

    
                
            
    
    



Video 3. Three approximate optimal solutions of \eqref{opt2} constructed using a wave-front tracking algorithm 

[1] Navid Allahverdi,  Alejandro Pozo and Enrique Zuazua. Numerical aspects of large-time optimal control of Burgers equation. ESAIM: Mathematical Modelling and Numerical Analysis, 50 (5):1371-1401,2016.

[2]  Navid Allahverdi,  Alejandro Pozo and Enrique Zuazua. Numerical aspects of sonic-boom minimization. A panorama of Mathematics: Pure and Applied, 658:267,2016.

[3] François Bouchut and François James. One-dimensional transport equations with discontinuous coefficients. Nonlinear Analysis, 32(7):891,1998.

[4] Alberto Bressan and Andrea Marson. A maximum principle for optimally controlled systems of conservation laws. Rendiconti del Seminario Matematico della Universita di Padova, 94:79-94, 1995.

[5] Carlos Castro, Francisco Palacios and Enrique Zuazua. An alternating descent method for the optimal control of the inviscid Burgers equation in the presence of shocks. Mathematical Models and Methods in Applied Sciences, 18(03):369-416,2008.

[6] Carlos Castro, Francisco Palacios and Enrique Zuazua. Optimal control and vanishing viscosity for the Burgers equation. In Integral Methods in Science and Engineering, Volume 2, pages 65-90. Springer, 2010.

[7] Rinaldo Colombo and Vincent Perrollaz. Initial data identification in conservation laws and Hamilton-Jacobi equations. arXiv preprint arXiv:1903.06448,2019.

[8] Laurent Gosse and Enrique Zuazua. Filtered gradient algorithms for inverse design problems of one-dimensional Burgers equation. In Innovative algorithm and analysis, pages 197-227. Springer, 2017.

[9] Thibault Liard and Enrique Zuazua. Inverse design for the one-dimensional Burgers equation. Submitted (2019).
</description>
        <pubDate>Thu, 12 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0006</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0006</guid>
        
        
        <category>tutorial</category>
        
        <category>WP04</category>
        
      </item>
    
      <item>
        <title>Optimal Control Problem with CasADi on null-controllability of the network system</title>
        <description>This code needs the installation of CasADi 3.4.5: https://web.casadi.org/get/

The objectives of this post are twofold, one is to introduce CasADi (with IpOpt) to simulate optimal control problem, and the other is to introduce the concept of the structural controllability, as an example, for the 2D heat equation.

Controllability of the 2D heat equation

In this post, we simulate structural controllability for the two-dimensional heat equation. First, we start with the finite difference scheme of the 2D Heat equation and the control on one boundary of the square domain $[0,1]^2$.



A similar problem has been treated in another DyCon Blog post using AMPL and IpOpt, which deals with the one-dimensional fractional heat equation under positivity constraints. Here we use CasADi and IpOpt in Matlab language.

We will consider the problem of steering the initial datum:



to the final target $(1.5 \cdot \bar z_{i,j}(T))$, where $\bar z_{i,j}(T)$ is a reference solution from $z^0_{i,j}$ without control.

Problem formulation

Parameters for the problem:

N_size = 4; %% Space discretization for 1D
Nx = N_size^2; %% Space discretization for 2D
Nt = 20; %% Time discretization
T = 0.1; %% Final time

%% Discretization of the Space
xline_ = linspace(0,1,N_size+2);
[xmsf,ymsf] = meshgrid(xline_,xline_);
xline = xline_(2:end-1);
[xms,yms]   = meshgrid(xline,xline);

dx = xline(2) - xline(1);

%% Initial data
Y0_2d = zeros(N_size);
for i=1:N_size
    for j=1:N_size
        Y0_2d(i,j) = sin(xline(i)*pi)*sin(xline(j)*pi);
    end
end
Y0 = Y0_2d(:);


%% Definition of the dynamics : Y' = AY+BU
B = zeros(N_size^2,N_size); B(1:N_size,1:N_size) = eye(N_size); %% control for i=1,...,N_size.

A1_mat = ones(N_size,1);
A2_mat = spdiags([A1_mat -2*A1_mat A1_mat], [-1 0 1], N_size,N_size);
I_mat  = speye(N_size);
A_mat  = kron(I_mat,A2_mat)+kron(A2_mat,I_mat);

A = A_mat; %% A: Discrete Laplacian in 2D with uniform squared mesh

%% Discretization of the time : we need to check CFL condition to change 'Nt'.
tline = linspace(0,T,Nt+1); %%uniform time mesh

dt = tline(2)-tline(1);


The interactions between nodes (grid points) can be displayed as follows:

options_plot_graphs = {'LineWidth',2,'DisplayName','off','NodeColor','r','ArrowSize',9,'MarkerSize',7,'NodeLabel',{}};
p = plot(digraph(A),'XData',xms(:)','YData',yms(:)',options_plot_graphs{:});
hold on
plot(xms(:,1),yms(:,1),'b.','MarkerSize',30) %% Blue dots are controlled nodes
xlabel('x-axis')
ylabel('y-axis')
grid on
for i=1:N_size.^2
    text(p.XData(i)+0.01, p.YData(i)+0.02, num2str(i), 'FontSize', 20);
end




Fig 1. The interaction network of 'A_mat'. The controlled nodes are colored blue.

Now we may simulate the reference trajectory without control.

%% Simulation of the uncontrolled trajectory
M = eye(Nx) - 0.5*dt/dx.^2*A;
L = eye(Nx) + 0.5*dt/dx.^2*A;
P = 0.5*dt*B;

Y = zeros(Nx,Nt+1);

Y(:,1) = Y0;
for k=1:Nt %% loop over time intervals
   %% Crank-Nicolson method without control
   Y(:,k+1) = M\L*Y(:,k);
end
YT = Y(:,Nt+1);

ratio = 1.5;
Y1 = ratio*YT; %% Target data

clf
Z = reshape(Y(:,1),N_size,N_size);
Z = [zeros(1,N_size+2) ; zeros(N_size,1), Z, zeros(N_size,1) ; zeros(1,N_size+2)];
isurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.3);
isurf.CData = isurf.CData*0 + 10;
hold on
Z = reshape(Y(:,end),N_size,N_size);
Z = [zeros(1,N_size+2) ; zeros(N_size,1), Z, zeros(N_size,1) ; zeros(1,N_size+2)];
jsurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.7);
jsurf.CData = jsurf.CData*0 + 1;
jsurf.Parent.Color = 'none';
lightangle(10,10)
legend({'Initial Condition','Final Data'})



Fig 2. The initial condition and the final data of uncontrolled dynamics.

Optimization problem

From now on, we use CasADi to consider an exact control problem.

opti = casadi.Opti();  %% CasADi function

%% ---- Input variables ---------
X = opti.variable(Nx,Nt+1); %% state trajectory
U = opti.variable(N_size,Nt+1);   %% control

%% ---- Dynamic constraints --------
for k=1:Nt %% loop over control intervals
   %% Crank-Nicolson method : this helps us to boost the optimization
   opti.subject_to(M*X(:,k+1)== L*X(:,k) + 0.5*P*(U(:,k)+U(:,k+1)));
end

%% ---- State constraints --------
opti.subject_to(X(:,1)==Y0);
opti.subject_to(X(:,Nt+1)==Y1);

%% ---- Optimization objective  ----------
Cost = (dx*sum(sum(U.^2))*(T/Nt));
opti.minimize(Cost); %% minimizing L2 over time

%% ---- initial guesses for solver ---
opti.set_initial(X, Y);
opti.set_initial(U, 0);

%% ---- solve NLP              ------
p_opts = struct('expand',true);
s_opts = struct('max_iter',10000); %% iteration limitation

opti.solver('ipopt',p_opts,s_opts); %% set numerical backend
tic
sol = opti.solve();   %% actual solve
toc


This is Ipopt version 3.12.3, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:     2752
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:       84

Total number of variables............................:      420
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:      352
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  0.0000000e+00 6.69e-02 0.00e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  1.6511358e+02 6.66e-16 7.31e-07  -2.5 8.68e+01    -  1.00e+00 1.00e+00h  1
   2  1.6511358e+02 6.66e-16 2.39e-12  -8.6 5.47e-09    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 2

                                   (scaled)                 (unscaled)
Objective...............:   1.6511358437684962e+02    1.6511358437684962e+02
Dual infeasibility......:   2.3874235921539366e-12    2.3874235921539366e-12
Constraint violation....:   6.6613381477509392e-16    6.6613381477509392e-16
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   4.0210221040688533e-13    2.3874235921539366e-12


Number of objective function evaluations             = 3
Number of objective gradient evaluations             = 3
Number of equality constraint evaluations            = 3
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 3
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 2
Total CPU secs in IPOPT (w/o function evaluations)   =      0.822
Total CPU secs in NLP function evaluations           =      0.000

EXIT: Optimal Solution Found.
               t_proc [s]   t_wall [s]    n_eval
       nlp_f      1.9e-05      1.9e-05         3
       nlp_g     0.000103     0.000105         3
  nlp_grad_f      3.7e-05      3.4e-05         4
  nlp_hess_l      1.4e-05      1.3e-05         2
   nlp_jac_g     0.000185     0.000195         4
      solver         1.09        0.676         1
Elapsed time is 0.757156 seconds.



Post-processing

Sol_x = sol.value(X); %% solved controlled trajectory
Sol_u = sol.value(U); %% solved control function

clf
Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = reshape(Sol_x(:,end),N_size,N_size);
isurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.3);
isurf.CData = isurf.CData*0 + 10;
hold on
Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = reshape(Y(:,end),N_size,N_size);
jsurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.7);
jsurf.CData = jsurf.CData*0 + 1;

Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = ratio*reshape(Y(:,end),N_size,N_size);
plot3(xmsf,ymsf,Z,'k*')

jsurf.Parent.Color = 'none';
lightangle(10,10)

legend({'Controlled final data','Uncontrolled final data','Target'})




Fig 3. The final data of controlled and uncontrolled dynamics. The controlled data coinside with the target points.

%% Free and controlled dynamics in animation

Result_ref = zeros(N_size+2,N_size+2,Nt+1); %% displaying variable
Result_ref(2:end-1,2:end-1,:) = reshape(Y(:,:),[N_size,N_size,Nt+1]);

Result_con2d = zeros(N_size+2,N_size+2,Nt+1); %% displaying variable
Result_con2d(2:end-1,2:end-1,:) = reshape(Sol_x(:,:),[N_size,N_size,Nt+1]);
%% Free dynamics
fig = figure;
isurf2= surf(ratio*Result_ref(:,:,end),'FaceAlpha',0.3);
isurf2.CData = isurf2.CData*0 + 1;
hold on
isurf = surf(Result_ref(:,:,1),'FaceAlpha',0.7);
isurf.CData = isurf.CData*0 + 10;
title('Free dynamics')
legend('Target','Solution')
zlim([-0.5 1.5])
pause;
for it = 1:Nt+1
   isurf.ZData =  Result_ref(:,:,it);
    pause(0.1)
end
%% Controlled dynamics
clf
fig = figure;
isurf2= surf(ratio*Result_ref(:,:,end),'FaceAlpha',0.3);
isurf2.CData = isurf2.CData*0 + 1;
hold on
isurf = surf(Result_con2d(:,:,1),'FaceAlpha',0.7);
isurf.CData = isurf.CData*0 + 10;
title('Controlled dynamics')
legend('Target','Solution')
zlim([-0.5 1.5])
pause;
for it = 1:Nt+1
   isurf.ZData =  Result_con2d(:,:,it);
    pause(0.1)
end



   
      
         
      
      
         
      
   


Fig 4-5. Animations for the free and controlled dynamics. The target surface is also drawn in both dynamics, where free dynamics goes below than the target.

Structural controllability of the 2D heat equation

For the second part, we simulate another linear system to check the structural controllability of the 2D heat equation. It is known that its interacting network is structurally controllable by one sole node.

The following matrix ‘AS_mat’ links the nodes in a line, for example, 1-2-3-6-5-4-7-8-9 for $N=3$, which is a part of interactions in ‘A_mat’:

AC_mat = diag(ones(N_size-1,1),-1);
for j=1:2:N_size-2
    AC_mat = blkdiag(AC_mat,diag(ones(N_size-1,1),1));
    AC_mat(end,end-N_size)=1;
    if N_size==2
        break
    end
    AC_mat = blkdiag(AC_mat,diag(ones(N_size-1,1),-1));
    AC_mat(end-N_size+1,end-2*N_size+1)=1;
end
if length(AC_mat) &amp;lt; (N_size.^2)
    AC_mat = blkdiag(AC_mat,diag(ones(N_size-1,1),1));
    AC_mat(end,end-N_size)=1;
end

AS_mat = (AC_mat + AC_mat') - 2*eye(Nx);

options_plot_graphs = {'LineWidth',2,'DisplayName','off','NodeColor','r','ArrowSize',9,'MarkerSize',7,'NodeLabel',{}};
p = plot(digraph(AS_mat),'XData',xms(:)','YData',yms(:)',options_plot_graphs{:});
xlabel('x-axis');ylabel('y-axis')
hold on
plot(xms(1,1),yms(1,1),'b.','MarkerSize',30) %% Blue dots are controlled nodes
for i=1:N_size.^2
    text(p.XData(i)+0.01, p.YData(i)+0.02, num2str(i), 'FontSize', 20);
end

title('Network')
grid on




Fig 6. The interaction network of the new matrix 'AS_mat'. The controlled nodes are colored blue.

Since the 1D heat equation is controllable, ‘AS_mat’ is controllable by one node. However, it gets more and more difficult as the number of nodes increases, since it has different scale with the standard 1D heat equation. The length of the 1D domain grows as $N$ since it eventually become space filling curve in $[0,1]^2$.

Note also that ‘AS_mat’ has the nonzero elements in the positions that ‘A_mat’ has. By deleting several interactions of ‘A_mat’, ‘AS_mat’ is now exactly controllable with smaller controlled nodes. This is the idea of the structural controllability in the network system, called ‘network control’.

Problem formulation

B = zeros(N_size^2,1); B(1) = 1;
A = N_size.^2*AS_mat;
%% Y' = AY + BU

T = 0.1;
Nt = 30;
tline = linspace(0,T,Nt+1); %%uniform time mesh
dt = tline(2)-tline(1);

%% Simulation of the uncontrolled trajectory
M = eye(Nx) - 0.5*dt/dx.^2*A;
L = eye(Nx) + 0.5*dt/dx.^2*A;
P = 0.5*dt*B;

Y = zeros(Nx,Nt+1);
Y(:,1) = Y0;
for k=1:Nt %% loop over time intervals
   %% Crank-Nicolson method without control
   Y(:,k+1) = M\L*Y(:,k);
end
YT = Y(:,Nt+1);
Y1 = ratio*YT;


Optimization problem in CasADi

opti = casadi.Opti();  %% CasADi function

%% ---- Input variables ---------
X = opti.variable(Nx,Nt+1); %% state trajectory
U = opti.variable(1,Nt+1);   %% control

%% ---- Dynamic constraints --------
for k=1:Nt %% loop over control intervals
   %% Crank-Nicolson method
   opti.subject_to(M*X(:,k+1)== L*X(:,k) + P*(U(:,k)+U(:,k+1)));
end

%% ---- State constraints --------
opti.subject_to(X(:,1)==Y0);
opti.subject_to(X(:,Nt+1)==Y1);

%% ---- Optimization objective  ----------
Cost = (sum(U.^2)*(T/Nt)); %%1e3*dx^2*sum(sum((X(:,Nt+1)-Y1).^2))+;
opti.minimize(Cost); %% minimizing L2 at the final time

%% ---- Initial guess ----
opti.set_initial(X, Y);
opti.set_initial(U, 0);

%% ---- solve NLP              ------
p_opts = struct('expand',true);
s_opts = struct('max_iter',1e5); %% cut down the algorithm at the 1000-th iteration.
opti.solver('ipopt',p_opts,s_opts); %% set numerical backend
tic
sol = opti.solve();   %% actual solve
toc


This is Ipopt version 3.12.3, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:     2852
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:       31

Total number of variables............................:      527
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:      512
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  0.0000000e+00 1.04e-01 0.00e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  2.9522421e+04 1.33e-15 6.25e-02  -2.5 1.08e+03    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 1

                                   (scaled)                 (unscaled)
Objective...............:   2.9522420557910038e+04    2.9522420557910038e+04
Dual infeasibility......:   6.2500000000000000e-02    6.2500000000000000e-02
Constraint violation....:   1.3322676295501878e-15    1.3322676295501878e-15
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   1.4002321948103652e-12    6.2500000000000000e-02


Number of objective function evaluations             = 2
Number of objective gradient evaluations             = 2
Number of equality constraint evaluations            = 2
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 2
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 1
Total CPU secs in IPOPT (w/o function evaluations)   =      0.516
Total CPU secs in NLP function evaluations           =      0.000

EXIT: Optimal Solution Found.
               t_proc [s]   t_wall [s]    n_eval
       nlp_f      6.2e-05      1.4e-05         2
       nlp_g     0.000212       0.0001         2
  nlp_grad_f      4.3e-05      2.9e-05         3
  nlp_hess_l      3.2e-05      3.3e-05         1
   nlp_jac_g     0.000147     0.000148         3
      solver        0.668        0.573         1
Elapsed time is 0.638270 seconds.


Post-processing

Sol_x = sol.value(X); %% solved controlled trajectory
Sol_u = sol.value(U); %% solved control
%%Sol_x = opti.debug.value(X);
%%Sol_u = opti.debug.value(U); %% final data if algorithm stops with error

%%
clf
Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = reshape(Sol_x(:,end),N_size,N_size);
isurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.3);
isurf.CData = isurf.CData*0 + 10;
hold on
Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = reshape(Y(:,end),N_size,N_size);
jsurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.7);
jsurf.CData = jsurf.CData*0 + 1;

Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = ratio*reshape(Y(:,end),N_size,N_size);
plot3(xmsf,ymsf,Z,'k*')

jsurf.Parent.Color = 'none';
lightangle(10,10)

legend({'Controlled final data','Uncontrolled final data','Target'})




Fig 7. The initial condition and the final data of uncontrolled dynamics. It has a different structure compared to Fig 2.

%% Free and controlled dynamics in animation

Result_ref = zeros(N_size+2,N_size+2,Nt+1); %% displaying variable
Result_ref(2:end-1,2:end-1,:) = reshape(Y(:,:),[N_size,N_size,Nt+1]);

Result_con2d = zeros(N_size+2,N_size+2,Nt+1); %% displaying variable
Result_con2d(2:end-1,2:end-1,:) = reshape(Sol_x(:,:),[N_size,N_size,Nt+1]);

fig = figure;
isurf2= surf(ratio*Result_ref(:,:,end),'FaceAlpha',0.3);
isurf2.CData = isurf2.CData*0 + 1;
hold on
isurf = surf(Result_ref(:,:,1),'FaceAlpha',0.7);
isurf.CData = isurf.CData*0 + 10;
title('Free dynamics')
legend('Target','Solution')
zlim([-0.5 1.5])
pause;
for it = 1:Nt+1
   isurf.ZData =  Result_ref(:,:,it);
    pause(0.1)
end

%%
clf

fig = figure;
isurf2= surf(ratio*Result_ref(:,:,end),'FaceAlpha',0.3);
isurf2.CData = isurf2.CData*0 + 1;
hold on
isurf = surf(Result_con2d(:,:,1),'FaceAlpha',0.7);
isurf.CData = isurf.CData*0 + 10;
title('Controlled dynamics')
legend('Target','Solution')
zlim([-0.5 1.5])
pause;
for it = 1:Nt+1
   isurf.ZData =  Result_con2d(:,:,it);
    pause(0.1)
end


   
      
         
      
      
         
      
   

Fig 8-9. Animations for the free and controlled dynamics. The target surface is also drawn in both dynamics, where free dynamics goes below than the target.
</description>
        <pubDate>Thu, 07 Nov 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp06/P0006</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp06/P0006</guid>
        
        
        <category>tutorial</category>
        
        <category>WP06</category>
        
      </item>
    
      <item>
        <title>Movil control strategy for models with memory terms</title>
        <description>En este tutorial enseñaremos como implentar la estrategía del control interíor móvil para la ecuación del calor. En el ejemplo típico de control interior en la ecuación del calor se pretende llevar al sistema desde un estado inicial, $u_0$ hasta el estado nulo en todo el espacio, $\Omega$. Para ello se define una subconjunto, $\omega \in \Omega$, donde el control, $f(x,t)$ puede actuar, es decir que para puntos, $x \notin \omega$, el control es cero. Este problema se puede escribir como:



Donde $f$ es el control definido de solo en el subconjunto, $\omega \in \Omega$.

Es conocido que la controlabilidad de la ecuación del calor para todo tiempo esta asegurada, sin embargo en el caso de la ecuación del calor con términos de memoria este resultado no es válido. En este caso, eligiremos un problema con un término de memoria: $\int_0^t u(x,\tau)d\tau$. De esta forma el problema se puede escribir como:



Este resultado se puede vercuenado aplicamos un control LQR sobre ambos sistemas. El mínimo del funcional LQR en el primer sistema (Equation \ref{heatinterior}) estabiliza la dínamica mientras que el mínimo del funcional en el segundo caso queda muy lejos del equilibrio.




    
        
          
             
           
        
        
          
             
           
        
    
    
        
          
              Video 1: LQR in Heat equation (Equation \ref{heatinterior})
           
        
        
          
              Video 2:  LQR in Heat equation with memory (Equation \ref{heatinterior_memory})
           
        
     
    
        
          
              Podemos ver la evolucion de dos modelos, con un región de control, $\chi_{\omega}$, situado en la posición del elipsoide azul en la parte superior de la simulación. Podemos ver que el control LQR es eficaz para la ecuación del calor, sin embargo débil ante la presencia de término de memoria
           
        
     


En el articulo [1], se menciona la idea del control móvil de ….
….
….

Definición del función característica dependiente del espacio

Nuestro objetivo en esta sección es la construcción de una función que dado un punto, $\textbf{x} \in \Omega$, devuelva la función carácteristica correspondiente. Para el diseño de la función $\chi_{\omega(t)}$, se ha decidido que ni el tamaño, ni la orientación de $\omega$ cambia en el tiempo. De esta forma, una vez fijados el tamaño en las dos direcciones del espacio y la forma del subconjunto, obtenemos una función que solo depende de un punto $x\in \Omega$.

En esta simulación crearemos el subconjunto como un cuadrado que puede moverse en $\Omega$. este cuadrado se puede construir con una función $W(x)$ definida de la siguiente manera.



donde $\Theta(x)$ es la fución theta de heaviside. Dado que la función $\Theta(x)$, tiene una aproximación analítica, la función $W(x,a,b)$ puede ser suavizada, detalle que será de vital importancia para que se pueda calcular el gradiente de la restrición asociada a la dinámica cunado realizamos el problema de control óptimo.

Un representación gráfica de $W(x,a,b)$ permiter reconocer a esta función con valor unidad entre los valores $a$ y $b$ y nulo fuera de ellos.


  
    
      
    
  
  
    
      Figure 1: Representación gráfica de $W(x,a,b)$
    
  


La generalización de esta función en dos dimensiones en inmediata,



De esta forma dado $(x_{min}, x_{max}, y_{min}, y_{max})$, obtenemos la función característica dependiente solo de la posición de un solo punto.


  
    
       
    
  
  
    
      Video 3: Representación gráfica de  $W_{2D}$
    
  


Construcción de la dinámica

Para el sistema con memoria (Equation \ref{heatinterior_memory}), podemos introducir una nueva variable, $z(x,t)$ tal que:



De esta manera el sistema con memoria se convierte en un sistema acoplado de PDEs:



Dado que $\chi_{\omega}$ puede moverse, y ademas que queremos obtener la trayectoria óptima para el control móvil añadiremos al sistema una partícula que puede moverse en dos dimensiones, su posición vendrá denotada por, $\textbf{d} = (d_x,d_y)$, y su velocidad, $\textbf{v} = (v_x,v_y)$. Además añadiremos un control $\textbf{g}(t) = (g_x(t),g_y(t))$ que actuará como una fuerza que moverá el subconjunto $\chi_{\omega}$.

Entonces, el sistema total queda como:



Numerical Implementation

En este tutorial necesitaremos DyCon Toolbox, y CasADi. Dado que CasADi es una dependecia de DyCon Toolbox, podemos instalarlo de la siguiente forma

unzip('https://github.com/DeustoTech/DyCon-Computational-Platform/archive/master.zip')
addpath(genpath(fullfile(cd,'DyCon-toolbox-master'))
StartDyconPlatform


Podemos escribir la ecuación \ref{heatinterior_memory_z_all}, en su forma discreta:



Creamos las variables de mesh

% Create the mesh variables
clear;
Ns = 7;
Nt = 15;
xline = linspace(-1,1,Ns);
yline = linspace(-1,1,Ns);
[xms,yms] = meshgrid(xline,yline);


Creamos la matriz A, que contiene el laplaciano en 2D y la dinámica del control movil

A  = FDLaplacial2D(xline,yline);

Atotal = zeros(2*Ns^2+4,2*Ns^2+4);
%
Atotal( 1:Ns^2  , 1:Ns^2 ) = A;
%
Atotal( Ns^2+1 : 2*Ns^2   ,   1    :  Ns^2   )  =  eye(Ns^2);
Atotal(    1   :  Ns^2    , Ns^2+1 : 2*Ns^2  )  =  50*eye(Ns^2); % z = 50*y

RumbaMatrixDynamics = [0 0 1 0; ...
                       0 0 0 1; ...
                       0 0 0 0; ...
                       0 0 0 0 ];

             
Atotal(2*Ns^2+1:end,2*Ns^2+1:end) = RumbaMatrixDynamics;
Atotal = sparse(Atotal);


Greamos la función $B(\textbf{d}) = B(x_d,y_d)$
%%
% We create the B() function 
xwidth = 0.3;
ywidth = 0.3;
B = @(xms,yms,xs,ys) WinWP05(xms,xs,xwidth).*WinWP05(yms,ys,ywidth);
Bmatrix =  @(xs,ys) [diag(reshape(B(xms,yms,xs,ys),1,Ns^2)) ;zeros(Ns^2)];




Optimal Control Problem





opti = casadi.Opti();  % CasADi optimization structure

% ---- Input variables ---------
Ucas = opti.variable(2*Ns^2+4,Nt+1); % state trajectory
Fcas = opti.variable(Ns^2+2,Nt+1);   % control

% ---- Dynamic constraints --------
dUdt = @(y,f) Atotal*u+ [Bmatrix(u(end-3),u(end-2))*f(1:end-2) ; ...
                                         0                     ; ...
                                         0                     ; ...
                                     f(end-1)                  ; ...
                                     f(end)                    ]; 

% -----Euler backward method-------
for k=1:Nt % loop over control intervals
   y_next = Ucas(:,k) + (T/Nt)*dUdt(Ucas(:,k+1),dUdt(:,k+1)); 
   opti.subject_to(Ucas(:,k+1)==y_next); % close the gaps
end

% ---- State constraints --------
opti.subject_to(Ucas(:,1)==[Y0 ; 0.7 ; 0.7; -1.5 ; -1.5]);

% ---- Optimization objective  ----------
Cost = (Ucas(1:end-4,Nt+1))'*(Ucas(1:end-4,Nt+1));

opti.minimize(Cost); % minimizing L2 at the final time

% ---- initial guesses for solver ---
opti.set_initial(Ucas, Unum_free);
opti.set_initial(Fcas, 0);

% ---- solve NLP              ------
p_opts = struct('expand',false);
s_opts = struct('acceptable_tol',1e-4,'constr_viol_tol',1e-3,'compl_inf_tol',1e-3);
opti.solver('ipopt',p_opts,s_opts); % set numerical backend
tic
sol = opti.solve();   % actual solve
toc


Mvil Control



  
    
       
    
  



Video 3



</description>
        <pubDate>Mon, 04 Nov 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0011</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0011</guid>
        
        
        <category>tutorial</category>
        
        <category>WP05</category>
        
      </item>
    
  </channel>
</rss>
