<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DyCon Blog</title>
    <description>Welcome to the web interface of DyCon Toolbox, the computational platform developed within the &lt;a href='https://cmc.deusto.eus/dycon/' target='_blank'&gt;ERC DyCon - Dynamic Control&lt;/a&gt; project.</description>
    <link>https://deustotech.github.io/DyCon-Blog/</link>
    <atom:link href="https://deustotech.github.io/DyCon-Blog/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 30 Jul 2019 08:47:11 +0200</pubDate>
    <lastBuildDate>Tue, 30 Jul 2019 08:47:11 +0200</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>Uniform exponential and polynomial stability and approximation in control of a thermoelastic model</title>
        <description>The main objective of this blog is to explain numerically the difference between exponential and polynomial decay in term of energy and spectral properties. We Show also that system with polynomial decay are very  sensitive to the choice of initial data.

Model Problem

We consider the numerical approximation of the following coupled thermoelastic wave models





where $u(x,t)$ is the displacement (longitudinal or transverse, depending upon the application) at position $x$ along a bounded smooth domain $\Omega\subset\mathbb{R}$ and time $t$ , and $\theta(x,t)$ is the temperature deviation from the reference temperature at position $x$ and time $t$, $u_0(x)$, $v_0(x)$ and $\theta_0(x)$ are initial data in a suitable space. The small positive constant $\gamma$ is a thermo-mechanical coupling parameter and is generally small in comparison to 1. System (\ref{eq1}) differs from system $\eqref{eq2}$ at the coupling terms, where we have replaced the strong coupling ($\gamma\theta_x$ and $\gamma u_{tx}$) by a weak coupling ($\gamma\theta$ and $\gamma u_{t}$).

It is well known from literature that system (\ref{eq1}) and (\ref{eq2}) are respectively exponentially and polynomially stable, see [3,7] and [5,6,9].

In this post, we will show by numerical experiments, how the coupling terms affect quantitative and qualitative properties of thermoelastic systems (\ref{eq1}) and (\ref{eq2}). These results could be found in [8,10].

To do this, we consider a semi discretization version of both systems (\ref{eq1}) and (\ref{eq2}), obtained with finite element method, which has the following form



where for all $n\in\mathbb{N}$, $z_n=(u_n,v_n,\theta_n)^T$ is the semi discrete solution, $z_{n0}$ is the discretized initial data, $A_{i,n}$ the discretized dynamic and the subscript $\cdot_i$ refers to system (\ref{eq1}) and (\ref{eq2}) with



and $F_{2,n}=I_n$,



Spectral properties of thermoelastic systems

Figure 1 and Figure 2 show how the coupling terms affect the placement of eigenvalues of the dynamic $A_{n}$. In Figure 1, we see that a uniform distance between the eigenvalues and the imaginary axis is preserved, see Table 1. Another observation is that for fixed $n$, the eigenvalues of higher frequency modes, in particular, the one of the $n^{th}$ mode, are closer to the imaginary axis. Moreover, as the number of modes increases, these eigenvalues bend back towards the vertical line $\lambda=-\frac{\gamma^2}{2}$, a fact which has been already shown in [4]. Therefore, the corresponding spectral element approximation scheme preserves the property of exponential stability.



 Location of the complex eigenvalues of the matrix $A_{1,n}$ with the finite element method

error
Nx = 30;
stabexpsem(Nx);


Error using error
Not enough input arguments.

Error in tp1d0d1572_49d1_41a8_914f_f09a199a8ec3 (line 114)
error



In Figure 2, conversely to Figure 1 where a uniform distance between the eigenvalues and the imaginary axis is preserved, we observe that, as the number of modes increases, an asymptotic behaviour appears in the neighborhood of the imaginary axis at $\pm\infty$. This property is mainly related to systems with polynomial decay, see \cite{BEPS2006}.

 Location of the complex eigenvalues of the matrix $A_{2,n}$ with the finite

Nx = 30;
stabpolysem(Nx);


Uniform and polynomial decay of the energy

The discrete energy associated to system (\ref{eq3}) is given by



The discrete energy $E_{1,n}$ associated to system (ref{eq1}) decays exponentially to zero, see Figure 3, in the following sense: $\exists M,\alpha$ positive constants such that



However, the introduction of the weak coupling term in system (ref{eq1}) has changed the dynamic and consequently the behavior of energy (\ref{eq4}). In this case, we say that system (\ref{eq2}) decays polynomially to zero, see Figure 4, in the following sense: $\exists M,\alpha$ positive constants such that



 Exponential decay of $E_{1,n}(t)$

 Polynomial decay of $E_{2,n}(t)$

Effect of smoothness of the initial data on the rate of decay of energy

It has been shown theoretically, see [1,2], that the energy associated to system (\ref{eq2}) is very sensitive to the smoothness of its initial data. This fact, has been also observed numerically, see Figure 6. we use

Nx = 100;
FinalTime = 100;
dt = 0.5;
mode = 1;
Gamma = 0.2;
n = 100;
k= 2;


and we consider the following initial data

u0=zeros(1,n);
x = linspace(0,pi,100);
v0=sqrt(2/pi)*sin(k*x);
teta0=zeros(1,n);


Through Figure 6, we notice that for $j = 1$, the approximate energy $E_{2,n}(t)$ decays to zero as the time $t$ increases. Moreover, we observe that the decay rate depends strongly on $j$. That is, when $j$ increases, initial data are very oscillating. We say in this case that the rate of decay of the discrete energy $E_{2,n}(t)$ is very sensitive to the choice of the initial data. However, the behavior of the energy assosiated to system (\ref{eq1}) remains indifferent to the smoothness of initial data when $n\to\infty$, see Figure 5.

  Exponential decay of $E_{1,n}(t)$

  Polynomial decay of $E_{2,n}(t)$

To obtain the previous figures, one need only to execute the following

script:

[u,v,theta,Et] = data_effect_exp(FinalTime,dt,Nx,mode,Gamma);
%% AniThermalDisplacement(u,v,theta,Et)


[u,v,theta,Et] = p1energyfem(FinalTime,dt,Nx,mode,Gamma);
%% AniThermalDisplacement(u,v,theta,Et)


References

[1] A. B' atkai, K.J. Engel, J. Pr&quot;uss and R. Schnaubelt, Polynomial stability of operator semigroups, Math. Nachr. 279, pp.

[2] A. Borichev and Y. Tomilov, Optimal polynomial decay of functions and operator semigroups, Math. Ann., 347(2), pp.455-478, 2010.

[3] S. W. Hansen, Exponential energy decay in a linear thermoelastic rod. J. Math. Anal. Appli.,167, pp. 429-442, 1992.

[4] F.A. Khodja, A. Benabdallah, and D. Teniou, Stability of coupled systems, Abstr. Appl. Anal. Volume 1, Number 3, 327-340, 1996.

[5] F. A. Khodja, A. Benabdallah and D. Teniou, Dynamical stabilizers and coupled systems}, ESAIM Proceeding,2, pp. 253-262, 1997.

[6] F. A. Khodja, A. Bader and A. Benabdallah, Dynamic stabilization of systems via decoupling techniques, ESAIM: COCV,4,

[7] Z. Liu and S. Zheng, Exponential stability of semigroup associated with thermoelastic system, Quart. Appl. Math, 51, pp.535-545, 1993.

[8] Z. Y. Liu and S. Zheng, Uniform exponential stability and approximation in control of a thermoelastic system, SIAM J. Control Optim. 32, pp. 1226-1246, 1994.

[9] Z. Liu and B. Rao, Characterization of polynomial decay rate for the solution of linear evolution equation. Zeitschrift  angewandte Mathematik und Physik ZAMP,56, pp. 630-644, 2005.

[10] L. Maniar and S. Nafiri, Approximation and uniform polynomial stability of C_0-semigroups,ESAIM: COCV 22, pp. 208-235, 2016.

</description>
        <pubDate>Thu, 18 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/P0030</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/P0030</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>Controllability to steady states of a reaction diffusion system and emergence of barriers.</title>
        <description>asda
</description>
        <pubDate>Mon, 08 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0028</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0028</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>Analysis, numerics and control for the obstacle problem</title>
        <description>In this tutorial, we present some aspects of the obstacle problem in the stationary (elliptic) and the evolutionary (parabolic) setting by means of numerical simulations, performed in FEniCS and Matlab.




 Figure 1. The solution (blue) of the one-dimensional elliptic obstacle problem is superharmonic (concave down) and matches derivatives with the obstacle (black). 


1. Mathematical formulation

1.1. Elliptic problem
Let $\Omega \subset \mathbb{R}^d$ be open, regular and bounded, let $\psi \in H^2(\Omega)$ (the obstacle) and $g \in H^1(\Omega)$ (boundary data) with $\psi \leq g$ on $\partial \Omega$ be given. We consider the functional



where $f \in L^2(\Omega)$ is given, and the closed convex set



The classical obstacle problem can be written as



and admits a unique minimizer $\phi \in \mathcal{K}^g_{\text{OB}}$, which is also a solution of the variational inequality



The terminology “obstacle problem” comes from the physical origin of the model $-$ the solution $\phi$ represents the equilibrium position of an elastic membrane, which is constrained to lie above an obstacle (given by the graph of the function $\psi$).

Notation:  The notation



designates the Gateaux derivative ($L^2$-gradient) of the functional ${F}_{\text{OB}}$ at the point $\phi$ in the direction $\zeta$; in occurence,



Most of the regularity theory for the obstacle problem has been developed for the model case $\Delta \psi=-1$. We refer to [3,4] for a detailed presentation. 
For simplicity of the presentation, let us thus assume for a moment that $f \equiv -1$ and $\psi \equiv 0$. Choosing appropriate test functions bring us from the variational inequality for $\phi$ to



The set ${ \phi=0 }$ is called contact set, while $\partial { \phi&amp;gt;0 }$ is the free boundary.



 The solution $\phi$ to the elliptic obstacle problem just above. 


Remark: At this point, we may see why solving the elliptic obstacle problem is different to just solving the Poisson equation for $\phi$ in a subdomain of $\Omega$ and setting $\phi=\psi$ elsewhere. Indeed, solving the latter problem does not guarantee that we would have



along the boundary.

1.2. Parabolic problem

The parabolic counterpart onsists in finding $u \in H^1(]0, +\infty[; L^2(\Omega))\cap L^2(]0,+\infty[; H^2(\Omega) \cap \mathcal{K}^g_{\text{OB}})$ satisfying



The name “parabolic obstacle problem” for the above system may be misleading. 
While the mathematical formulation is similar, the physical interpretation of the elliptic and parabolic problem is different. In the parabolic setting, seeing $\psi$ as a physical obstacle in space is not correct. Rather, one should interpret $\psi$ as a barrier for the temperature $u$. More accurately, we are dealing with a parabolic variational inequality with an obstacle-type constraint.

The function $\psi$ may be time-dependent, but for simplicity we omit this case.











 Figure 2. Here $\psi(x)=3*\sqrt{(1-x^2)}$ in $(-1,1)$ (black) is a barrier for the evolving solution (blue). The initial data coincides with $\psi$ on (-1.5, 1.5). We observe that the contact set $\{ u = \psi \}$ changes (gets smaller) as time grows. There is also matching of normal derivatives on the contact points (i.e. the free boundary). 
Finally, the solution of the parabolic problem (left, blue) converges to that of the elliptic problem (right, red) for large time, as seen below.   

For $\psi \equiv 0$ and $f\equiv-1$ (or more generally $f + \Delta \psi = -1$), a manifestation of the parabolic variational inequality above is as a “weak form” of the one-phase Stefan problem (see [3,4]). In this setting, we may pass from the variational inequality to the equivalent problem with two boundary conditions at the free boundary



This is an overdetermined problem, which means that the free boundary/the contact set ${u=0}$ has to change with time to ensure that both BC hold for every time. The evolution of the contact set may be observed in the numerics of Figures 2,3,4.

Remark: $\quad$
As for the elliptic problem, solving the above parabolic problem is different to just solving the heat equation for $u$ in a subdomain of $\Omega$ and setting $u$ elsewhere, with a Dirichlet boundary condition. Indeed, solving the latter problem does not guarantee that we would have $|\nabla u|= 0$ along the boundary.

Remark: $\quad$
While in Figure 2 the contact set is shrinking does not disappear, it may happen that the contact set vanishes (depending on the magnitude of the boundary data $g$, the support of the initial data $u_0$, and if present, the source term $f$).

1.3. Relationship between both problems

In the recent paper [5], it is shown that the solution $u(t)$ to the parabolic variational inequality converges to the solution $\phi$ of the elliptic probelem in $H^1(\Omega)$ norm as $t\rightarrow \infty$ with exponential rate. This is done by means of new techniques including a so-called constrained Lojaseiwicz inequality.

We may observe this convergence numerically in Figures 3 and 4. In both cases, we work in the ball $B_2$, with boundary data $g\equiv 0.8$, barrier $\psi\equiv 0$ and 
initial datum supported outside $B_{1.5}$.

The one-dimensional case:









Figure 3. The solution of the parabolic problem (left, blue) converges to that of the elliptic problem (right, red) as time increases. We again see that the contact set $\{ u = 0\}$ changes with time. 

The two-dimensional case:



  






Figure 4. We see that as time increases, the contact region $\{ u = 0\}$ (white patch) gets smaller. In terms of the Stefan problem, the white patch represents the ice temperature. Ice is melting as time increases, but does not fully melt, because the support of the initial data is too small and the temperature on the boundary is not high enough.  

2. Numerical implementation

2.1. Possible strategies

A common approach for proving the well-posedness and $W^{2,p}$ regularity for variational inequalities is a technique called penalization, which consists of approximating by a sequence of semilinear equations [8]. For any $\epsilon&amp;gt;0$, we will consider



to approximate the parabolic problem, and remove $u’$ and time dependence for the elliptic one. As $\epsilon\rightarrow0$, the solution $u_\epsilon$ of the above equation converges to the variational inequality.  Here



may be replaced by another penalty function, for instance $\beta_\epsilon(u) = -\exp(-u/\epsilon)$.

The approximated problem is relatively simple to implement numerically. We may use finite elements (say $P1$ elements) to discretize in space, and time-stepping (Euler implicit for instance) to discretize in time.

There are other ways to solve the variational inequality after discretizing in space and time (using one’s favorite metood). One which is popular in the literature for the elliptic problem is the primal dual active set method, which we will present in a future post.

2.2. Code

i). Elliptic problem.

Let us start by solving the two-dimensional elliptic problem from Figure 4.

The fenics module [1] contains all of the necessary finite element tools for the space discretization of PDEs.

from fenics import *
from obstacles import dome
from mshr import mesh

It is advantageous to regularize the “kink” appearing in penalty function (the negative part of a function) in view of using a Newton method for solving the nonlinear problem

def smoothmax(r, eps=1e-4): 
	return conditional(gt(r, eps), r-eps/2, conditional(lt(r, 0), 0, r**2/(2*eps)))

We mesh the domain $B_2$.

mesh = generate_mesh(Circle(Point(0, 0), 2), 25)


$P1$ elements are used for the FEM spaces (but one may easily choose higher order in the definition of V).

V = FunctionSpace(mesh, &quot;CG&quot;, 1)
w = Function(V)
v = TestFunction(V)
psi = Constant(0.)
f = Constant(-1)		
eps = Constant(pow(10, -8))


Using the symbolic expressions of FEniCS, we define the variational formulation of the penalized PDE, which we write in the form $F(w)=0$:

bc = DirichletBC(V, 0.8, &quot;on_boundary&quot;)
F = dot(grad(w), grad(v))*dx - 1/eps*inner(smoothmax(-w+psi), v)*dx - f*v*dx


We solve the nonliner problem with the command solve, which makes use of a Newton method to solve the nonlinear equation $F(w)=0$.

solve(F == 0, w, bcs=bc)


We visualise in ParaView by storing the solution in .vtk format using:
vtkel = File(&quot;output/el.pvd&quot;)
vtkel &amp;lt;&amp;lt; w


ii). Parabolic problem.

We set $T=2$, use $100$ subdivisions and set

dt = T/100


This part only differs by the presence of a time-loop. We define the initial datum in a separate class:

class indata(Expression):
	def eval(self, value, x):
		if sqrt(x[0]*x[0]+x[1]*x[1]) &amp;lt;= 1.95:
			value[0] = 0
		elif 1.95 &amp;lt;= sqrt(x[0]*x[0] + x[1]*x[1]) &amp;lt;= 2:
			value[0] = (sqrt(x[0]*x[0]+x[1]*x[1])-1.95)/(2-1.95)*0.8
		else:
			value[0] = 0.8


Repeating as in the elliptic case up to defining the variational form, we now set the inital datum (interpolating the expression onto the FEM space) and time:

un = interpolate(indata(degree=2), V)
t = 0

We set up the time loop:

vtksol = File(&quot;output/popsol.pvd&quot;)
for n in range(num_steps):
    t+=dt
    solve(F==0, u, bcs=bc)
    vtksol &amp;lt;&amp;lt; (u, t)
    un.assign(u) 


Optimal Control

We will now briefly present the implementation of an optimal control strategy for the elliptic and parabolic problems. We will make use of the penalized problems where $\epsilon&amp;gt;0$ is small (of the order $10^{-8}$). This strategy has been succesfully applied in [8].

3.1. Elliptic problem

Given a target $\phi_d$ and a regularization parameter $\delta&amp;gt;0$ (we usually use $\delta = 10^{-2}$), we seek to minimize



subject to



For simplicity of the presentation, we will consider







on the domain $\Omega = [-2,2]^2$. The target is the function $\phi_d(x) = \frac12(\cos(x_1)+\cos(x_2))$.

The uncontrolled solution of the elliptic obstacle problem in this case is:





The FEniCS optimization code will have the effect of obtaining the following results.



	

	
	
	
	















Figure. The optimal state (top left) may be seen to satisfy the obstacle constraint, and takes the shape of the target (bottom left). 

Let us present the numerical implementation. After importing the dolfin_adjoint optimization module [2], we make use of the code for simulating the uncontrolled problem. A “tape” of the forward model is built. This tape is used to drive the optimization by repeatedly solving the forward model and the adjoint model for varying control inputs.

Defining the objective functional to be minimized:

delta = Constant(1e-2)
j = assemble(0.5*inner(w-wd, w-wd)*dx + delta/2*inner(u, u)*dx)	
m = Control(u)


Writing the state $y$ as the output of the solution map corresponding to the input $m$, one sees that the objective functional depends only on the control:

J = ReducedFunctional(j, m)									


We run the optimization, based on a conjugate-gradient method:

u_opt = minimize(J, options={&quot;method&quot;=&quot;CG&quot;})


The tape is modified such that the initial guess for y (to be used in the Newton solver in the forward problem) is set to y_opt.

y_opt = y.block_variable.saved_output
Control(y).update(y_opt)


The algorithm converged after 8 iterations, and the value of the functional at the final iteration is $0.0967$.

3.2. The parabolic problem

Given a final time $T&amp;gt;0$, a target $u_d$ and a regularization parameter $\delta&amp;gt;0$, we seek to minimize



subject to



For simplicity of the presentation, we will consider the same setting as in Figure 3, namely $f\equiv-1\,$,  $g\equiv0.8\,$, on the domain $\Omega = [-2,2]$. The target temperature is $u_d(x) = 0.8$. This would correspond to “melting”, as this target is never equal to zero, thus has no contact set. We would thus expect the action of the control $v$ to lift-up $u$ from $0$ and thus the contact set (and free boundary) to vanish.

We appeal to DyCon-Toolbox [9] for the numerical implementation of this problem. DyCon-Toolbox is an efficient and easy to use solver for nonlinear control problems.



The optimal state (left, red), starting from an initial datum with a non-empty contact set (left, blue) and the optimal control (red, right). 


The action and magnitude of the control ensures that the solution to the parabolic problem will lift-off from the initial contact set. 
For comparison, we recall that the uncontroled free dynamics have a very different behavior:





We begin by symbolically defining the time variable:
syms t


We discretize the interval $[-2, 2]$:
N = 70;
xi = -2; xf = 2;
xline = linspace(xi,xf,N+2);
xline = xline(2:end-1);

We define symbolically (as in FEniCS) the state vector $Y$ and control vector $U$:
Y = SymsVector('y',N);
U = SymsVector('u',N);

We discretize by finite differences, and define the semilinear penalty term:
alpha = 1e-3;
epsilon = 1e-2;
A = FDLaplacian(xline);

F  = @(Y) NonLinearTerm(Y,alpha);
dF = @(Y) DiffNonLinearTerm(Y,alpha);


We may define the parabolic problem to be solved.
dx = xline(2) - xline(1);
Y_t = @(t,Y,U,Params) A*Y + 1/epsilon*F(-Y) + U + (1/dx^2)*[0.8;zeros(N-2,1);0.8];
Dyn = pde(Y_t,Y,U);

We set the mesh, and other relevant parameters such as the final time and initial data. We consider the same data as in the free problem.

Dyn.mesh   = xline;
Dyn.Solver = @ode23;
Dyn.Nt     = 150;
Dyn.FinalTime        = 0.3;
Dyn.InitialCondition = InitialConditionFcn(xline);


We now compute the necessary Jacobian matrices.

Dyn.Derivatives.Control.Num = @(t,Y,U,Params) eye(N);
Dyn.Derivatives.State.Num   = @(t,Y,U,Params) A + 1/epsilon*dF(-Y);


We may solve the free problem over the given time interval. We recall that we have used finite differences to discretize in space (but finite elements can be used as well in more complicated settings), and the underlying solve command solves the system of ODEs by means of some Runge-Kutta scheme.

[tspan,Ysolution] = solve(Dyn);
figure
surf(Ysolution)

Having solved the free dynamics, we are now in a position to solve the optimal control problem:

YT = 0.8 + 0*xline';
beta = dx^4;
Psi  = @(T,Y) dx*(YT - Y).'*(YT - Y);
L    = @(t,Y,U)  dx*(YT - Y).'*(YT - Y) + ...
                 beta*dx*0.5*alpha*(U.'*U);
OCP = Pontryagin(Dyn,Psi,L);
U0 = -ones(Dyn.Nt,Dyn.ControlDimension);
U0 = GradientMethod(OCP,U0,'Graphs',true,'EachIter',2,'DescentAlgorithm',@AdaptativeDescent)


References:

[1] The FEniCS Project Version 1.5
M. S. Alnaes, J. Blechta, J. Hake, A. Johansson, B. Kehlet, A. Logg, C. Richardson, J. Ring, M. E. Rognes and G. N. Wells
Archive of Numerical Software, vol. 3, 2015.

[2] Patrick E. Farrell, David A. Ham, Simon W. Funke and Marie E. Rognes (2013). Automated derivation of the adjoint of high-level transient finite element programs, SIAM Journal on Scientific Computing 35.4, pp. C369-C393. doi:10.1137/120873558. arXiv:1204.5577

[3] Figalli A. (2018), Free boundary regularity in obstacle problems 
Journées EDP 2018, to appear.

[4] Figalli, A. (2018), Regularity of interfaces in phase transitions via obstacle problems 
Proceedings ICM 2018, to appear.

[5] Colombo M. and Spolaor, L. and Velichkov, B. (2018), On the asymptotic behavior of the solutions to parabolic variational inequalities, ArXiV preprint.

[6] Borjan Geshkovski (2018). Obstacle Problems: Theory and Applications. Master Thesis.

[7] Hintermüller M. and Kopacka I., A smooth penalty approach and a nonlinear multigrid algorithm for elliptic MPECs. Computational Optimization and Applications, 50(1):111–145, 2011.

[8] D. Kinderlehrer and G. Stampacchia. An introduction to variational inequalities and their applications. Volume 31 of Classics in Applied Mathematics. SIAM, 2000.

[9] DyCon-Toolbox, https://deustotech.github.io/dycon-toolbox-documentation/.

</description>
        <pubDate>Mon, 08 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp03/WP03-P0031</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp03/WP03-P0031</guid>
        
        
        <category>tutorial</category>
        
        <category>WP03</category>
        
      </item>
    
      <item>
        <title>Rotors imbalance suppression by optimal control</title>
        <description>Consider a rotor rotating around a fixed axis. Because of wear and damage, the mass distribution is not homogeneous. This leads to dangerous vibrations in the rotation. A prototypical example can be a wind turbine, affected by misalignment of the blades and/or mass imbalance of the hub and blades [2].

In order to compensate the imbalance, two balancing heads are mounted at the endpoints of the axle, as in figure 1. Each balancing head is made of two masses free to rotate.

Our goal is to determine the optimal movement of the balancing masses to minimize the vibrations. Control theoretical techniques are employed. For further details, see [6].

 Figure 1: representation of the rotor and the balancing. The balancing heads are located at the endpoints of the spindle. The four balancing masses (two for each balancing head) are drawn in red. 

Consider a rotor-fixed reference frame $(O;(x,y,z))$. Figures 1 and 2 show a front view of the device and a scheme of the balancing heads. 

Figure 2: front view of the system made of rotor and balancing device. 

Figure 3: scheme of one balancing head. The balancing masses $(m_i,P_{i,1})$ and $(m_i,P_{i,2})$ are drawn in red. The bisector of the angle generated by $\overset{\longrightarrow}{OP_{i,1}}$ and $\overset{\longrightarrow}{OP_{i,2}}$ is the dashed line. The *intermediate* angle $\alpha_i$ is represented in 3(A), while the *gap* angle $\gamma_i$ is depicted in 3(B). The angles $\alpha_i$ and $\gamma_i$ give the position of the balancing masses in each balancing head. 

We consider two planes



orthogonal to the rotation axis $z$. The balancing device (see figures 1 and 2) is made of two heads lying in each of these planes.

The heads are fixed to the rotor and rotate with it. In particular, $\alpha_i$ and $\gamma_i$ are defined with respect to the rotor-fixed reference frame $(O;(x,y,z))$.

Each head is made of a pair of balancing masses, which are free to rotate orthogonally to the rotation axis $z$.

Namely, we have

  two mass-points $(m_1,P_{1,1})$ and $(m_1,P_{1,2})$ lying on $\pi_1$ at distance $r_1$ from the axis $z$, i.e., in the reference frame $(O;(x,y,z))$





  two mass-points $(m_2,P_{2,1})$ and $(m_2,P_{2,2})$ lying on $\pi_2$ at distance $r_2$ from the axis $z$, namely, in the reference frame $(O;(x,y,z))$




For any $i=1,2$, let $b_i$ be the bisector of the angle generated by $\overset{\longrightarrow}{OP_{i,1}}$ and $\overset{\longrightarrow}{OP_{i,2}}$ (see figure 3). The intermediate angle $\alpha_i$ is the angle between the $x$-axis and the bisector $b_i$, while the gap angle $\gamma_i$ is the angle between $\overset{\longrightarrow}{OP_{i,1}}$ and the bisector $b_i$.

The imbalance is modelled by a resulting force $F$ and a momentum $N$ orthogonal to the rotation axis. In the rotor-fixed reference frame $(O;(x,y,z))$, set $P_1 :=  (0,0,-a)$, $P_2 :=  (0,0,b)$, $F :=  (F_x,F_y,0)$ and $N :=  (N_x,N_y,0)$. By imposing the equilibrium condition on forces and momenta, the force $F$ and the momentum $N$ can be decomposed into a force $F_1$ exerted at $P_1$ contained in plane $\pi_1$ and a force $F_2$ exerted at $P_2$ contained in $\pi_2$.

In each plane, we generate a force to balance the system, by moving the balancing masses:

  in the plane $\pi_1$, we compensate $F_1$ by the centrifugal force:





  in the plane $\pi_2$, we compensate $F_2$ by the centrifugal force:




The overall imbalance of the system is then given by the resulting forces in $\pi_1$ and $\pi_2$,



and



respectively.

The overall imbalance on the system made of rotor and balancing device is measured by the imbalance indicator



Our task is to find a control strategy such that

  the balancing masses move from their initial configuration $\Phi_0$ to a final configuration $\overline{\Phi}$, where the imbalance is compensated;
  the imbalance and velocities should be kept small during the correction process.


We address the minimization problem



where $Q(\Phi) :=  G(\Phi)-\inf G$ and



with .

The theoretical analysis of the above problem is in [6]. The existence of the optimum is proved. The stabilization of the optimal trajectories towards steady optima is proved in any condition.

Simulation

In order to perform some numerical simulations, we firstly discretize our cost functional and then we run AMPL-IPOpt to minimize the resulting discretized functional.

For the purpose of the numerical simulations, it is convenient to rewrite the cost functional as



subject to the state equation



Discretization
Choose $T$ sufficiently large and $Nt \in \mathbb{N} \setminus {0,1}$. Set



The discretized state is  , whereas the discretized control (velocity) is $(\psi_{i})_{i=0, … ,Nt-2}$. The discretized functional then reads as



subject to the state equation



Execution

The discretized minimization problem is



We address the above minimization problem by employing the interior-point optimization routine IPOpt (see [3,4]) coupled with AMPL [1], which serves as modelling language and performs the automatic differentiation. The interested reader is referred to [8, Chapter 9] and [7] for a survey on existing numerical methods to solve an optimal control problem.

In figures 4, 5, 6 and 7, we plot the computed optimal trajectory for \eqref{functional}, with initial datum $\Phi_0=\left(\alpha_{0,1},\gamma_{0,1};\alpha_{0,2},\gamma_{0,2}\right) :=  \left(2.6,0.6, 2.5,1.5\right)$. We choose $F$, $N$ and $m_i$. The exponential stabilization proved in [6] emerges. 

Figure 4: intermediate angle $\alpha_1$ versus time. 

Figure 5: gap angle $\gamma_1$ versus time. 

 Figure 6: intermediate angle $\alpha_2$ versus time. 
In figure 8, we depict the imbalance indicator versus time along the computed trajectories. As expected, it decays to zero exponentially.

Figure 7: gap angle $\gamma_2$ versus time. 

 Figure 8: system response. 



 Figure 9: We represent the evolution in time of the rotor vibrations.
In the uncontrolled case, the balancing device does not act. In the controlled case, our balancing strategy suppress the vibrations. 

References:
[1] Robert Fourer, David M Gay, and Brian W Kernighan. A modeling language for mathematical programming. Management Science, 36(5):519{554, 1990.

[2] Mike Jeffrey, Michael Melsheimer, and Jan Liersch. Method and system for determining an imbalance of a wind turbine rotor, September 11 2012. US Patent 8,261,599.

[3] Andreas Waechter, Carl Laird, F Margot, and Y Kawajir. Introduction to ipopt: A tutorial for downloading, installing, and using ipopt. Revision, 2009.

[4] Andreas Waechter and Lorenz T Biegler. On the implementation of an interior-point lterline-search algorithm for large-scale nonlinear programming. Mathematical programming, 106(1):25{57, 2006.

[6] Matteo Gnuffi, Dario Pighin and Noboru Sakamoto. Rotors imbalance suppression by optimal control. Preprint.

[7] Noboru Sakamoto and Arjan J van der Schaft. Analytical approximation methods for the stabilizing solution of the Hamilton-Jacobi equation. IEEE Transactions on Automatic Control, 53(10):2335{2350, 2008.

[8] Emmanuel Trélat. Contrôle optimal : théorie et applications
Mathématiques Concrètes. Vuibert, Paris, 2005. available
online:
https://www.ljll.math.upmc.fr/trelat/chiers/livreopt2.pdf.
</description>
        <pubDate>Mon, 08 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp02/P0005</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp02/P0005</guid>
        
        
        <category>tutorial</category>
        
        <category>WP02</category>
        
      </item>
    
      <item>
        <title>Propagation of one and two-dimensional discrete waves under finite difference approximation</title>
        <description>In [1], we discuss several aspects of wave propagation in a computational
framework. In particular, we consider the following one-dimensional wave equation



and we discuss the propagation properties of its finite-difference solutions on uniform and non-uniform grids, by establishing comparisons with the usual behavior of the continuos waves.

Our approach is based on the study of the propagation of high-frequency Gaussian beam solutions (that is, solutions originated from highly concentrated and oscillating initial data), both in continuous and
discrete media.

Roughly speaking, the idea at the basis of this techniques is that the energy of Gaussian beam solutions propagates along bi-characteristic rays, which are obtained from the Hamiltonian system associated to the
symbol of the operator under consideration.

At the continuous level of equation \eqref{main_eq_1d}, these mentioned rays are straight lines and travel with a uniform velocity.

On the other hand, the finite difference space semi-discretization of \eqref{main_eq_1d} may introduce different dynamics, with a series of unexpected propagation properties at high frequencies. For instance, one can generate spurious solutions traveling at arbitrarily small velocities which, therefore, show lack of propagation in space.

In addition, the introduction of a non-uniform mesh for the discretization may generate further pathologies such as internal
reflections, meaning that the waves change direction without hitting the boundary.

In order to illustrate these mentioned pathological phenomena, we perform simulations on a uniform space-mesh of $N$ points and mesh-size $h=2/(N+1)$



and on two non-uniform ones produced by applying to $\mathcal G_h$ the transformations



Moreover, the initial data are constructed starting from the following Gaussian profile



Low frequency simulations

We present in Figure 1 our simulations for low-frequency solutions of \eqref{main_eq_1d}. In particular, we considered initial position and frequency $(x_0,\xi_0)=(0,\pi/4)$ and a time horizon $T=5s$.

In this case, the numerical solutions behave basically like the continuous ones: they start traveling to the left along the straight characteristic line $x+t$ and, after having hit the boundary, they reflect following the Descartes-Snell’s law and continue propagating, this time to the right along the other branch of the characteristic ($x−t$).


Figure 1. Numerical solutions of \eqref{main_eq_1d} with $(x_0,\xi_0)=(0,\pi/4)$ on uniform and non-uniform meshes.

High frequency simulations

When increasing the frequency, the situation changes and we encounter several interesting phenomena and pathologies:

• The so-called umklapp or U-process, also known as internal reflection, consisting in the reflection of waves without touching only one or both the endpoints of the space interval. This phenomenon is typical for the semi-discretization of high-frequecncy solutions of \eqref{main_eq_1d} on non-uniform meshes, which may produce waves oscillating in the interior of the computational domain and reflecting without touching the boundary (see Figure 2 - middle) or touching the boundary only at one of the endpoints (see Figure 2 - right).


Figure 2. Numerical solutions of \eqref{main_eq_1d} with $(x_0,\xi_0)=(1/2,\pi)$ on uniform and non-uniform meshes.

• Non-propagating waves, corresponding to equilibrium (fixed) points on the phase diagram (see Figure 3).


Figure 3. Numerical solutions of \eqref{main_eq_1d} with $(x_0,\xi_0)=(0,\pi)$ on uniform and non-uniform meshes.

These phenomena are related with the particular nature of the discrete group velocity which, in the finite difference setting, is given by



and vanishes for $\xi = (2k+1)\pi$, $k\in\mathbb{Z}$. Moreover, they can be understood by looking at the phase portrait of the hamiltonian system associated to the finite difference semi-discretization of \eqref{main_eq_1d} (see Figure 4).


Figure 4. Phase portrait of the Hamiltonian system for the numerical wave equation corresponding to the and the grid transformation $g_1$ (left) and $g_2$ (right).

In particular, the solutions displayed in Figure 2 correspond to
trajectories which remain always in the red area of these phase portraits, while Figure 3 shows solutions starting from the equilibrium point $(0,\pi)$ (the green one in Figure 4)

Notice that, for the grid transformation $g_1$, this equilibrium point is a center (stable) while it is a saddle (unstable) for the grid transformation $g_2$. For this reason, in the first case the non-propagating wave remains concentrated along the vertical ray, while in the second case the wave presents more very dispersive features.

Two-dimensional simulations

Analogous phenomena can be detected also in the case of the finite-difference semi-discretization of the two-dimensional wave equation



Also in this case, we perform simulations on  a uniform mesh of $N$ points both in the $x$ and $y$ direction and mesh-sizes $h_x=2/(N+1)=h_y$



and on two non-uniform ones produced by applying to $\mathcal G_h$ the transformations $g_1$ and $g_2$ above introduced.

Moreover, the initial data are constructed once again starting from a Gaussian profile:



Then, it can be observed in Video 1 that, as for the one-dimensional case, at low frequencies the solution remains concentrated and propagates along straight characteristics which reach the boundary, where there is reflection according to the Descartes-Snell’s law. This independently on whether we use a uniform or a non-uniform mesh.







Video 1. Numerical solutions of \eqref{main_eq_2d} with $(x_0,y_0,\xi_0,\eta_0)=(0,0,\pi/4,\pi/4)$ on uniform and non-uniform meshes.

Nevertheless, increasing the frequencies similar phenomena as in the one-dimensional case show up. For instance, on the non-uniform mesh corresponding to the transformation $g_1$, we observe the so-called
rodeo effect, according to which, waves that should propagate along straight lines are trapped along closed circles (Video 2 - middle).




Video 2. Numerical solutions of \eqref{main_eq_2d} with $(x_0,y_0,\xi_0,\eta_0)=(0,\tan(\arccos(\sqrt[4]{1/2},\pi/2,\pi)$ on uniform and non-uniform meshes.

Finally, waves starting from the point $(x_0,y_0,\xi_0,\eta_0)=(0,0,\pi,\pi)$, which is an equilibrium for the phase Hamiltonian system, cannot move, and remain trapped around the point $(0,0)$ in the physical plane for any time (see Video 3).




Video 3. Numerical solutions of \eqref{main_eq_2d} with $(x_0,y_0,\xi_0,\eta_0)=(0,0,\pi,\pi)$ on uniform and non-uniform meshes.

Conclusions

Summarizing, our analysis shows that the finite-difference semi-discretization of one and two-dimensional waves may modify the dynamics of the continuous model. In particular, as a result of the accumulation of the local effects introduced by the heterogeneity of the employed grid, numerical high-frequency solutions can bend in a singular and unexpected manner. Moreover, this phenomenon has to be added to the well known numerical dispersion effect, producing the high-frequency discrete group velocity to vanish, even in uniform grids.
Our results constitute a warning both for adaptivity and for the treating of control and inverse problems. In broad terms, the goal of adaptivity is to refine a mesh on the support of the solution, keeping it coarse where the solution has little oscillations and energy. Our analysis shows that, in this context, adaptivity has to be performed with some attention. Indeed, if one is not careful enough when refining the mesh, they can be produced spurious effects due to the fact that waves feel the fictitious numerical boundaries that are generated when the grid passes from fine to coarse. Finally, our results are also a signal that the dangers of uniform meshes in the study of numerical control and inverse problems (already observed in [2]) may be enhanced when the mesh is non-uniform. In more details, the heterogeneity of the grid may introduce added trapping effects, which need to be avoided in
order to prove convergence in the context of controllability, stabilization or inversion algorithms.

References

[1] U. Biccari, A. Marica and E. Zuazua, Propagation of one and two-dimensional discrete waves under finite difference approximation. Submitted

[2] E. Zuazua, Propagation, observation, control and numerical approximation of waves. SIAM Rev. 47, 2 (2005), 197-243.

</description>
        <pubDate>Wed, 26 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0023</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0023</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>Sparse sources identification through adjoint localization algorithm</title>
        <description>Model Problem

We consider the numerical approximation of the inverse problem for the linear advection-diffusion equation,



with $d$ being the diffusivity of the material and $v$ the direction of the advection.

Given a final time $T&amp;gt;0$ and a target function $u^\ast$ the aim is to identify the initial condition $u_0$ such that the solution, at time $t=T$, reaches the target $u^*$ or gets as close as possible to it. We assume that the initial condition $u_0$ is characterized as a combined set of sparse sources. This means that $u_0$ is a linear combination of unitary deltas with certain and possibly different weights, i.e:



We formulate the inverse problem using optimal control techniques. In particular, we consider the minimization of the following functional:



Space and time discretization

Letting $\textbf{u} : [0, T] \rightarrow \mathbb{R}^s$ where $s$ is the number of grid points on $\Omega$, we can write a general finite element (FE) discretization of the diffusion–advection equation in \eqref{modeleq} in a compact form as:



In order to get a time discretized version of the previous equation, we apply implicit Euler method with stepsize $\Delta t := T/N$ where $N$ is the total number of time steps. The numerical approximations to the solution are given by the vectors $\textbf{u}^n \approx \textbf{u}(t_n) \in \mathbb{R}^s$ with respect to the index $n=i\Delta t$ for $i=1,2,..,N$. Therefore, the fully discrete version of model equation is as follows,



Adjoint Algorithm for sparse source identification

The algorithm to be presented in this work for the sparse source identification of the linear diffusion-advection equation based on the adjoint methodology consists of two steps. Firstly, we use the adjoint methodology to identify the locations of the sources. Secondly, a least squares fitting is applied to find the corresponding intensities of the sources.

We have considered here a two-dimensional example with several sources to be identified in a multi-model environment. This means that the left half ($\Omega_1 = [0,1] \times [0,1]$) and the right half ($\Omega_2 = [1,2] \times [0,1]$) of the domain are modelled with different equations. In particular, the heat equation is used on $\Omega_1$ and the diffusion–advection equation is used on $\Omega_2$.

The initialization parameters look as follows:

N=30; %% space discretization points in y-direction
dx=1/(N+1); %% mesh size
t0=0; %% initial time
tf=0.1; %% final time
n=5; %% time discretization points
dt=(tf-t0)/n; %% stepsize
TOL=1e-5; %% stopping tolerance

d1=0.05; %% diffusivity of the material on the left sudomain
d2=0.05; %% diffusivity of the material on the left sudomain

%% advection components
vx=0;
vy=-3;

tau=dx^4; %% regularization parameter
epsilon=0.1; %% stepsize of the gradient descent method


We now compute the FE discretization matrices $M$, $A$ and $V$ that are respectively the mass matrix, the stiffness matrix and the advection matrix. For the FE discretization we assume equidistant structured meshes. In particular we use triangular elements and the classical pyramidal test functions are employed.

[M,A,V] = computeFEmatrices(N,d1,d2,vx,vy); %% Compute FE discretization matrices


A reference initial condition is chosen and we compute using the FE discretization specified above and implicit Euler in time its corresponding final state at time $T$. This final state will be considered the initial data of the inverse problem to be solved and we name it the target function $u^*$ as mentioned previously.

U0_ref = initial_deltas(N); %% computes reference initial condition

[U_target,u_target] = compute_target(U0_ref,N,n,dt,M,A,V); %% Compute target distribution


We now call the algorithm that estimates the initial condition $u_0$ using as a initial data the target function $u^*$. As mentioned before, this algorithm consists of two steps.

Firstly, the classical adjoint methodology that minimizes the functional $J(u_0)$ subject to the diffusion-advection equation is used. The iterative optimization algorithm employed is the classical gradient descent method. However, although this iterative procedure finds quite accurately the locations of the sources, it does not recover the sparse character of the initial condition. This is not suprising because the recovered initial data comes from solving the adjoint problem which is basically a diffusive process that smoothes out its state. Consequently, a second procedure is needed to project the obtained non sparse initial condition into the set of admissible sparse solutions.

As the initial condition $u_0$ is assumed to be a linear combination between the locations and the intensities, once we have fixed the locations using the adjoint methodology we can solve a least squares problem to get the remaining intensities. We assemble a matrix $\textbf{L} \in \mathbb{R}^{s \times l}$ where at each column we have the forward solution for a single unitary delta placed at each of the locations already identified. We then solve the following linear system of equations for the vector of unknowns $\alpha = (\alpha_1, \alpha_2, …, \alpha_l)^T$:



to find the intensities vector $\alpha$.

Adjoint algorithm for sparse source identification (algorithm 4)

U0 = SparseIdentification(u_target,TOL,dt,n,N,M,A,V,epsilon,tau);


Finally, the final state at $T$ is computed using as a initial condition the estimated sparse sources identified with our algorithm.

Compute final state with the recovered initial condition

[UF,u_final] = compute_target(U0,N,n,dt,M,A,V);


We can see the evolution recovered



We now visualize the numerical results. Plots on the left side show the reference initial solution and the given target. Similarly, plots on the right side show the recovered initial condition and the distribution at the final time $T$ produced by the recovered initial sources.

One can observe the difference between the two models (the heat equation on $\Omega_1$ and the diffusion-advection on $\Omega_2$) in the two figures at the bottom where the initial sources on $\Omega_2$ move downwards at the same time as they dissipate while the initial sources on $\Omega_1$ only dissipate without displacement.

xplot = linspace(0,2,2*N+3); %% space grid w.r.t component x
yplot = linspace(0,1,N+2); %% space grid w.r.t component y
%%
figure('unit','norm','pos',[0.25 0.1 0.5 0.8])
subplot(3,2,1)
surf(xplot,yplot,U0_ref)
shading interp;colorbar;colormap jet
title('Reference initial state (front view)')
subplot(3,2,2)
surf(xplot,yplot,U0)
shading interp;colorbar;colormap jet
title('Recovered initial state (front view)')
subplot(3,2,3)
pcolor(xplot,yplot,U0_ref)
shading interp;colorbar;colormap jet
title('Reference initial state (above view)')
subplot(3,2,4)
pcolor(xplot,yplot,U0)
shading interp;colorbar;colormap jet
title('Recovered initial state (above view)')
subplot(3,2,5)
pcolor(xplot,yplot,U_target)
shading interp;colorbar;colormap jet
title('Given target u^*')
subplot(3,2,6)
pcolor(xplot,yplot,UF)
shading interp;colorbar;colormap jet
title('Recovered final state')



</description>
        <pubDate>Fri, 14 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0014</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0014</guid>
        
        
        <category>tutorial</category>
        
        <category>WP04</category>
        
      </item>
    
      <item>
        <title>Controllability of a Class of Infinite Dimensional Systems with Age Structure</title>
        <description>
 Infinite dimensional dynamical systems coupling age structuring with diffusion appear naturally in
 population dynamics, medicine or epidemiology. A by now classical example is the Lotka-Mckendrick system with spatial diffusion. The
 aim of this blog is to study contaollability properties of such age structured models in an unified manner. 
 


Let $A : \mathcal{D}(A) \to X$  be the generator of a $C^0$ semigroup $\mathbb{S}$ on the Hilbert space $X$ and let $U$ be
another Hilbert space. Both $X$ and $U$ will be identified with their duals. Let $B$ be a (possibly unbounded) linear operator
from $U$ to $X$, which is supposed to be an admissible control operator for  $\mathbb{S}$.
In the examples we have in mind, the above spaces and operators describe the dynamics of a system without age structure.
In particular, $X$ is the state space and $U$ is the control space.
The corresponding age structured system is obtained by first extending these spaces to
\begin{equation} \label{input-space}
\mathcal{X} = L^{2}(0,a_{\dagger}; X), \quad \mathcal{U} = L^{2}(0,a_\dagger;U).
\end{equation} 
where $a_\dagger&amp;gt;0$ denotes the maximal age individuals can attain. Let $p(t) \in \chi$ be the distribution density of the
individuals with respect to age $a\geqslant 0$ and at some time $t \geqslant 0.$  Then the abstract version of the Lotka-McKendrick
system to be considered in this paper writes:
 \begin{equation} \label{eq:main}
\begin{cases}
\displaystyle \frac{\partial p}{\partial t} + \frac{\partial p}{\partial a} - A p  + \mu(a) p =  \mathcal{\chi}_{(a_{1},a_{2})} B u, &amp;amp; t \geqslant 0, a \in (0,a_\dagger), \\
\displaystyle p(t,0)  = \displaystyle \int_{0}^{a_\dagger} \beta(s) p(t,s) \; {\rm d}s, &amp;amp; t \geqslant 0, \\
\displaystyle p(0,a) = p_{0},
\end{cases}
\end{equation} 
where $\mathcal{\chi}$ is the characteristic function of the interval $(a_{1}, a_{2})$ with
$0 \leqslant a_{1} &amp;lt; a_{2} \leqslant a_\dagger$ and $p_{0}$ is the initial population density.
In the above system, the positive function $\mu:[0,a_\dagger] \to \mathbb{R}_{+}$ denotes the
natural mortality rate of individuals of age $a.$ We denote by $\beta: [0,a_\dagger] \to \mathbb{R}_{+}$
the positive function describing the fertility rate at age $a.$ We assume that the fertility rate $\beta$ a
nd the mortality rate $\mu$ satisfy the conditions

(H1) $\beta \in L^\infty[0, a_\dagger], \; \beta \geqslant 0$ for almost every $a \in [0,a_\dagger].$
(H2) $\mu \in L^1_{loc}[0, a_\dagger], \; \mu \geqslant 0$ for almost every $a \in [0,a_\dagger].$
(H3) $\displaystyle \int_0^{a_\dagger} \mu(a) \ {\rm d} a = \infty.$


Before we state our result, let us introduce the notion of null controllability of the pair $(A,B).$

We say that a pair $(A,B)$ is null-controllable in time $\tau,$ if for every $z_{0} \in X$ there exists a control $u \in L^{2}(0,\tau,U)$ such that, the solution of the system
\begin{equation*}
\dot z(t) = A z(t) + Bu(t) \quad t \in [0,\tau], \qquad z(0) = z_{0},
\end{equation*}
satisfies $z(\tau) = 0.$


We prove the following result

Assume that  $\beta$ and $\mu$ satisfy the conditions (H1)-(H3) above. Moreover,
suppose that the fertility rate $\beta$ is such that
\begin{equation} \label{eq:beta}
\beta(a)= 0 \mbox{ for all } a \in (0,a_{b}),
\end{equation}
for some $a_b\in (0,a_\dagger)$ and that $a_1 &amp;lt; a_b$.
Let us assume that the pair $(A,B)$ is null controllable in arbitrary time. 
Then for every $\tau &amp;gt; a_{1} + a_{\dagger}-a_{2}$ and for every $p_{0} \in \chi$ there exists  a control $v \in L^{2}(0,\tau;\mathcal{U})$ such that the solution $p$ of \eqref{eq:main} satisfies
\begin{equation}
p(\tau,a) = 0 \mbox{ for all }  a \in (0,a_\dagger).
\end{equation} 
 

It is well known that null controllability is equivalent to final state observability of the adjoint system
(see for instance [4, Section 11.2]). The adjoint of the above system reads as
\begin{equation} \label{eq:adj}
\begin{cases}
\displaystyle \frac{\partial q}{\partial t} - \frac{\partial p}{\partial a} - A^* p  + \mu(a) p - \beta(a) q(t,0) =  0, &amp;amp; t \geqslant 0, a \in (0,a_\dagger), \\
\displaystyle q(t,a_\dagger)  = 0, &amp;amp; t \geqslant 0, \\
\displaystyle q(0,a) = q_{0},
\end{cases}
\end{equation} 
where $A^*$ is the adjoint of  $A.$  In order to prove Theorem 1, it is enough to prove the following

 Let us assume the hypothesis of Theorem 1. Then for every $\tau &amp;gt; a_1 + a_\dagger - a_2$ there exists $k_\tau &amp;gt; 0$ such that
 the solution $q$ of \eqref{eq:adj} satishfies
 \begin{equation} \label{eq:est-adj}
 \int_0^{a_\dagger} \|q(\tau, a)\|^2_X \ da  \leqslant k_\tau^2 \int_0^\tau \int_{a_1}^{a_2} \left\|B^*q(t,a) \right\|^2_U \ da dt, \qquad \qquad (q_0 \in \mathcal{X}).
 \end{equation}
 
Let us give an idea of the proof. We combine characteristics method with final state observability of the pair $(A^*, B^*).$ For siplicity
in the presentation, let us assume that $\mu = 0,$ $a_1 = 0,$ $a_2 &amp;lt; a_b$ and $\tau = 2a_\dagger.$
The detail proof of Theorem 1, in a slightly more general case, can be found in [3]. Integrating along the characteristic lines,
it is not very difficult to see that
\begin{equation*}
q(t,a) = \int_{t + a - a_\dagger}^{t} e^{(t-s)A^*} \beta(a+ \tau - s) q(s, 0) \ ds, \qquad t &amp;gt; a_\dagger. 
\end{equation*}
Therefore,
\begin{equation} \label{est0}
\int_0^{a_\dagger} \|q(\tau, a)\|^2_X \ da \leqslant C \int_{a_\dagger}^\tau \left\|q(t,0) \right\|^2_X \ dt. 
\end{equation}
Thus to prove \eqref{eq:est-adj}, we need to estimate the right hand side of the above estimate. We now make use of the condition
\eqref{eq:beta}.  Note that, due to this condition, $q$ satisfies
\begin{equation} \label{eq:adj-2}
\displaystyle \frac{\partial q}{\partial t} - \frac{\partial q}{\partial a} - A^* p  + \mu(a) p =  0,  \quad  t \geqslant 0, a \in (0,a_2).
\end{equation}
For a.e. $t \in (a_\dagger, \tau),$ we define $w(s) = q(s, t- s),$ $s \in (t - a_2, t).$ Then $w$ solves
\begin{equation*}
\displaystyle \frac{\partial w}{\partial s} - A^* w = 0, \quad s \in (t - a_2, t). 
\end{equation*}
Since the pair $(A, B)$ is null controllable in any time, or equivalently the pair $(A^*, B^*)$ is final-state observable in any
time, there exists a constant
$C &amp;gt; 0,$ depending only on $a_2, A$ and $B$  such that
\begin{equation*}
\left\| w(t) \right\|_{X}^2 \leqslant C \int_{t-a_2}^t \left\| B^* w(s) \right\|^2_U \ ds. 
\end{equation*}
Coming back to $q$ and integrating over $[a_\dagger, \tau]$ with respect to $t,$ we have that
\begin{equation}
\int_{a_\dagger}^\tau \|q(t,0)\|^2_X \ dt \leqslant \int_{0}^\tau \int_{0}^{a_2} \left\|B^* q(t,a)\right\|^2  \ da dt. 
\end{equation}
Combining the above estimate together with \eqref{est0}, we get \eqref{eq:est-adj}. In the two figures below, we ilustrate the
estimate of $q(t,0)$ and the final-state observability of $q$ in the general case.



  
   
     
  
   Fig.1 - An ilustration of the estimate of $q(t,0).$ We apply final state observability of $(A^*, B^*)$ along
  the characteristics. Since we want to estimate $q(t,0),$ we consider the trajectory $\gamma(s) = (t-s,s),$
  $s \leqslant t \leqslant \tau$ (or equivalently the backward characteristics starting from $(t,0).$) 

    

    
  
   Fig.2 - An illustration of the final-state observability at time $\tau &amp;gt; a_1 + a_\dagger - a_2$: For
  $ a \in (0,a_2 - \varepsilon)$ (blue region) the backward characteristics starting from $t = \tau$ enters the
  observation domain.  For $a \in (a_2 - \varepsilon, a_\dagger)$, the backward characteristics (green region)
  hits the line $a = a_\dagger$, gets renewed by the renewal condition $\beta(a)q(t,0)$ and then enters the observation
  domain (purple region).
 
 
 
 

Examples
We consider two examples :  1) The classical Lotka-McKendrick system and 2) Lotka-Mckendrick system with diffusion.

 1)  The classical Lotka-McKendrick system : Let us choose $X = \mathbb{R},$ $A=0$ and $B=1.$ Then the system \eqref{eq:main} reduces
 to  classical Lotka-McKendrick system. By Theorem 1, this system is null controllable in time $\tau &amp;gt; a_1 + a_\dagger - a_2.$ A
 similar result was obtained in [1]. 



 2)  The Lotka-McKendrick system with spatial diffusion  : Let $\Omega$ be a smooth bounded domain in $\mathbb{R}^3$ and
 $\omega \subseteq \Omega.$ Let us consider 
 \begin{equation*}
 X = L^2(\Omega), \quad A = \Delta , \quad \mathcal{D}(A) =
 \left\{ f \in H^2(\Omega) \mid \displaystyle \frac{\partial f}{\partial n} = 0\right\}, \quad B = \chi_{\omega}.
 \end{equation*}
 This corresponds to the Lotka-McKendrick model with spatial diffusion ([2]). It is known that, the pair $(A, B)$ or equivalently
 the heat equation with localized interior control, is null controllable in any time. Thus we can apply Theorem 1 to conclude that
 the system is null controllable in time $\tau &amp;gt; a_1 + a_\dagger - a_2.$
 
 Several other applications can be found in [3].

 Due to the presence of the transport phenomena, the system \eqref{eq:main} is not null controllable for small time (see for
instance [2, Proposition 5.1]). This can also be seen from the following numerical simulation. Let us consider the case $A = 0$
and $B = 1,$ i.e the classical Lotka-McKendrick system. We choose $a_1 = 0,$ $a_2 = .2$ and $a_{\dagger} = 2.$ We choose a initial
data $q_0$ for the system \eqref{eq:adj}, localized in a neighbourhood of $a = 1.8,$ and we plot the solution of the adjoint problem
\eqref{eq:adj}(See Fig 3). We see that, the solution propages along the characteristic lines. It reaches the observation/control region
$(a_1, a_2) = (0,.2)$ in time $t &amp;gt; 1.8.$ Before this time the $L^2$ norm of the solution over the obsevation region is small. Hence
the lack of null controllability for small time. 

  
   
     
  

    

    
  
  
 
 
  Fig.3 : Solution of the adjoing system \eqref{eq:adj}, localized at $t = 0$ near $a = 1.8,$ that propagates with the
  velocity $1$ to the left. As soon as it reaches $a =0,$ it gets renewed by the renewal condition and propagates to the left again.
 

In this video we see the evolution of the adjoint system \eqref{eq:adj}. We notice the same behavious described above.

   
  

References
 [1] D. Maity,  On the Null Controllability of the Lotka-Mckendrick System, Submitted. 
 [2] D. Maity, M. Tucsnak and E. Zuazua,  Controllability and positivity constraints in population dynamics with age
structuring and diffusion , Journal de Math&amp;eacute;matiques Pures et Appliqu&amp;eacute;s. In press, 10.1016/j.matpur.2018.12.006.

 [3] D. Maity, M. Tucsnak and E. Zuazua,  Controllability of a Class of Infinite Dimensional
Systems with Age Structure. Submitted.

 [4] M. Tucsnak and G. Weiss,  Observation and control for operator semigroups,   
Birkh&amp;auml;user Advanced Texts: Basler Lehrbu&amp;uuml;cher. [Birkh&amp;auml;user Advanced Texts: Basel Textbooks], Birkh&amp;auml;user Verlag, Basel, 2009. 

</description>
        <pubDate>Fri, 07 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp05/WP99-P0030</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp05/WP99-P0030</guid>
        
        
        <category>tutorial</category>
        
        <category>WP05</category>
        
      </item>
    
      <item>
        <title>Finite Element approximation of the one-dimensional fractional Laplacian</title>
        <description>We describe here a Finite Element algorithm for the approximation of the one-dimensional fractional Laplacian $(-d_x^2)^s$ on the interval $(-L,L)$, $L&amp;gt;0$ and for the numerical resolution of the following fractional Poisson equation



This algorithm has also been emploied in [2,3] for the numerical controllability of fractional parabolic problems (see our previous entries in the DyCon Blog, WP3_P0001 and WP3_P0022).

We recall that the fractional Laplacian is defined, for all $s\in(0,1)$ and any function $u$ regular enough, as the following singular integral



with $c_s$ an explicit normalization constant given by



$\Gamma$ being the usual Euler Gamma function.

The starting point of the FE method is the definition of a bilinear form associated to the fractional Laplace operator $(-d_x^2)^s$ and the introduction of the variational formulation corresponding to the elliptic problem \eqref{Fl_Poisson}.

This variational formulation is given as follows: find $u\in H_0^s(-L,L)$ such that the identity



is satisfied for any function $v\in H_0^s(-L,L)$. In \eqref{variational}, with $H_0^s(-L,L)$ we indicate the space



$H^s(\mathbb{R})$ being the usual fractional Sobolev space. Moreover, the bilinear form



is defined as



Let us describe how, starting from the above bilinear form, we can obtain our FE approximation. For simplicity, in what follows we will take $L=1$, although the methodology remains the same for any real $L&amp;gt;0$.

Let us take a uniform partition of the interval $(-1,1)$ as follows:



with $x_{i+1}=x_i+h$, $i=0,\ldots N$. We call $\mathfrak{M}$ the mesh composed by the points ${x_i\,:\, i=1,\ldots,N}$, while the set of the boundary points is denoted $\partial\mathfrak{M}:={x_0,x_{N+1}}$.

Now, define $K_i:=[x_i,x_{i+1}]$ and consider the discrete space



where $\mathcal{P}^1$ is the space of the continuous and piece-wise linear functions. Hence, we approximate \eqref{variational} with the following discrete problem: find $u_h\in V_h$ such that



for all $v_h\in V_h$. If now we indicate with



a basis of $V_h$, it will be sufficient that the above equality is satisfied for all the functions of the basis, since any element of $V_h$ is a linear combination of them. Therefore the problem takes the following form



Clearly, since $u_h\in V_h$, we have $u_h(x) = \sum_{j=1}^N u_j\phi_j(x)$, where the coefficients $u_j$ are, a priori, unknown. In this way, \eqref{WFD} is reduced to solve the linear system $\mathcal A_h u=F$, where the stiffness matrix $\mathcal A_h\in \mathbb{R}^{N\times N}$ has components



while the vector $F\in\mathbb{R}^N$ is given by $F=(F_1,\ldots,F_N)$ with



Moreover, the basis



that we will employ is the classical one in which each $\phi_i$ is the tent function with $supp(\phi_i)=(x_{i-1},x_{i+1})$ and verifying $\phi_i(x_j)=\delta_{i,j}$. In particular, for $x\in{x_{i-1},x_i,x_{i+1}}$ the $i^{th}$ function of the basis is explicitly defined as (see Figure 1)




Figure 1. Basis function $\phi_i$ on its support $(x_{i-1},x_{i+1})$.

We now start building the stiffness matrix $\mathcal A_h$ approximating the fractional Laplacian. This will be done in three steps, since the values of the matrix can be computed differentiating among three well defined regions: the upper triangle, corresponding to $j\geq i+2$, the upper diagonal corresponding to $j=i+1$ and the diagonal, corresponding to $j=i$. In each of these regions the intersections among the support of the basis functions are different, thus generating different values of the bilinear form.

We present below an abridged explanation of how to compute the entries of $\mathcal{A}_h$. Complete details may be found in [2].

Step 1: $j\geq i+2$

In this case we have $supp(\phi_i)\cap supp(\phi_j) =\emptyset$ (see also Figure 2). Hence, \eqref{stiffness_nc} is reduced to computing only the integral




Figure 2. Basis functions $\phi_i(x)$ and $\phi_j(x)$ for $j\geq i + 1$. The supports are disjoint.

Taking into account the definition of the basis function \eqref{basis_fun}, the integral \eqref{elem_noint_app} becomes



Let us introduce the following change of variables:



Then, rewriting (with some abuse of notations since there is no possibility of confusion) $\hat{x}=x$ and $\hat{y}=y$, we get



This integral can be computed explicitly, and we obtain



Notice that, when $s=1/2$, both the numerator and the denominator of the expression above are zero. In this case, the value of $a_{i,j}$ can be obtained by taking the limit $s\to 1/2$ and we get



if $k\neq 2$ and



Step 2: $j= i+1$
This is the most cumbersome case, since it is the one with the most interactions between the basis functions (see Figure 3).


Figure 3. Basis functions $\phi_i(x)$ and $\phi_{i+1}(x)$. In this case, the intersection of the supports is the interval $[x_i,x_{i+1}]$.

Using the symmetry of the integral with respect to the bisector $y=x$, we have



Also in this case, the terms $Q_i$, $i=1,\ldots,6$, can be computed explicitely, by noticing also the following facts:


  $Q_1=Q_6=0$ since $\phi_i = 0$ on the domain of integration.
  $Q_2=Q_5$ due to symmetry.


Then, the elements $a_{i,i+1}$ are given by the sum $2Q_2+Q_3+Q_4$ and we have



Step 3: $j= i$
As a last step, we fill the diagonal of the matrix $\mathcal A_h$, which collects the values corresponding to $\phi_i(x)=\phi_j(x)$ (see Figure 4).


Figure 4. Basis functions $\phi_i(x)=\phi_j(x)$.

In this case, we have



Once again, the terms $R_i$, $i=1,\ldots,7$ can be computed explicitely, by taking also into account that $R_1=R_3=R_6=R_7=0$ because the corresponding integration domains are all away from the support of the basis functions.

The result of these computations gives the values



Step 4: building of $\mathcal A_h$

Summarizing, we have the following values for the elements of the stiffness matrix $\mathcal{A}_h$: for $s\neq 1/2$



For $s=1/2$, instead, we have



Numerical results

We present the numerical simulations corresponding to the algorithm previously described.

First of all, we test numerically the accuracy of our method for the resolution of the elliptic equation \eqref{Fl_Poisson} by applying it to the following problem



In this particular case, the unique solution $u$ can be computed exactly and it is given by



where $\chi_{(-1,1)}$ indicates the characteristic function of the interval $(-1,1)$.

The solution of \eqref{poisson} in the case  $s=0.1$ and $N=50$ is computed with the following script which emploies the function FEFractionalLaplacian.m ginving the FE discretization of $(-d_x^2)^s$.

s = 0.1;
N = 50;
L = 1;

x = linspace(-L,L,N+2);
x = x(2:end-1);
h = x(2)-x(1);

f = @(x) 1+0*x;
Phi = @(x) 1-abs(x);

F = zeros(N,1);

for i=1:N
    xx = linspace(x(i)-h,x(i)+h,N+1);
    xx = 0.5*(xx(2:end)+xx(1:end-1));
    B1 = f(xx).*(Phi((xx-x(i))/h));
    F(i) = ((2*h)/N)*sum(B1); 
end

A = FEFractionalLaplacian(s,L,N);
sol = A\F;


In Figure 5, we show a comparison for different values of $s$ between the exact solution \eqref{real_sol} and the computed numerical approximation.


Figure 5. Real and numerical solution.

One can notice that when $s=0.1$ (and also for other small values of s), the computed solution is to a certain extent different from the exact solution. Notwithstanding, it is well-known that the notion of trace is not defined for the spaces $H^s(-1,1)$ with $s\leq 1/2$. Hence, it is somehow natural that we cannot expect a point-wise convergence in this case.

Furthermore, the accuracy of our algorithm is validated by a simple error analysis.

The computation of the error in the space $H_0^s(-1,1)$ can be readily done by using the definition of the bilinear form, namely



where have used the orthogonality condition $a(v_h,u-u_h)=0$ for all $v_h \in V_h$.

For this particular test, since $f\equiv 1$ in $(-1,1)$, the problem is therefore reduced to



where the right-hand side can be easily computed, since we have the closed formula



and the term corresponding to $\int_{-1}^1u_h$ can be carried out numerically. Moreover, we have the following convergence result.

Theorem [2] For the solution $u$ of \eqref{WFD} and its FE approximation $u_h$ given by \eqref{WFD}, if $h$ is sufficiently small, the following estimates hold



where $\mathcal{C}$ is a positive constant not depending on $h$.

In Figure 6, we present the computational errors evaluated for different values of $s$ and $h$, which can be obtained with the following function.

function [h,e] = error_fl(s,N)

x = linspace(-1,1,N+2);
x = x(2:end-1);
h = x(2)-x(1);

f = @(x) 1+0*x;
Phi = @(x) 1-abs(x);

F = zeros(N,1);

for i = 1:N
    xx = linspace(x(i)-h,x(i)+h,N+1);
    xx = 0.5*(xx(2:end)+xx(1:end-1));
    B1 = f(xx).*(Phi((xx-x(i))/h));
    F(i) = ((2*h)/N)*sum(B1); 
end

A = FEFractionalLaplacian(s,1,N);
sol = A\F;
val = pi/(2^(2*s)*gamma(s+0.5)*gamma(s+1.5));
valnum = h*sum(sol);
e = sqrt(val-valnum);



Figure 6. Computational error in logarithmic scale in terms for different values of $s$.

The rates of convergence shown are of order (in $h$) of $1/2$, and this convergence rate is maintained also for small values of $s$. This confirms the accuracy of our approximation. In particular, the behavior shown in Figure 6 is not in contrast with the known theoretical results.

References

[1] G. Acosta, F. Bersetche and J. P. Borthagaray, A short FE implementation for a 2d homogeneous Dirichlet problem of a Fractional Laplacian. Comput. Math. Appl., Vol. 74, No. 4 (2017), pp. 784-816.

[2] U. Biccari and V. Hernández-Santamarı́a, Controllability of a one-dimensional fractional heat equation: theoretical and
numerical aspects. IMA J. Math. Control. Inf, to appear, 2018.

[3] U. Biccari, M. Warma and E. Zuazua, Controllability of the one-dimensional fractional heat equation under positivity constraints. Submitted.
</description>
        <pubDate>Fri, 07 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp05/WP99-P0024</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp05/WP99-P0024</guid>
        
        
        <category>tutorial</category>
        
        <category>WP05</category>
        
      </item>
    
      <item>
        <title>A numerical method for solving an age structured virus model</title>
        <description>The aim of this tutorial is to give a numerical method for solving an age structured virus model.

Introduction

The virus infection mathematical models are proposing and studying for a long time (see for example C.L. Althaus, R.J. DE Boer [1] and F. Brauer, C. Castillo-Chavez [2]. In particular case of an HIV infection model (see for P. W. Nelson and al. [6]), the corresponding model is usually divided into three classes called  uninfected cells, $T$,  infected cells, $i$ and free virus particles, $V$.



schematic representation of HIV dynamic.

We refer the reader to [4] and [5] for more general class on nonlinear incidence rates that take into account the saturation phenomenon.

We consider an age-structured HIV infection model with a very general nonlinear infection function



with the boundary and initial conditions



We denote by



The number $R_0$ represents the expected number of secondary infections produced by a single infected cell during its lifetime,



The complete global stability analysis for the system (\ref{A}) has been studied in [4]. The system (\ref{A}) admits at most two equilibrium, from Theorem 3.1 and Theorem 5.2 in [4], we obtain the following result:


  
    If $R_0 \leqslant 1$, the disease free equilibrium $E_0=(\frac{A}{\mu},0,0)$ is globally asymptotically stable.
  
  
    If $R_0&amp;gt;1$, the positive infection equilibrium $E^{\ast}=(T^\ast,i^\ast,V^\ast)$ is globally asymptotically stable.
  


Numerical method

We consider the Beddington-Deangelis function $f$  defined by



In this case, the basic reproduction number ${\cal R}_0$  is given by



Where $\pi(a)=\exp^{-\int_{0}^{a} \delta (s) ds}$ and $N=\int_{0}^{\infty} p(a) \pi(a) da$.

The numerical method to solve this system of equation is based on the upwind method for solving hyperbolic partial differential equation, (see [3]) called also the FTBS method (Forward-Time-Backward-Space), has first-order accuracy in both space and time. The CFL condition is necessary for the stability of numerical solutions. The ODEs are solving by explicit Euler method.

we use a grid with points $(x_j,t_n)$ defined by



with age step $\Delta a$ and time step $\Delta t$. Denoting, respectively, by $T^n$, $i^n_j$ and $V^n$  the numerical approximation of $T(t_n)$, $i(t_n,a_j)$ and $V(t_n)$, moreover,

 we thus obtain the difference scheme of hyperbolic PDE



with $\lambda = \frac{\Delta t}{\Delta a}$. We fix the following values of parameters



with the initial conditions



The functions $p$ is given by



We change the values of $\tau_1$ in order to have $R_0 \leq 1$ or to have $R_0 &amp;gt; 1$.  If we choose $ \tau_1 = 3 $ then $ R_0 = 0.5417 &amp;lt; 1 $,

 

And if we choose $ \tau_1 = 0.5 $ then $ R_0 = 1.4216 &amp;gt; 1 $,

 

clear all,close all
a1=0;
a2=60;
Tf=300;
I0=@(t)4*exp(-0.3*t);
T0=20;
V0=5;
A0=2; mu=0.02; muc=0.4;
beta=0.1;
alpha1=0.1;
alpha2=0.2;
delta=0.4;
fct=@(x,y) (beta*x*y)/(1+alpha1*x+alpha2*y);
N=199;M=1200;
h=(a2-a1)/N;
k=Tf/M;
a=a1+(1:N)*h;
ap=[0,a];
t=0+(0:M)*k;
lambda=k/h;
C=eye(N);
A=(1-lambda)*C+lambda*diag(ones(1,N-1),-1);


The reproduction number $R_0$

R0=tauxR(N,h,a,delta,beta,muc,mu,A0,alpha1)



R0 =

    1.4216




T(1)=T0;
V(1)=V0;
U= I0(a(1:N))';  %% initial values
Up=[fct(T0,V0); U]; %% Initial value + Boundary condition
Uf=Up;

F=zeros(N,1);

UI=zeros(1,M);;

for j=1:M
    Uold=U;
      UI(j)=h*fct(T(j),V(j));
    for o=1:N
    UI(j)=UI(j)+h*Uold(o);
    end
    B=[lambda*fct(T(j),V(j)) ;zeros(N-1,1)];
    F=- delta*Uold ;
    U=A*Uold+B+k*F;
    val=feval(@int,Uold,N-1,h,a);
    T(j+1)=T(j)+k*(A0-mu*T(j)-fct(T(j),V(j)));
    V(j+1)=V(j)+k*(val - muc *V(j));
    Up=zeros(N+1,1);
    Up=[fct(T(j+1),V(j+1)); U];
    Uf=[Uf,Up];
end


 figure(1);
    [X , Y] = meshgrid( ap ,t);
 mesh (X , Y , Uf')
 title('The evolution of solution i(t,a)')
 xlabel('Age')
 ylabel('time')
 figure(2)
 plot(t,T','b',t,[UI UI(N+2)],'r',t,V','g')
 legend('S(t)','I(t)=\int i(t,a)da','R(t)')
 xlabel('Time')






References

[1]  R. J. De Boer C. L. Althaus. Dynamics of immune escape during hiv/siv infection, PloS Comput. Biol, 2008.

[2] F. Brauer and C. Castillo-Chavez. Mathematical Models in Population Biology and Epidemiology Springer, New York, 2000.

[3] L. Edsberg. Introduction to Computation and Modeling for Differential Equations, 2nd Edition. Wiley, 288 Pages, 2016.

[4] M. N. Frioui S. E. Miri, T. M. Touaoula. Unified lyapunov functional for an age-structured virus model with very general nonlinear infection response. J. Appl. Math. Comput, pages 1–27, 2017.

[5]  T. Kuniya J. Wang, R. Zhang.. Mathematical analysis for an age-structured hiv infection model with saturation infection rate, Elect. J. Diff. Eq, pages 1–19, 2015.

[6]  A. S. Perelson P. W. Nelson. Mathematical analysis of delay differential equation models of hiv-1 infection. Math. Biosc, 179, pages 73–94, 2002.

</description>
        <pubDate>Tue, 04 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0025</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0025</guid>
        
        
        <category>tutorial</category>
        
        <category>WP05</category>
        
      </item>
    
      <item>
        <title>Controllability of the one-dimensional fractional heat equation under positivity constraints</title>
        <description>In [2], we analyzed the controllablity properties under non-negative control and state constraints of the following heat-like equation involving the fractional Laplacian on $(-1,1)$



In \ref{frac_heat}, $\omega\subset (-1,1)$ is the control region in which the distributed control $u$ acts. Moreover, we denote by $(-d_x^2)^s$ the fractional Laplace operator defined, for all $s\in(0,1)$, as the following singular integral



with $c_s$ an explicit normalization constant given by



Gamma being the usual Euler Gamma function.

The main result we established are the following results:


  
    For any $s&amp;gt;1/2$, there exists $T&amp;gt;0$ such that the fractional heat equation \ref{frac_heat} is controllable to positive trajectories by means of a non-negative control $u\in L^\infty(\omega\times(0,T))$. Moreover, if the initial datum $z_0\geq 0$ is non-negative, we also have $z(x,t)\geq 0$ for every $(x,t)\in (-1,1)\times (0,T)$.
  
  
    If we define the minimal controllability time by
  




we have $T_{min}&amp;gt;0$.


  For $T = T_{min}$, there exists a non-negative control $u\in \mathcal M(\omega\times(0,T_{min}))$, the space of Radon measures
on $\omega\times(0,T_{min})$, such that the corresponding solution $z$ of \ref{frac_heat} satisfies $z(x,T) = \widehat{z}(x,T)$ a.e.
in $(-1,1)$.


These results extend to the fractional case the ones previously obtained by our team in the context of the linear and semi-linear heat equation (see our previous entries in the DyCon Blog, WP3_P0001 and WP3_P0002).

In this post, we present some numerical development in order to find the minimal controllability time for the discretized
fractional heat equation with non-negative control constraint and to confirm our theoretical results.

In particular, we will consider the problem of steering the initial datum



to the target trajectroy $\widehat{z}$ solution of \ref{frac_heat} with initial datum



and right-hand side $\widehat{u}\equiv 1$.

We choose $s=0.8$ and $\omega=(-0.3,0.8)\subset (-1,1)$ as the control region. The approximation of the minimal controllability time is obtained by solving the following constrained minimization problem.



subject to



To solve this problem numerically, we employ the expert interior-point optimization routine IpOpt combined with automatic differentiation and the modeling language AMPL. The interest of using AMPL together with IpOpt is that the gradient of the cost function and the constraints is automatically generated. Solving problems with IpOpt and AMPL can be made online through the NEOS solvers.

To perform our simulations, we apply a FE method for the space discretization of the fractional Laplacian (see [1]) on a uniform space-grid



with $N_x=20$ . Moreover, we use an explicit Euler scheme for the time integration on the time-grid



with $N_t$ satisfying the Courant-Friedrich-Lewy condition. In particular, we choose here $N_t=100$.

The AMPL code for solving this minimation problem is included below. In it, the matrices defining the dynamics are computed through specific functions implemented in Matlab and are given as parameters.

It is important to remark that we are interested in the controllability to the trajectory $\widehat{z}(\cdot,T)$ but, at the same time, $T$ is a variable in our code since it is the cost functional we aim to minimize. In view of that, our final target changes during the minimization process. Nevertheless this issue can be bypassed by taking advance of the linear nature of our equation and solving the traslated constrained minimization problem consisting in finding the minimial time for steering the inital datum $z_0-\widehat{z}_0$ by employing a control $u\geq\widehat{u}$ ($\widehat{z}_0$ and $\widehat{u}$ are the same given above).

# Minimal time for the constrained controllability of the fractional heat equation.

# 1: define the parameters

param Nx = 20;               # number of spatial discretization points

param Nt = 100;              # number of time discretization points

param y0 {1..Nx};            # initial condition

param y1 = 0;                # target

param dx = 2/Nx;             # Space step

param C = 1;                 # Bound on the controls

param A {1..Nx,1..Nx};       # Stiffness or rigidity matrix

param B {1..Nx,1..Nx};       # Control matrix

param M {1..Nx,1..Nx};       # Mass matrix  

# 2: define the variables

var y {j in 0..Nt, i in 1..Nx};       # State
var u {j in 0..Nt, i in 1..Nx}&amp;gt;=-C;   # Control
var T &amp;gt;=0;                            # Time horizon
var dt = T/Nt;                        # Time step

# 3: define the data

data;

# Initial datum

param y0: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 :=
1 -0.000000 -0.905270 -1.785847 -2.617711 -3.378170 -4.046482 -4.604416 -5.036753 -5.331701 -5.481215 -5.481215 -5.331701 -5.036753 -4.604416 -4.046482 -3.378170 -2.617711 -1.785847 -0.905270 -0.000000;

# Stiffness or rigidity matrix A

param A: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 :=
1 -5.551728 2.242487 0.359689 0.077115 0.033148 0.017829 0.010871 0.007193 0.005044 0.003694 0.002798 0.002178 0.001733 0.001405 0.001158 0.000966 0.000816 0.000697 0.000600 0.000521
...
20 0.000521 0.000600 0.000697 0.000816 0.000966 0.001158 0.001405 0.001733 0.002178 0.002798 0.003694 0.005044 0.007193 0.010871 0.017829 0.033148 0.077115 0.359689 2.242487 -5.551728;


# Control matrix B

param B: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 :=
1 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
...
20 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000;


# Mass matrix M

param M: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 :=
1 0.070175 0.017544 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
...
20 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.017544 0.070175;


# 4: define the cost functional to minimize

minimize cost: T;

# 5: define the constraints

# 5.a: dynamics y' = Ay + Bu, implemented through an Explicit Euler method.

subject to y_dyn {j in 1..Nt, i in 2..Nx-1}:
sum {l in 1..Nx} M[i,l]*y[j,l] = sum {l in 1..Nx}M[i,l]*y[j-1,l] + dt*sum {l in 1..Nx}(A[i,l]*y[j-1,l] + B[i,l]*u[j-1,l]);

# 5.b: homogeneous Dirichlet boundary conditions in -1 and 1.

subject to left_boundary  {j in 0..Nt}: y[j,1] = 0;
subject to right_boundary {j in 0..Nt}: y[j,Nx] = 0;

# 5.c: initial condition.

subject to y_init {i in 1..Nx}: y[0,i] = y0[i];

# 5.d: target.

subject to y_end1 {i in 1..Nx}: y[Nt,i] = y1;

# 6: solve the problem with IpOpt

option solver ipopt;
option ipopt_options &quot;max_iter=100000 linear_solver=mumps hessian_approximation=exact halt_on_ampl_error yes&quot;;
solve;

# 7: print the results.

printf: &quot;T  = %24.16e\n&quot;, T;
printf: &quot;Nx = %d\n&quot;, Nx;
printf: &quot;Nt = %d\n&quot;, Nt;
printf {j in 0..Nt, i in 1..Nx}: &quot; %24.16e\n&quot;, y[j,i];
printf {j in 0..Nt, i in 1..Nx}: &quot; %24.16e\n&quot;, u[j,i];

end;


Once the minimization is concluded, we save the results in a file “data.txt” and we use Matlab to reshape the solution and the control so to obtain two $N_x\times(N_t+1)$ matrices for the plots.

This can be done through the following script:

close all
% Read the data from the external file data.txt

fid= fopen('data.txt','r');
C = fscanf(fid,'%f',Inf);
T = C(1);
Nx = C(2);
Nt = C(3);
y = C(4:(Nt+1)*Nx+3);
u = C((Nt+1)*Nx+4:end);
fclose(fid);

% Reshape the state y and the control u into two Nx times Nt+1 matrices
y = reshape(y,Nx,Nt+1);
u = reshape(u,Nx,Nt+1);


From the reshaped solution and control, we can generate the plots. For instance, the m-file plot_control.m is the one generating Figure 2 below.

The minimal time that we obtain from our minimization process is $T_{min}\simeq 0,2101$. Our simulations show that in this time horizon the fractional heat equation \ref{frac_heat} is controllable from the initial datum $z_0$ to the desired trajectory $\widehat{z}(\cdot,T)$ by maintaining the positivity of the solution (as it is expected since the initial datum is positive in $(-1,1)$, see Figure 1).


Figure 1. Controllability of the fractional heat equation \ref{frac_heat}in the minimal time $T_{min}=0.2101$.

Moreover, as it is observed also in Figure 2, the control has an impulsional behavior.


Figure 2. Minimal-time control. In the $(t,x)$ plane in blue the time $t$ varies from $t = 0$ (left) to $t = T_{min}$ (right).

This behavior of the control is not surprising. Indeed, as it was already observed in our previous works [3,4], the minimal-time controls are expected to be atomic measures, in particular linear combinations of Dirac deltas. Our simulations are thus consistent with the aforementioned papers.

The impulsional behavior of the control is then lost when extending the time horizon beyond $T_{min}$. This is shown in Figure 3, in which we display the behavior of the control steering the solution of the fractional heat equation \ref{frac_heat} from the initial datum $z_0$ to the target $\widehat{z}(\cdot,T)$ in the time horizon $T=0.4$.


Figure 3. Behavior of the control in time $T = 0.4$. The white lines delimit the control region $\omega = (-0.3, 0.8)$. The regions in which the control is active are marked in yellow. The atomic nature is lost.

This control has been computed by employing once again IpOpt for solving the following minimization problem:



subject to



As we can observe, the action of this control is now more distributed in $\omega$. Neverthelss, in accordance with our theoretical results, the equation is still controllable in the prescribed time horizon (see Figure 4)


Figure 4. Controllability of the fractional heat equation \ref{frac_heat}in time $T = 0.4$. The atomic behavior of the control is lost.

Finally, we consider the case of a time horizon $T&amp;lt;T_{min}$, in which constrained controllability is expected to fail. This time, we employ a classical conjugate gradient method implemented in the DyCon Computational Toolbox for solving the above optimization problem.

As before, we apply a FE method for the space discretization of the fractional Laplacian on a uniform space-grid with $N_x=20$ points and we use an explicit Euler scheme for the time integration on a time-grid with $N_t=100$ points. Furthermore, we choose a time horizon $T=0.15$, which is below the minimal controllability time $T_{min}$.

Our simulation then show that the solution of \ref{frac_heat} fails to be controlled. In fact, Figure 5 shows that the state computed by employing the tools of the DyCon Computational Toolbox does not totally match the desired target in the time horizon prescribed.


Figure 5. Evolution in the time interval $(0,0.15)$ of the solution of \ref{frac_heat} with $s = 0.8$ under the positivity control constraint $u\geq 0$. The equation is not controllable.

References

[1] U. Biccari and V. Hernández-Santamarı́a, Controllability of a one-dimensional fractional heat equation: theoretical and
numerical aspects. IMA J. Math. Control. Inf, to appear, 2018.

[2] U. Biccari, M. Warma and E. Zuazua, Controllability of the one-dimensional fractional heat equation under positivity constraints. Submitted.

[3] J. Loheac, E. Trélat, and E. Zuazua, Minimal controllability time for the heat equation under unilateral state or control
constraints. Math. Models Methods Appl. Sci., Vol. 27, No. 9 (2017), pp 1587-1644.

[4] D. Pighin and E. Zuazua, Controllability under positivity constraints of semilinear heat equations. Math. Control. Relat.
Fields, Vol. 8, No. 3,4 (2018), pp. 935-964.
</description>
        <pubDate>Fri, 31 May 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp03/WP03-P0022</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp03/WP03-P0022</guid>
        
        
        <category>tutorial</category>
        
        <category>WP03</category>
        
      </item>
    
  </channel>
</rss>
