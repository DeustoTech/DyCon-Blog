<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DyCon Blog</title>
    <description>Welcome to the web interface of DyCon Toolbox, the computational platform developed within the &lt;a href='https://cmc.deusto.eus/dycon/' target='_blank'&gt;ERC DyCon - Dynamic Control&lt;/a&gt; project.</description>
    <link>https://deustotech.github.io/DyCon-Blog/</link>
    <atom:link href="https://deustotech.github.io/DyCon-Blog/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 13 Feb 2020 17:05:06 +0100</pubDate>
    <lastBuildDate>Thu, 13 Feb 2020 17:05:06 +0100</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>Stabilization of a double pendulum on a cart in DyCon Toolbox</title>
        <description>The finite-dimensional dynamical system given by a pendulum on a cart (cartpole) is widely considered as a benchmark for comparing the performance of different control strategies. In this blog post, we consider a double pendulum on a cart and we solve the problem of swinging up the pendulum from the downward position to the upward position using optimal control techniques.

Equations of motion



  Figure 1. Scheme of system dynamics


The physical system defined by the double pendulum in a cart can be modelled as a system of six ordinary differential equations, whose state at each instant of time $t \geq 0$ is the vector $y(t) = \left( x(t), \theta_{1}(t), \theta_{2}(t), v(t), \omega_{1}(t), \omega_{2}(t) \right)$, where:


  $x(t) \in \mathbb{R}$ is the position of the cart.
  $\theta_{i}(t) \in [0, 2\pi]$ is the angle of the $i$-th pendulum.
  $v(t) \in \mathbb{R}$ is the velocity of the cart.
  $\omega_{i}(t) \in \mathbb{R}$ is the angular velocity of the $i$-th pendulum.


The equations of motion of the system can be derived using the Lagrangian formalism of classical mechanics and are given by:



where, for each $t \geq 0$, we define:



and



We have the fixed parameters:


  $d_{i} \in [0,1]$ are damping coefficients.
  $m &amp;gt; 0$ is the mass of the cart and $m_{i} &amp;gt; 0$ is the mass of the $i$-th pendulum.
  $l_{i} &amp;gt; 0$ is the length of the $i$-th pendulum.


The function $u \in L^{\infty}(0,\infty; \mathbb{R})$ is a time-dependent control that acts on the acceleration term $\dot{v}(t)$ of the cart, and can thus be interpreted as a force that is exerted on the cart.

This dynamical system shows chaotic behaviour. The following animation displays the evolution of the double pendulum on a cart with control $u = 0$ and starting at the two different initial conditions










  Figure 2. Chaotics behaviour


  Optimal Control Problem 

We will solve the problem of steering the state of the pendulum from the downward position $y_{0} = (0, \pi, \pi, 0, 0, 0)$ to the upward position $z = (0, 0, 0, 0, 0, 0)$ in a fixed time horizon $T &amp;gt; 0$ using a control $u(t)$.

One way to look for solutions to this problem is to minimize the following functional:



Where $\alpha &amp;gt;0$ is a fixed parameter, the state vector $y(t)$ is subject to the system of differential equations (1) and $y(0) = y_0$.

  Numerical simulation 

We start by implementing the dynamical system defined in (1) as a MATLAB function. We fix the lengths $l_{i} = 1$, and the mass of the cart $M = 50$. The damping coefficients are set to $d_{i} = 0.1$.

  &amp;gt;&amp;gt; type cartpole_dynamics.m

function ds = cartpole_dynamics(t,s,u,params)
    L1 = 1;    L2 = 1;    g = 9.8;
    m1 = params.m1;    m2 = params.m2;
    M = 50;
    d1 = 1e-1;    d2 = 1e-1;    d3 = 1e-1;
    %%%%%%%%%%%%%%%%%%%%%5%%%
    ds = zeros(6,1,class(s));
    %
    q      = s(1);    theta1 = s(2);
    theta2 = s(3);    dq     = s(4);
    dtheta1= s(5);    dtheta2= s(6); 
    % q
    ds(1) = dq -q;
    % theta 1
    ds(2) = dtheta1;
    % theta 2
    ds(3) = dtheta2;
    %
    Mt = [ M+m1+m2                  L1*(m1+m2)*cos(theta1)     m2*L2*cos(theta2) ; ...
          L1*(m1+m2)*cos(theta1)     L1^2*(m1+m2)             L1*L2*m2*cos(theta1-theta2) ; ...
          L2*m2*cos(theta2)          L1*L2*m2*cos(theta1-theta2)  L2^2*m2        ];
    % v
    f1 = L1*(m1+m2)*dtheta1^2*sin(theta1) + m2*L2*theta2^2*sin(theta2)      - d1*dq + u  ;
    f2 = -L1*L2*m2*dtheta2^2*sin(theta1-theta2) + g*(m1+m2)*L1*sin(theta1)  - d2*dtheta1;
    f3 =  L1*L2*m2*dtheta1^2*sin(theta1-theta2) + g*L2*m2*sin(theta2)       - d3*dtheta2; 

    ds(4:6) = Mt\[f1;f2;f3];
end


This optimal control problem is solved using CasADi with the IPOPT solver. MATLAB’s symbolic toolbox has been used to implement the system dynamics in CasADi.

The time horizon is set to $T = 10$ and the system (1) has been discretized using a Crank-Nicolson scheme. The use of an implicit discretization method with good behaviour with respect to the number of mesh points has been crucial to speed up the optimization process.

import casadi.*
% define optimal 

Ss = SX.sym('x',6,1);As = SX.sym('u',1,1);ts = SX.sym('t');
%
EvolutionFcn = Function('f',{ts,Ss,As},{ cartpole_dynamics(ts,Ss,As,params) });
%
dynamics_obj = ode(EvolutionFcn,Ss,As,tspan);
dynamics_obj.InitialCondition = s0;
%
PathCost  = Function('L'  ,{ts,Ss,As},{ (  (Ss.'*Ss) + 1e-3*(As.'*As) ) });
FinalCost = Function('Psi',{Ss}      ,{ (  (Ss.'*Ss) ) });

ocp_obj = ocp(dynamics_obj,PathCost,FinalCost);
%
U0 =0*tspan;
[OptControl ,OptState] = IpoptSolver(ocp_obj,U0,'integrator','CrankNicolson');



The following animation displays the resulting evolution of the system’s state:






  Figure 3. Optimal solution 


Interestingly, due to the chaotic character of system (1), the IPOPT routine yields different controlled trajectories if we change the initial guess of the control:






  Figure 4. Several initial guess of optimization

</description>
        <pubDate>Thu, 13 Feb 2020 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp01/P0008</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp01/P0008</guid>
        
        
        <category>tutorial</category>
        
        <category>WP01</category>
        
      </item>
    
      <item>
        <title>Optimal Control of the Fokker-Planck Equation with CasADi</title>
        <description>In this tutorial, we present an optimal control problem related to the Fokker-Planck equation.

Description of the problem

The Fokker Planck Equation

Let $\Omega$ be an open, bounded, regular subset of $\mathbb{R}^{n}$. Let $T&amp;gt;0$ and denote by $u\in L^2(0,T;H^{1}(\Omega))^n$ a time-dependent vector field in $\Omega$. Consider a particle in $\Omega$ that moves with velocity $u(x,t)$ at each point $x\in\Omega$ in time $t\in(0,T)$. Suppose furthermore that the particle is subject to additive Brownian noise.

Let $p_0(x)$ be the probability density of the position of the particle at time $t=0$. Then, at every time $t&amp;gt;0$, the probability density $p(x,t)$ of the particle satisfies the Fokker-Planck equation [1]:



Where $\mathrm{n}$ is the outward unit normal vector field on $\partial\Omega$.

Fix a positive real number $a&amp;gt;0$ and introduce the family of admissible controls:



For every non-negative initial data $p_0\in H^{1}(\Omega)$ and every admissible control $u\in\mathcal{U}_{\mathrm{ad}}$, there is a unique solution $p\in\mathcal{C}([0,T];L^{2}(\Omega))\cap L^{2}(0,T;H^{1}(\Omega))$ to the previous problem such that $p(x,t)\geq 0$ for every $t\geq 0$ and almost every $x\in\Omega$ [2].

If, besides, $\int_{\Omega}p_{0}(x)dx=1$, then integrating by parts it’s easy to check that $\int_{\Omega}p(x,t)dx=1$ for every $t\geq 0$, so $p(.,t)$ is indeed a probability density on $\Omega$ for every $t\geq 0$.

Optimal Control

Fix a smooth reference trajectory $z:[0,T]\rightarrow\Omega$. Our objective is to find an admissible control $u\in\mathcal{U}_{\mathrm{ad}}$ that minimizes the following functional:



subject to:



where $\alpha,\beta$ and $\gamma$ are non-negative real 
numbers. In [2] it is proven that there always exists a $u^{*}\in\mathcal{U}_{\mathrm{ad}}$ minimizing the previous functional among the family of admissible controls.

Numerical Simulation

In the numerical example that we will present in this post, we will work over the one-dimensional domain $\Omega = (-6,6)$ with time horizon $T = 5$, and the oscillating reference trajectory $z(t) = 4\sin(2t)$. We also fix $\alpha=\beta=\gamma=1$, so that our objective will be to minimize the functional:



subject to





We consider the initial probability density function



where $C&amp;gt;0$ is chosen so that $\int_{-6}^{6}p_0(x)dx=1$.



We start by defining the mesh sizes and parameters. We discretize the spatial domain with $20$ points and the temporal domain with $80$ points.

%% mesh sizes and parameters

% spatial mesh
X_max = 6; % length of space domain
Nx = 20; % number of mesh points
x_line = linspace(-X_max,X_max,Nx); % discretization of the space domain
dx = x_line(2) - x_line(1); % space increment

% temporal mesh
T = 5; % time horizon
Nt = 80; % number of mesh points
t_line = linspace(0,T,Nt); % discretization of the time domain
dt = t_line(2) - t_line(1); % time increment

% parameters
k = dt/(dx^2);
b = dt/(2*dx);


We define the reference trajectory $z(t)=4\sin(2t)$:

%% reference trajectory

ref = 4*sin(2*t_line);


We define the initial probability density $p_0(x) = \frac{1}{C}\exp(-2x^2)$. We compute $C$ using $C = \int_{-6}^{6}\exp(-2x^2)dx = \sqrt{\frac{\pi}{2}}\mathrm{erf}(6\sqrt{2})$, where $\mathrm{erf}$ is the error function.

%% initial density

y0 = exp(-2*x_line.^2);

C = sqrt(pi/2)*erf(sqrt(2)*X_max); % normalizing constant
y0 = (1/C) * y0'; % normalized initial density


The uncontrolled evolution of this probability density is given by the following heat equation with Neumann boundary conditions:



We discretize and solve this equation:

%% uncontrolled solution

Yf = zeros(Nx,Nt);
Yf(:,1) = y0;

for n = 1 : Nt-1
    for j = 2 : Nx-1
        % euler step
        Yf(j,n+1) = Yf(j,n) +  k * (Yf(j+1,n) - 2*Yf(j,n) + Yf(j-1,n));
    end
    % zero flux boundary conditions
    Yf(Nx,n+1) = Yf(Nx-1,n+1); 
    Yf(1,n+1) = Yf(2,n+1);
end

We display the uncontrolled solution:


  
      
        
      
      
        
      
  


The solution $p(x,t)$ of the Heat equation (2) is the probability density associated to a one-dimensional Brownian motion on the real line. This is a particular case of a more general phenomenon: there is a correspondence between certain second order parabolic equations and solutions of stochastic ordinary differential equations [3]. Using the computed value of $p(x,t)$, we can simulate sample paths of a Brownian motion on the real line: the following animation displays the evolution of $100$ Brownian particles without control:





We now set up the optimal control problem in CasADi:

%% optimal control problem

opti = casadi.Opti();
Y = opti.variable(Nx,Nt); % state variable
U = opti.variable(Nx,Nt); % control variable


We specify the system dynamics, discretizing the Fokker-Planck equation using central differences for the spatial derivatives and a forward Euler scheme for the time derivative:

%% system dynamics

for n = 1 : Nt-1
    for j = 2 : Nx-1
        term1 = k*(Y(j+1,n)-2*Y(j,n)+Y(j-1,n));
        term2 = b*Y(j,n)*(U(j+1,n)-U(j-1,n));
        term3 = b*U(j,n)*(Y(j+1,n)-Y(j-1,n));
        opti.subject_to(Y(j,n+1) == Y(j,n) + term1 - term2 - term3);
    end
end


We now set the initial condition and zero flux boundary conditions as constraints:

%% initial conditions and zero flux boundary conditions

% initial condition
opti.subject_to(Y(:,1) == y0); 

% zero flux boundary conditions
for n = 2 : Nt
    opti.subject_to(Y(Nx,n) == Y(Nx-1,n)/(1-dx*U(Nx,n)));
    opti.subject_to(Y(1,n) == Y(2,n)/(1+dx*U(1,n)));
end


We set the constraints on the control, taking $a = 2$:

%% admissible control constraints

opti.subject_to(-2&amp;lt;=U(:)&amp;lt;=2);


We declare the cost functional:

%% cost functional

cost = 0;

% running cost
for n = 1 : Nt 
    for i = 1 : Nx
        cost = cost + (x_line(i)-ref(n))^2*Y(i,n);
    end
end

% terminal cost
for i = 1 : Nx 
    cost = cost + (x_line(i)-ref(n))^2*Y(i,Nt);
end

% control cost
for n = 1 : Nt % control cost
    for i = 1 : Nx
        cost = cost + Y(i,n)*U(i,n)^2;
    end
end


We solve the optimization problem using the IPOPT software:

%% solution of the optimization problem

% set optimization objective
opti.minimize(cost);

% solution of the optimization problem
p_opts = struct('expand',true);
s_opts = struct('max_iter',1000); 
opti.solver('ipopt',p_opts,s_opts); 

tic
sol = opti.solve(); 
toc


Obtaining the following display:

This is Ipopt version 3.12.3, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:    10448
Number of nonzeros in inequality constraint Jacobian.:     1600
Number of nonzeros in Lagrangian Hessian.............:     6204

Total number of variables............................:     3200
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:     1600
Total number of inequality constraints...............:     1600
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:     1600
        inequality constraints with only upper bounds:        0

Number of Iterations....: 39

                                   (scaled)                 (unscaled)
Objective...............:  7.2472498957747769e+002   9.6893349411152292e+002
Dual infeasibility......:  1.0060574595627259e-010   1.3450657609300798e-010
Constraint violation....:  1.1102230246251565e-016   1.1102230246251565e-016
Complementarity.........:  2.5059036929760477e-009   3.3503108849024674e-009
Overall NLP error.......:  2.5059036929760477e-009   3.3503108849024674e-009


Number of objective function evaluations             = 40
Number of objective gradient evaluations             = 40
Number of equality constraint evaluations            = 40
Number of inequality constraint evaluations          = 40
Number of equality constraint Jacobian evaluations   = 40
Number of inequality constraint Jacobian evaluations = 40
Number of Lagrangian Hessian evaluations             = 39
Total CPU secs in IPOPT (w/o function evaluations)   =      1.062
Total CPU secs in NLP function evaluations           =      0.047

EXIT: Optimal Solution Found.
      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval
       nlp_f  |   3.00ms ( 75.00us)   3.00ms ( 75.00us)        40
       nlp_g  |  14.00ms (350.00us)  13.99ms (349.85us)        40
  nlp_grad_f  |   5.00ms (121.95us)   5.00ms (121.90us)        41
  nlp_hess_l  |  10.00ms (256.41us)  10.01ms (256.74us)        39
   nlp_jac_g  |  15.00ms (365.85us)  15.98ms (389.78us)        41
       total  |   1.11 s (  1.11 s)   1.11 s (  1.11 s)         1
Elapsed time is 1.561797 seconds.


The following pictures display the temporal evolution of the controlled solution. The solution follows an oscillatory pattern similar to the one given by the reference trajectory:


  
      
        
      
      
        
      
  


Again, by the correspondence between second order parabolic equations and solutions to stochastic ordinary differential equations, the solution $p(x,t)$ to equation (2) is the probability density of a brownian particle on the real line that is subject to the velocity field $u(x,t)$. We use the values of $p(x,t)$ that we have just computed to simulate sample paths of this controlled brownian motion: the following animation displays the evolution of $100$ Brownian particles subject to the control $u(x,t)$:




References

[1] Hannes Risken, Till Frank. The Fokker-Planck Equation: Methods of Solution and Applications, Second Edition. Springer-Verlag Berlin Heidelberg, 1996

[2] Roy, S., Annunziato, M., Borzì, A., and Klingenberg, C. (2018). A Fokker–Planck approach to control collective motion. Computational Optimization and Applications, 69(2), 423-459.

[3] Stroock, Daniel W., Varadhan, S.R.S. Multidimensional Diffusion Processes. Springer-Verlag Berlin Heidelberg, Reprint of the 1997 Edition (Grundlehren der mathematischen Wissenschaften, Vol. 233).

</description>
        <pubDate>Thu, 19 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0013</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0013</guid>
        
        
        <category>tutorial</category>
        
        <category>WP05</category>
        
      </item>
    
      <item>
        <title>Inverse design for the one-dimensional Burgers equation</title>
        <description>The problem

We consider the following one-dimensional Burgers equation



where $u$ is the state, $u_0$ is the initial state and  the flux function $f$ is defined by $f(u)=\frac{u^2}{2}$. Kruzkov’s theory  provides existence and uniqueness of a  solution  of \eqref{eq} with initial datum $u_0 \in L^{\infty}(\mathbb R)$. This solution is called a weak-entropy solution, denoted by $(t,x) \to S_t^+(u_0)(x)$. For a given target function $u^T$, we introduce the backward entropy  solution $(t,x) \to S^-_{t}(u^T)(x)$  as follows: 
for every $t\in [0,T]$, for a.e $x\in \mathbb R$,



We study the problem of inverse design for \eqref{eq}. This problem consists in  identifying the set of initial data evolving to a given target at a final time.

Due to the time-irreversibility of the Burgers equation, some target functions are unattainable from weak-entropy solutions of this equation, making the inverse problem under consideration ill-posed. To get around this issue, we introduce the following  optimal control problem



where $u^T$ is a given target function and the class of admissible initial data $\mathcal{U}^0_{\text{ad}}$ in \eqref{opt2} is defined by



Above,  stands for functions of bounded variation and  $C&amp;gt;0$ is a constant large enough. The study of \eqref{opt2} is motivated by the minimization of the sonic boom effects generated by supersonic aircrafts [2].

To solve the optimal control problem \eqref{opt2}, some difficulties arise from a  theoretical  and  numerical point of view.

  Since the  entropy solution $u$ of \eqref{eq} may contain shocks even if the initial datum is a smooth function, this generates important added difficulties that have been the object of intensive study in the past, see  [3,4] and the references therein. In particular, the authors make sense of the derivative of $J_0$ in \eqref{opt2} in a weak way by requiring  strong conditions on the set of initial data. This leads to require that entropy solutions of \eqref{eq} have a finite number of non-interacting jumps.
  When $J_0$ is weakly differentiable,  gradient descent  methods have been implemented in [1,5,6] to solve numerically the optimal problem \eqref{opt2}. In the cases where it was applied successfully, only one possible initial datum emerges, namely the backward entropy solution $S_T^-(u^T)$. This is mainly due to the numerical viscosity that numerical schemes introduce to gain stability. To find some multiple minimizers, the authors in  [8]  use a filtering step in the backward adjoint solution.


Dans [9], we fully characterize the set of minimizers of the optimal control problem \eqref{opt2}.

Theorem 1.  Let $u^T\in BV(\mathbb R)$. The optimal control problem \eqref{opt2}  admits multiple optimal solutions. Moreover, for a.e $T&amp;gt;0$, the initial datum $u_0\in BV(\mathbb R)$ is an optimal solution of \eqref{opt2} if and only if $u_0 \in BV(\mathbb R)$ verifies $S_T^+(u_0)=S_T^+ (S_T^-(u^T))$.

A characterisation of the set  is given in [7]. An illustration of Theorem 1. is given in Figure 1.


Figure 1: The backward-forward  solution $S_T^+(S_T^-(u^T))$ is the projection of $u^T$ onto the set of attainable target functions. The shaded area in red at time $t=0$ represents the set of minimizers of \eqref{opt2} 

The proof of Theorem 1 is structured as follows. From [7, Theorem 3.1, Corollary 3.2] or [8, Corollary 1], there exists $u_0\in BV(\mathbb R)$ such that  if and only if  satisfies  the one-sided Lipschitz condition, i.e 

 Thus, the optimal problem \eqref{opt2} can be rewritten as  follows.



where the admissible set $\mathcal{U}^T_{\text{ad}}$ is defined by



Above, $K_1$ an open bounded interval large enough.  Note that the optimal problem \eqref{opt5} is not related to the PDE model \eqref{eq}. We prove that $q=S_T^+ (S_T^-(u^T))$ is a critical point of \eqref{opt5} using the first-order optimality conditions applied to \eqref{opt5} and the full characterization of the set  given in [9, Theorem A.2].

Numerical simulations

In [9,Section 3], we  implement a wave-front tracking algorithm to construct numerically the set of  minimizers of \eqref{opt2}.  We consider for instance, a target function   defined by



From Theorem 1,  the backward solution  is an  optimal solution of \eqref{opt2} and   is an optimal solution of \eqref{opt2} if and only if  . In Figure 2, the target function , the backward solution  and  the backward-forward solution  are plotted.



    
        
        
        
        
        
        
    
    
        
        $x\to S^{-}_T(u^T)(x)$ 
        
        
        $(t,x)\to S^{+}_t(S^{-}_T(u^T))(x)$ 
         
    




$u^T$  and $\color{red}{x\to S^{+}_T(S^{-}_T(u^T))(x)}$ 
$ $
Figure 2. Plotting of the target function $u^T$ defined in \eqref{uT}, the optimal solution $S_T^-(u^T)$ and the backward-forward solution $\color{red}{S^{+}_T(S^{-}_T(u^T))}$.

Note that  has four different shocks located at $x=1.1$, $x=3.1$, $x=5.3$ and $x=7.2$. If we use a conservative numerical method as Godunov scheme,  the approximate solution of  doesn’t have shocks because of numerical viscosity that numerical schemes introduced, see Video 1.



    
        
            
        
        
            
        
    


Video 1. Approximate solution of $S_T^+(u_0)$ with $u_0$ an $N$-wave constructed with $ \color{red}{\text{a wave-front tracking algorithm}}$ and $\color{blue}{\text{a Godunov scheme}}$ 

This implies that only one minimizer of \eqref{opt2} can be constructed using a Godunov scheme, which is the backward entropy solution $S_T^-(u^T)$. When a wave-front tracking algorithm is implemented, the approximate solution of $S_T^+(S_T^-(u^T))$ has shocks since we track the possible discontinuities from $u^T$ to  $S_T^+(S_T^-(u^T))$. This implies that all initial data $u_0$ that coincide with the approximate solution of $S_T^+ (S_T^-(u^T))$ can be recovered, see [9,Section 3].

In Video 2, we show that the weak-entropy solution of \eqref{eq}  with initial data $S_T^-(u^T)$ coincides with $S_T^+ (S_T^-(u^T))$ at time $T$.


Video 2. Approximate solution of $(t,x) \to S_t^+(S_T^-(u^T))(x)$  using a wave-front tracking algorithm. 

In Video 3, three other approximate optimal solutions $u_0$ of \eqref{opt2} are constructed. In particular, we show that  $S_T^+ (u_0)=S_T^+ (S_T^-(u^T))$.



    
        
            
        
        
            
        
    

    
                
            
    
    



Video 3. Three approximate optimal solutions of \eqref{opt2} constructed using a wave-front tracking algorithm 

[1] Navid Allahverdi,  Alejandro Pozo and Enrique Zuazua. Numerical aspects of large-time optimal control of Burgers equation. ESAIM: Mathematical Modelling and Numerical Analysis, 50 (5):1371-1401,2016.

[2]  Navid Allahverdi,  Alejandro Pozo and Enrique Zuazua. Numerical aspects of sonic-boom minimization. A panorama of Mathematics: Pure and Applied, 658:267,2016.

[3] François Bouchut and François James. One-dimensional transport equations with discontinuous coefficients. Nonlinear Analysis, 32(7):891,1998.

[4] Alberto Bressan and Andrea Marson. A maximum principle for optimally controlled systems of conservation laws. Rendiconti del Seminario Matematico della Universita di Padova, 94:79-94, 1995.

[5] Carlos Castro, Francisco Palacios and Enrique Zuazua. An alternating descent method for the optimal control of the inviscid Burgers equation in the presence of shocks. Mathematical Models and Methods in Applied Sciences, 18(03):369-416,2008.

[6] Carlos Castro, Francisco Palacios and Enrique Zuazua. Optimal control and vanishing viscosity for the Burgers equation. In Integral Methods in Science and Engineering, Volume 2, pages 65-90. Springer, 2010.

[7] Rinaldo Colombo and Vincent Perrollaz. Initial data identification in conservation laws and Hamilton-Jacobi equations. arXiv preprint arXiv:1903.06448,2019.

[8] Laurent Gosse and Enrique Zuazua. Filtered gradient algorithms for inverse design problems of one-dimensional Burgers equation. In Innovative algorithm and analysis, pages 197-227. Springer, 2017.

[9] Thibault Liard and Enrique Zuazua. Inverse design for the one-dimensional Burgers equation. Submitted (2019).
</description>
        <pubDate>Thu, 12 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0007</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0007</guid>
        
        
        <category>tutorial</category>
        
        <category>WP04</category>
        
      </item>
    
      <item>
        <title>Inverse design for the one-dimensional Burgers equation</title>
        <description>The problem

We consider the following one-dimensional Burgers equation



where $u$ is the state, $u_0$ is the initial state and  the flux function $f$ is defined by $f(u)=\frac{u^2}{2}$. Kruzkov’s theory  provides existence and uniqueness of a  solution  of \eqref{eq} with initial datum $u_0 \in L^{\infty}(\mathbb R)$. This solution is called a weak-entropy solution, denoted by $(t,x) \to S_t^+(u_0)(x)$. For a given target function $u^T$, we introduce the backward entropy  solution $(t,x) \to S^-_{t}(u^T)(x)$  as follows: 
for every $t\in [0,T]$, for a.e $x\in \mathbb R$,



We study the problem of inverse design for \eqref{eq}. This problem consists in  identifying the set of initial data evolving to a given target at a final time.

Due to the time-irreversibility of the Burgers equation, some target functions are unattainable from weak-entropy solutions of this equation, making the inverse problem under consideration ill-posed. To get around this issue, we introduce the following  optimal control problem



where $u^T$ is a given target function and the class of admissible initial data $\mathcal{U}^0_{\text{ad}}$ in \eqref{opt2} is defined by



Above,  stands for functions of bounded variation and  $C&amp;gt;0$ is a constant large enough. The study of \eqref{opt2} is motivated by the minimization of the sonic boom effects generated by supersonic aircrafts [2].

To solve the optimal control problem \eqref{opt2}, some difficulties arise from a  theoretical  and  numerical point of view.

  Since the  entropy solution $u$ of \eqref{eq} may contain shocks even if the initial datum is a smooth function, this generates important added difficulties that have been the object of intensive study in the past, see  [3,4] and the references therein. In particular, the authors make sense of the derivative of $J_0$ in \eqref{opt2} in a weak way by requiring  strong conditions on the set of initial data. This leads to require that entropy solutions of \eqref{eq} have a finite number of non-interacting jumps.
  When $J_0$ is weakly differentiable,  gradient descent  methods have been implemented in [1,5,6] to solve numerically the optimal problem \eqref{opt2}. In the cases where it was applied successfully, only one possible initial datum emerges, namely the backward entropy solution $S_T^-(u^T)$. This is mainly due to the numerical viscosity that numerical schemes introduce to gain stability. To find some multiple minimizers, the authors in  [8]  use a filtering step in the backward adjoint solution.


Dans [9], we fully characterize the set of minimizers of the optimal control problem \eqref{opt2}.

Theorem 1.  Let $u^T\in BV(\mathbb R)$. The optimal control problem \eqref{opt2}  admits multiple optimal solutions. Moreover, for a.e $T&amp;gt;0$, the initial datum $u_0\in BV(\mathbb R)$ is an optimal solution of \eqref{opt2} if and only if $u_0 \in BV(\mathbb R)$ verifies $S_T^+(u_0)=S_T^+ (S_T^-(u^T))$.

A characterisation of the set  is given in [7]. An illustration of Theorem 1. is given in Figure 1.


Figure 1: The backward-forward  solution $S_T^+(S_T^-(u^T))$ is the projection of $u^T$ onto the set of attainable target functions. The shaded area in red at time $t=0$ represents the set of minimizers of \eqref{opt2} 

The proof of Theorem 1 is structured as follows. From [7, Theorem 3.1, Corollary 3.2] or [8, Corollary 1], there exists $u_0\in BV(\mathbb R)$ such that  if and only if  satisfies  the one-sided Lipschitz condition, i.e 

 Thus, the optimal problem \eqref{opt2} can be rewritten as  follows.



where the admissible set $\mathcal{U}^T_{\text{ad}}$ is defined by



Above, $K_1$ an open bounded interval large enough.  Note that the optimal problem \eqref{opt5} is not related to the PDE model \eqref{eq}. We prove that $q=S_T^+ (S_T^-(u^T))$ is a critical point of \eqref{opt5} using the first-order optimality conditions applied to \eqref{opt5} and the full characterization of the set  given in [9, Theorem A.2].

Numerical simulations

In [9,Section 3], we  implement a wave-front tracking algorithm to construct numerically the set of  minimizers of \eqref{opt2}.  We consider for instance, a target function   defined by



From Theorem 1,  the backward solution  is an  optimal solution of \eqref{opt2} and   is an optimal solution of \eqref{opt2} if and only if  . In Figure 2, the target function , the backward solution  and  the backward-forward solution  are plotted.



    
        
        
        
        
        
        
    
    
        
        $x\to S^{-}_T(u^T)(x)$ 
        
        
        $(t,x)\to S^{+}_t(S^{-}_T(u^T))(x)$ 
         
    




$u^T$  and $\color{red}{x\to S^{+}_T(S^{-}_T(u^T))(x)}$ 
$ $
Figure 2. Plotting of the target function $u^T$ defined in \eqref{uT}, the optimal solution $S_T^-(u^T)$ and the backward-forward solution $\color{red}{S^{+}_T(S^{-}_T(u^T))}$.

Note that  has four different shocks located at $x=1.1$, $x=3.1$, $x=5.3$ and $x=7.2$. If we use a conservative numerical method as Godunov scheme,  the approximate solution of  doesn’t have shocks because of numerical viscosity that numerical schemes introduced, see Video 1.



    
        
            
        
        
            
        
    


Video 1. Approximate solution of $S_T^+(u_0)$ with $u_0$ an $N$-wave constructed with $ \color{red}{\text{a wave-front tracking algorithm}}$ and $\color{blue}{\text{a Godunov scheme}}$ 

This implies that only one minimizer of \eqref{opt2} can be constructed using a Godunov scheme, which is the backward entropy solution $S_T^-(u^T)$. When a wave-front tracking algorithm is implemented, the approximate solution of $S_T^+(S_T^-(u^T))$ has shocks since we track the possible discontinuities from $u^T$ to  $S_T^+(S_T^-(u^T))$. This implies that all initial data $u_0$ that coincide with the approximate solution of $S_T^+ (S_T^-(u^T))$ can be recovered, see [9,Section 3].

In Video 2, we show that the weak-entropy solution of \eqref{eq}  with initial data $S_T^-(u^T)$ coincides with $S_T^+ (S_T^-(u^T))$ at time $T$.


Video 2. Approximate solution of $(t,x) \to S_t^+(S_T^-(u^T))(x)$  using a wave-front tracking algorithm. 

In Video 3, three other approximate optimal solutions $u_0$ of \eqref{opt2} are constructed. In particular, we show that  $S_T^+ (u_0)=S_T^+ (S_T^-(u^T))$.



    
        
            
        
        
            
        
    

    
                
            
    
    



Video 3. Three approximate optimal solutions of \eqref{opt2} constructed using a wave-front tracking algorithm 

[1] Navid Allahverdi,  Alejandro Pozo and Enrique Zuazua. Numerical aspects of large-time optimal control of Burgers equation. ESAIM: Mathematical Modelling and Numerical Analysis, 50 (5):1371-1401,2016.

[2]  Navid Allahverdi,  Alejandro Pozo and Enrique Zuazua. Numerical aspects of sonic-boom minimization. A panorama of Mathematics: Pure and Applied, 658:267,2016.

[3] François Bouchut and François James. One-dimensional transport equations with discontinuous coefficients. Nonlinear Analysis, 32(7):891,1998.

[4] Alberto Bressan and Andrea Marson. A maximum principle for optimally controlled systems of conservation laws. Rendiconti del Seminario Matematico della Universita di Padova, 94:79-94, 1995.

[5] Carlos Castro, Francisco Palacios and Enrique Zuazua. An alternating descent method for the optimal control of the inviscid Burgers equation in the presence of shocks. Mathematical Models and Methods in Applied Sciences, 18(03):369-416,2008.

[6] Carlos Castro, Francisco Palacios and Enrique Zuazua. Optimal control and vanishing viscosity for the Burgers equation. In Integral Methods in Science and Engineering, Volume 2, pages 65-90. Springer, 2010.

[7] Rinaldo Colombo and Vincent Perrollaz. Initial data identification in conservation laws and Hamilton-Jacobi equations. arXiv preprint arXiv:1903.06448,2019.

[8] Laurent Gosse and Enrique Zuazua. Filtered gradient algorithms for inverse design problems of one-dimensional Burgers equation. In Innovative algorithm and analysis, pages 197-227. Springer, 2017.

[9] Thibault Liard and Enrique Zuazua. Inverse design for the one-dimensional Burgers equation. Submitted (2019).
</description>
        <pubDate>Thu, 12 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0006</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0006</guid>
        
        
        <category>tutorial</category>
        
        <category>WP04</category>
        
      </item>
    
      <item>
        <title>Optimal Control Problem with CasADi on null-controllability of the network system</title>
        <description>This code needs the installation of CasADi 3.4.5: https://web.casadi.org/get/

The objectives of this post are twofold, one is to introduce CasADi (with IpOpt) to simulate optimal control problem, and the other is to introduce the concept of the structural controllability, as an example, for the 2D heat equation.

Controllability of the 2D heat equation

In this post, we simulate structural controllability for the two-dimensional heat equation. First, we start with the finite difference scheme of the 2D Heat equation and the control on one boundary of the square domain $[0,1]^2$.



A similar problem has been treated in another DyCon Blog post using AMPL and IpOpt, which deals with the one-dimensional fractional heat equation under positivity constraints. Here we use CasADi and IpOpt in Matlab language.

We will consider the problem of steering the initial datum:



to the final target $(1.5 \cdot \bar z_{i,j}(T))$, where $\bar z_{i,j}(T)$ is a reference solution from $z^0_{i,j}$ without control.

Problem formulation

Parameters for the problem:

N_size = 4; %% Space discretization for 1D
Nx = N_size^2; %% Space discretization for 2D
Nt = 20; %% Time discretization
T = 0.1; %% Final time

%% Discretization of the Space
xline_ = linspace(0,1,N_size+2);
[xmsf,ymsf] = meshgrid(xline_,xline_);
xline = xline_(2:end-1);
[xms,yms]   = meshgrid(xline,xline);

dx = xline(2) - xline(1);

%% Initial data
Y0_2d = zeros(N_size);
for i=1:N_size
    for j=1:N_size
        Y0_2d(i,j) = sin(xline(i)*pi)*sin(xline(j)*pi);
    end
end
Y0 = Y0_2d(:);


%% Definition of the dynamics : Y' = AY+BU
B = zeros(N_size^2,N_size); B(1:N_size,1:N_size) = eye(N_size); %% control for i=1,...,N_size.

A1_mat = ones(N_size,1);
A2_mat = spdiags([A1_mat -2*A1_mat A1_mat], [-1 0 1], N_size,N_size);
I_mat  = speye(N_size);
A_mat  = kron(I_mat,A2_mat)+kron(A2_mat,I_mat);

A = A_mat; %% A: Discrete Laplacian in 2D with uniform squared mesh

%% Discretization of the time : we need to check CFL condition to change 'Nt'.
tline = linspace(0,T,Nt+1); %%uniform time mesh

dt = tline(2)-tline(1);


The interactions between nodes (grid points) can be displayed as follows:

options_plot_graphs = {'LineWidth',2,'DisplayName','off','NodeColor','r','ArrowSize',9,'MarkerSize',7,'NodeLabel',{}};
p = plot(digraph(A),'XData',xms(:)','YData',yms(:)',options_plot_graphs{:});
hold on
plot(xms(:,1),yms(:,1),'b.','MarkerSize',30) %% Blue dots are controlled nodes
xlabel('x-axis')
ylabel('y-axis')
grid on
for i=1:N_size.^2
    text(p.XData(i)+0.01, p.YData(i)+0.02, num2str(i), 'FontSize', 20);
end




Fig 1. The interaction network of 'A_mat'. The controlled nodes are colored blue.

Now we may simulate the reference trajectory without control.

%% Simulation of the uncontrolled trajectory
M = eye(Nx) - 0.5*dt/dx.^2*A;
L = eye(Nx) + 0.5*dt/dx.^2*A;
P = 0.5*dt*B;

Y = zeros(Nx,Nt+1);

Y(:,1) = Y0;
for k=1:Nt %% loop over time intervals
   %% Crank-Nicolson method without control
   Y(:,k+1) = M\L*Y(:,k);
end
YT = Y(:,Nt+1);

ratio = 1.5;
Y1 = ratio*YT; %% Target data

clf
Z = reshape(Y(:,1),N_size,N_size);
Z = [zeros(1,N_size+2) ; zeros(N_size,1), Z, zeros(N_size,1) ; zeros(1,N_size+2)];
isurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.3);
isurf.CData = isurf.CData*0 + 10;
hold on
Z = reshape(Y(:,end),N_size,N_size);
Z = [zeros(1,N_size+2) ; zeros(N_size,1), Z, zeros(N_size,1) ; zeros(1,N_size+2)];
jsurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.7);
jsurf.CData = jsurf.CData*0 + 1;
jsurf.Parent.Color = 'none';
lightangle(10,10)
legend({'Initial Condition','Final Data'})



Fig 2. The initial condition and the final data of uncontrolled dynamics.

Optimization problem

From now on, we use CasADi to consider an exact control problem.

opti = casadi.Opti();  %% CasADi function

%% ---- Input variables ---------
X = opti.variable(Nx,Nt+1); %% state trajectory
U = opti.variable(N_size,Nt+1);   %% control

%% ---- Dynamic constraints --------
for k=1:Nt %% loop over control intervals
   %% Crank-Nicolson method : this helps us to boost the optimization
   opti.subject_to(M*X(:,k+1)== L*X(:,k) + 0.5*P*(U(:,k)+U(:,k+1)));
end

%% ---- State constraints --------
opti.subject_to(X(:,1)==Y0);
opti.subject_to(X(:,Nt+1)==Y1);

%% ---- Optimization objective  ----------
Cost = (dx*sum(sum(U.^2))*(T/Nt));
opti.minimize(Cost); %% minimizing L2 over time

%% ---- initial guesses for solver ---
opti.set_initial(X, Y);
opti.set_initial(U, 0);

%% ---- solve NLP              ------
p_opts = struct('expand',true);
s_opts = struct('max_iter',10000); %% iteration limitation

opti.solver('ipopt',p_opts,s_opts); %% set numerical backend
tic
sol = opti.solve();   %% actual solve
toc


This is Ipopt version 3.12.3, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:     2752
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:       84

Total number of variables............................:      420
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:      352
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  0.0000000e+00 6.69e-02 0.00e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  1.6511358e+02 6.66e-16 7.31e-07  -2.5 8.68e+01    -  1.00e+00 1.00e+00h  1
   2  1.6511358e+02 6.66e-16 2.39e-12  -8.6 5.47e-09    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 2

                                   (scaled)                 (unscaled)
Objective...............:   1.6511358437684962e+02    1.6511358437684962e+02
Dual infeasibility......:   2.3874235921539366e-12    2.3874235921539366e-12
Constraint violation....:   6.6613381477509392e-16    6.6613381477509392e-16
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   4.0210221040688533e-13    2.3874235921539366e-12


Number of objective function evaluations             = 3
Number of objective gradient evaluations             = 3
Number of equality constraint evaluations            = 3
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 3
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 2
Total CPU secs in IPOPT (w/o function evaluations)   =      0.822
Total CPU secs in NLP function evaluations           =      0.000

EXIT: Optimal Solution Found.
               t_proc [s]   t_wall [s]    n_eval
       nlp_f      1.9e-05      1.9e-05         3
       nlp_g     0.000103     0.000105         3
  nlp_grad_f      3.7e-05      3.4e-05         4
  nlp_hess_l      1.4e-05      1.3e-05         2
   nlp_jac_g     0.000185     0.000195         4
      solver         1.09        0.676         1
Elapsed time is 0.757156 seconds.



Post-processing

Sol_x = sol.value(X); %% solved controlled trajectory
Sol_u = sol.value(U); %% solved control function

clf
Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = reshape(Sol_x(:,end),N_size,N_size);
isurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.3);
isurf.CData = isurf.CData*0 + 10;
hold on
Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = reshape(Y(:,end),N_size,N_size);
jsurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.7);
jsurf.CData = jsurf.CData*0 + 1;

Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = ratio*reshape(Y(:,end),N_size,N_size);
plot3(xmsf,ymsf,Z,'k*')

jsurf.Parent.Color = 'none';
lightangle(10,10)

legend({'Controlled final data','Uncontrolled final data','Target'})




Fig 3. The final data of controlled and uncontrolled dynamics. The controlled data coinside with the target points.

%% Free and controlled dynamics in animation

Result_ref = zeros(N_size+2,N_size+2,Nt+1); %% displaying variable
Result_ref(2:end-1,2:end-1,:) = reshape(Y(:,:),[N_size,N_size,Nt+1]);

Result_con2d = zeros(N_size+2,N_size+2,Nt+1); %% displaying variable
Result_con2d(2:end-1,2:end-1,:) = reshape(Sol_x(:,:),[N_size,N_size,Nt+1]);
%% Free dynamics
fig = figure;
isurf2= surf(ratio*Result_ref(:,:,end),'FaceAlpha',0.3);
isurf2.CData = isurf2.CData*0 + 1;
hold on
isurf = surf(Result_ref(:,:,1),'FaceAlpha',0.7);
isurf.CData = isurf.CData*0 + 10;
title('Free dynamics')
legend('Target','Solution')
zlim([-0.5 1.5])
pause;
for it = 1:Nt+1
   isurf.ZData =  Result_ref(:,:,it);
    pause(0.1)
end
%% Controlled dynamics
clf
fig = figure;
isurf2= surf(ratio*Result_ref(:,:,end),'FaceAlpha',0.3);
isurf2.CData = isurf2.CData*0 + 1;
hold on
isurf = surf(Result_con2d(:,:,1),'FaceAlpha',0.7);
isurf.CData = isurf.CData*0 + 10;
title('Controlled dynamics')
legend('Target','Solution')
zlim([-0.5 1.5])
pause;
for it = 1:Nt+1
   isurf.ZData =  Result_con2d(:,:,it);
    pause(0.1)
end



   
      
         
      
      
         
      
   


Fig 4-5. Animations for the free and controlled dynamics. The target surface is also drawn in both dynamics, where free dynamics goes below than the target.

Structural controllability of the 2D heat equation

For the second part, we simulate another linear system to check the structural controllability of the 2D heat equation. It is known that its interacting network is structurally controllable by one sole node.

The following matrix ‘AS_mat’ links the nodes in a line, for example, 1-2-3-6-5-4-7-8-9 for $N=3$, which is a part of interactions in ‘A_mat’:

AC_mat = diag(ones(N_size-1,1),-1);
for j=1:2:N_size-2
    AC_mat = blkdiag(AC_mat,diag(ones(N_size-1,1),1));
    AC_mat(end,end-N_size)=1;
    if N_size==2
        break
    end
    AC_mat = blkdiag(AC_mat,diag(ones(N_size-1,1),-1));
    AC_mat(end-N_size+1,end-2*N_size+1)=1;
end
if length(AC_mat) &amp;lt; (N_size.^2)
    AC_mat = blkdiag(AC_mat,diag(ones(N_size-1,1),1));
    AC_mat(end,end-N_size)=1;
end

AS_mat = (AC_mat + AC_mat') - 2*eye(Nx);

options_plot_graphs = {'LineWidth',2,'DisplayName','off','NodeColor','r','ArrowSize',9,'MarkerSize',7,'NodeLabel',{}};
p = plot(digraph(AS_mat),'XData',xms(:)','YData',yms(:)',options_plot_graphs{:});
xlabel('x-axis');ylabel('y-axis')
hold on
plot(xms(1,1),yms(1,1),'b.','MarkerSize',30) %% Blue dots are controlled nodes
for i=1:N_size.^2
    text(p.XData(i)+0.01, p.YData(i)+0.02, num2str(i), 'FontSize', 20);
end

title('Network')
grid on




Fig 6. The interaction network of the new matrix 'AS_mat'. The controlled nodes are colored blue.

Since the 1D heat equation is controllable, ‘AS_mat’ is controllable by one node. However, it gets more and more difficult as the number of nodes increases, since it has different scale with the standard 1D heat equation. The length of the 1D domain grows as $N$ since it eventually become space filling curve in $[0,1]^2$.

Note also that ‘AS_mat’ has the nonzero elements in the positions that ‘A_mat’ has. By deleting several interactions of ‘A_mat’, ‘AS_mat’ is now exactly controllable with smaller controlled nodes. This is the idea of the structural controllability in the network system, called ‘network control’.

Problem formulation

B = zeros(N_size^2,1); B(1) = 1;
A = N_size.^2*AS_mat;
%% Y' = AY + BU

T = 0.1;
Nt = 30;
tline = linspace(0,T,Nt+1); %%uniform time mesh
dt = tline(2)-tline(1);

%% Simulation of the uncontrolled trajectory
M = eye(Nx) - 0.5*dt/dx.^2*A;
L = eye(Nx) + 0.5*dt/dx.^2*A;
P = 0.5*dt*B;

Y = zeros(Nx,Nt+1);
Y(:,1) = Y0;
for k=1:Nt %% loop over time intervals
   %% Crank-Nicolson method without control
   Y(:,k+1) = M\L*Y(:,k);
end
YT = Y(:,Nt+1);
Y1 = ratio*YT;


Optimization problem in CasADi

opti = casadi.Opti();  %% CasADi function

%% ---- Input variables ---------
X = opti.variable(Nx,Nt+1); %% state trajectory
U = opti.variable(1,Nt+1);   %% control

%% ---- Dynamic constraints --------
for k=1:Nt %% loop over control intervals
   %% Crank-Nicolson method
   opti.subject_to(M*X(:,k+1)== L*X(:,k) + P*(U(:,k)+U(:,k+1)));
end

%% ---- State constraints --------
opti.subject_to(X(:,1)==Y0);
opti.subject_to(X(:,Nt+1)==Y1);

%% ---- Optimization objective  ----------
Cost = (sum(U.^2)*(T/Nt)); %%1e3*dx^2*sum(sum((X(:,Nt+1)-Y1).^2))+;
opti.minimize(Cost); %% minimizing L2 at the final time

%% ---- Initial guess ----
opti.set_initial(X, Y);
opti.set_initial(U, 0);

%% ---- solve NLP              ------
p_opts = struct('expand',true);
s_opts = struct('max_iter',1e5); %% cut down the algorithm at the 1000-th iteration.
opti.solver('ipopt',p_opts,s_opts); %% set numerical backend
tic
sol = opti.solve();   %% actual solve
toc


This is Ipopt version 3.12.3, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:     2852
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:       31

Total number of variables............................:      527
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:      512
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  0.0000000e+00 1.04e-01 0.00e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  2.9522421e+04 1.33e-15 6.25e-02  -2.5 1.08e+03    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 1

                                   (scaled)                 (unscaled)
Objective...............:   2.9522420557910038e+04    2.9522420557910038e+04
Dual infeasibility......:   6.2500000000000000e-02    6.2500000000000000e-02
Constraint violation....:   1.3322676295501878e-15    1.3322676295501878e-15
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   1.4002321948103652e-12    6.2500000000000000e-02


Number of objective function evaluations             = 2
Number of objective gradient evaluations             = 2
Number of equality constraint evaluations            = 2
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 2
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 1
Total CPU secs in IPOPT (w/o function evaluations)   =      0.516
Total CPU secs in NLP function evaluations           =      0.000

EXIT: Optimal Solution Found.
               t_proc [s]   t_wall [s]    n_eval
       nlp_f      6.2e-05      1.4e-05         2
       nlp_g     0.000212       0.0001         2
  nlp_grad_f      4.3e-05      2.9e-05         3
  nlp_hess_l      3.2e-05      3.3e-05         1
   nlp_jac_g     0.000147     0.000148         3
      solver        0.668        0.573         1
Elapsed time is 0.638270 seconds.


Post-processing

Sol_x = sol.value(X); %% solved controlled trajectory
Sol_u = sol.value(U); %% solved control
%%Sol_x = opti.debug.value(X);
%%Sol_u = opti.debug.value(U); %% final data if algorithm stops with error

%%
clf
Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = reshape(Sol_x(:,end),N_size,N_size);
isurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.3);
isurf.CData = isurf.CData*0 + 10;
hold on
Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = reshape(Y(:,end),N_size,N_size);
jsurf = surf(xmsf,ymsf,Z,'FaceAlpha',0.7);
jsurf.CData = jsurf.CData*0 + 1;

Z = zeros(N_size+2,N_size+2);
Z(2:end-1,2:end-1) = ratio*reshape(Y(:,end),N_size,N_size);
plot3(xmsf,ymsf,Z,'k*')

jsurf.Parent.Color = 'none';
lightangle(10,10)

legend({'Controlled final data','Uncontrolled final data','Target'})




Fig 7. The initial condition and the final data of uncontrolled dynamics. It has a different structure compared to Fig 2.

%% Free and controlled dynamics in animation

Result_ref = zeros(N_size+2,N_size+2,Nt+1); %% displaying variable
Result_ref(2:end-1,2:end-1,:) = reshape(Y(:,:),[N_size,N_size,Nt+1]);

Result_con2d = zeros(N_size+2,N_size+2,Nt+1); %% displaying variable
Result_con2d(2:end-1,2:end-1,:) = reshape(Sol_x(:,:),[N_size,N_size,Nt+1]);

fig = figure;
isurf2= surf(ratio*Result_ref(:,:,end),'FaceAlpha',0.3);
isurf2.CData = isurf2.CData*0 + 1;
hold on
isurf = surf(Result_ref(:,:,1),'FaceAlpha',0.7);
isurf.CData = isurf.CData*0 + 10;
title('Free dynamics')
legend('Target','Solution')
zlim([-0.5 1.5])
pause;
for it = 1:Nt+1
   isurf.ZData =  Result_ref(:,:,it);
    pause(0.1)
end

%%
clf

fig = figure;
isurf2= surf(ratio*Result_ref(:,:,end),'FaceAlpha',0.3);
isurf2.CData = isurf2.CData*0 + 1;
hold on
isurf = surf(Result_con2d(:,:,1),'FaceAlpha',0.7);
isurf.CData = isurf.CData*0 + 10;
title('Controlled dynamics')
legend('Target','Solution')
zlim([-0.5 1.5])
pause;
for it = 1:Nt+1
   isurf.ZData =  Result_con2d(:,:,it);
    pause(0.1)
end


   
      
         
      
      
         
      
   

Fig 8-9. Animations for the free and controlled dynamics. The target surface is also drawn in both dynamics, where free dynamics goes below than the target.
</description>
        <pubDate>Thu, 07 Nov 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp06/P0006</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp06/P0006</guid>
        
        
        <category>tutorial</category>
        
        <category>WP06</category>
        
      </item>
    
      <item>
        <title>Movil control strategy for models with memory terms</title>
        <description>En este tutorial enseñaremos como implentar la estrategía del control interíor móvil para la ecuación del calor. En el ejemplo típico de control interior en la ecuación del calor se pretende llevar al sistema desde un estado inicial, $u_0$ hasta el estado nulo en todo el espacio, $\Omega$. Para ello se define una subconjunto, $\omega \in \Omega$, donde el control, $f(x,t)$ puede actuar, es decir que para puntos, $x \notin \omega$, el control es cero. Este problema se puede escribir como:



Donde $f$ es el control definido de solo en el subconjunto, $\omega \in \Omega$.

Es conocido que la controlabilidad de la ecuación del calor para todo tiempo esta asegurada, sin embargo en el caso de la ecuación del calor con términos de memoria este resultado no es válido. En este caso, eligiremos un problema con un término de memoria: $\int_0^t u(x,\tau)d\tau$. De esta forma el problema se puede escribir como:



Este resultado se puede vercuenado aplicamos un control LQR sobre ambos sistemas. El mínimo del funcional LQR en el primer sistema (Equation \ref{heatinterior}) estabiliza la dínamica mientras que el mínimo del funcional en el segundo caso queda muy lejos del equilibrio.




    
        
          
             
           
        
        
          
             
           
        
    
    
        
          
              Video 1: LQR in Heat equation (Equation \ref{heatinterior})
           
        
        
          
              Video 2:  LQR in Heat equation with memory (Equation \ref{heatinterior_memory})
           
        
     
    
        
          
              Podemos ver la evolucion de dos modelos, con un región de control, $\chi_{\omega}$, situado en la posición del elipsoide azul en la parte superior de la simulación. Podemos ver que el control LQR es eficaz para la ecuación del calor, sin embargo débil ante la presencia de término de memoria
           
        
     


En el articulo [1], se menciona la idea del control móvil de ….
….
….

Definición del función característica dependiente del espacio

Nuestro objetivo en esta sección es la construcción de una función que dado un punto, $\textbf{x} \in \Omega$, devuelva la función carácteristica correspondiente. Para el diseño de la función $\chi_{\omega(t)}$, se ha decidido que ni el tamaño, ni la orientación de $\omega$ cambia en el tiempo. De esta forma, una vez fijados el tamaño en las dos direcciones del espacio y la forma del subconjunto, obtenemos una función que solo depende de un punto $x\in \Omega$.

En esta simulación crearemos el subconjunto como un cuadrado que puede moverse en $\Omega$. este cuadrado se puede construir con una función $W(x)$ definida de la siguiente manera.



donde $\Theta(x)$ es la fución theta de heaviside. Dado que la función $\Theta(x)$, tiene una aproximación analítica, la función $W(x,a,b)$ puede ser suavizada, detalle que será de vital importancia para que se pueda calcular el gradiente de la restrición asociada a la dinámica cunado realizamos el problema de control óptimo.

Un representación gráfica de $W(x,a,b)$ permiter reconocer a esta función con valor unidad entre los valores $a$ y $b$ y nulo fuera de ellos.


  
    
      
    
  
  
    
      Figure 1: Representación gráfica de $W(x,a,b)$
    
  


La generalización de esta función en dos dimensiones en inmediata,



De esta forma dado $(x_{min}, x_{max}, y_{min}, y_{max})$, obtenemos la función característica dependiente solo de la posición de un solo punto.


  
    
       
    
  
  
    
      Video 3: Representación gráfica de  $W_{2D}$
    
  


Construcción de la dinámica

Para el sistema con memoria (Equation \ref{heatinterior_memory}), podemos introducir una nueva variable, $z(x,t)$ tal que:



De esta manera el sistema con memoria se convierte en un sistema acoplado de PDEs:



Dado que $\chi_{\omega}$ puede moverse, y ademas que queremos obtener la trayectoria óptima para el control móvil añadiremos al sistema una partícula que puede moverse en dos dimensiones, su posición vendrá denotada por, $\textbf{d} = (d_x,d_y)$, y su velocidad, $\textbf{v} = (v_x,v_y)$. Además añadiremos un control $\textbf{g}(t) = (g_x(t),g_y(t))$ que actuará como una fuerza que moverá el subconjunto $\chi_{\omega}$.

Entonces, el sistema total queda como:



Numerical Implementation

En este tutorial necesitaremos DyCon Toolbox, y CasADi. Dado que CasADi es una dependecia de DyCon Toolbox, podemos instalarlo de la siguiente forma

unzip('https://github.com/DeustoTech/DyCon-Computational-Platform/archive/master.zip')
addpath(genpath(fullfile(cd,'DyCon-toolbox-master'))
StartDyconPlatform


Podemos escribir la ecuación \ref{heatinterior_memory_z_all}, en su forma discreta:



Creamos las variables de mesh

% Create the mesh variables
clear;
Ns = 7;
Nt = 15;
xline = linspace(-1,1,Ns);
yline = linspace(-1,1,Ns);
[xms,yms] = meshgrid(xline,yline);


Creamos la matriz A, que contiene el laplaciano en 2D y la dinámica del control movil

A  = FDLaplacial2D(xline,yline);

Atotal = zeros(2*Ns^2+4,2*Ns^2+4);
%
Atotal( 1:Ns^2  , 1:Ns^2 ) = A;
%
Atotal( Ns^2+1 : 2*Ns^2   ,   1    :  Ns^2   )  =  eye(Ns^2);
Atotal(    1   :  Ns^2    , Ns^2+1 : 2*Ns^2  )  =  50*eye(Ns^2); % z = 50*y

RumbaMatrixDynamics = [0 0 1 0; ...
                       0 0 0 1; ...
                       0 0 0 0; ...
                       0 0 0 0 ];

             
Atotal(2*Ns^2+1:end,2*Ns^2+1:end) = RumbaMatrixDynamics;
Atotal = sparse(Atotal);


Greamos la función $B(\textbf{d}) = B(x_d,y_d)$
%%
% We create the B() function 
xwidth = 0.3;
ywidth = 0.3;
B = @(xms,yms,xs,ys) WinWP05(xms,xs,xwidth).*WinWP05(yms,ys,ywidth);
Bmatrix =  @(xs,ys) [diag(reshape(B(xms,yms,xs,ys),1,Ns^2)) ;zeros(Ns^2)];




Optimal Control Problem





opti = casadi.Opti();  % CasADi optimization structure

% ---- Input variables ---------
Ucas = opti.variable(2*Ns^2+4,Nt+1); % state trajectory
Fcas = opti.variable(Ns^2+2,Nt+1);   % control

% ---- Dynamic constraints --------
dUdt = @(y,f) Atotal*u+ [Bmatrix(u(end-3),u(end-2))*f(1:end-2) ; ...
                                         0                     ; ...
                                         0                     ; ...
                                     f(end-1)                  ; ...
                                     f(end)                    ]; 

% -----Euler backward method-------
for k=1:Nt % loop over control intervals
   y_next = Ucas(:,k) + (T/Nt)*dUdt(Ucas(:,k+1),dUdt(:,k+1)); 
   opti.subject_to(Ucas(:,k+1)==y_next); % close the gaps
end

% ---- State constraints --------
opti.subject_to(Ucas(:,1)==[Y0 ; 0.7 ; 0.7; -1.5 ; -1.5]);

% ---- Optimization objective  ----------
Cost = (Ucas(1:end-4,Nt+1))'*(Ucas(1:end-4,Nt+1));

opti.minimize(Cost); % minimizing L2 at the final time

% ---- initial guesses for solver ---
opti.set_initial(Ucas, Unum_free);
opti.set_initial(Fcas, 0);

% ---- solve NLP              ------
p_opts = struct('expand',false);
s_opts = struct('acceptable_tol',1e-4,'constr_viol_tol',1e-3,'compl_inf_tol',1e-3);
opti.solver('ipopt',p_opts,s_opts); % set numerical backend
tic
sol = opti.solve();   % actual solve
toc


Mvil Control



  
    
       
    
  



Video 3



</description>
        <pubDate>Mon, 04 Nov 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0011</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0011</guid>
        
        
        <category>tutorial</category>
        
        <category>WP05</category>
        
      </item>
    
      <item>
        <title>Numerical simulation of nonlinear Population Dynamics Structuring by age and Spatial diffusion</title>
        <description>In this tutorial, we propose the Hum method to approximate numerically the control in a null controllability problem for a non linear population dynamics model structuring in age and spatial diffusion.

For given the positive function $F$, we consider the following Population Dynamics Model Structuring by age and spatial diffusion:



where, $\Omega$ is a boundary subset of $\mathbb{R}^{N}$, $A$ is the maximal age and $T&amp;gt;0$ the final time. Also, $\Theta=\omega× (a_1,a_2)× (0,T),$ is the control support. Here, $\beta$ is the fertility rate depending also the age a, $\mu$ the mortality rate depending of the age a, $y_0$ the initial condition in $L^2(\Omega× (0,A)),$ $V$ is the control term and $y$ represent the density of the population of age $a$ at time $t$ and location $x∈ \Omega.$

We assume that the fertility rate $\beta$ and the mortality rate $\mu$ satisfy the demographic property:



and



where



The function $F,$ verify:



Numerical Simulations

In this part, the objective is to illustrate numerically the approximate null controllability of the nonlinear problem.

Indeed, we consider the following system:



Discretization and simulation of uncontrolled system

The idea in this part is to highlight the numerical simimulation of the nonlinear problem. The first parts is to reduce the PDE to the finite dimensional system of the form



where $A_l$ and $B$ are matrices, and



is the finite dimensional state and control vector. Here, VectorF is the contribution of the nonlinear part, which comes from births. So let’s consider the following system



where



To solve $(4)$, the space (dimension 1) and age discretization is performed with finite difference method on rectangular grid 
on $[0,L]\times [0,A]$. For a given rectangular grid $\mathcal{T}$ with vertex $(x_i,a_j)\quad 1\leq i\leq N,\quad 1\leq j\leq M$ and uniform step size (without loss of generality) $\Delta x$ in $x-$direction and $\Delta a$ in $a-$direction, we denote by  the diameter of the grid
The finite difference approximation of the diffusion term of the operator $\textbf{A}$ is given by



The finite difference approximation of the aging term of the operator A is given by



Let $y_{i,j}(t)$ be the approximation of $y(x_i,a_j)$ and



where $y_{i,j}$ is at the position $i+j*(N-1)$ and $A_l$ the matrix of the mortality approximation, the diffusion approximation and the aging approximation.

Take into account the newborns

We denote by $\beta(a),$ the fertility rate, the newborn is given by:



We approximate $\int_{0}^{A}\beta(a)y(x,a,t)da$ by



Then



But as



then



We create also the nonlinear vectorF from the births. Indeed, if we denote by



the matrix of the births,



and we define the vectorF by:



The corresponding discrete system is given for a continuous initial solution $y_0$ by



Example 1

Simulation of the uncontrolled system:

For the simulation, we take $L=1,\text{ } A=10\text{, }\Delta x=1/54\quad \Delta a= 5/54$ and $T=40$. Moreover $F(t)=t\Phi(t)$ a Globally Lipchitz function where



The fertility $\beta$ is given by:



here $v=1$, $\gamma=5$, $\alpha=7$ and the mortality rate $\mu$ by









Video 1. Evolution of the state of the uncontrolled system between t=0 and t=30 

We observe in this video the growth (aging) of news borns over time. We also notice the high birth rate of this population.

Construction of the control and numerical simulation

We construct the control problem, which consists in minimizing the functional and we choose the classical Hum functional and the control matrix $B=\chi_{\Theta}$ where $\Theta=(x_1,x_2)\times (a_1,a_2)\times (0,T),$ and we suppose that $U_T$ is the desired state:



Here $U_T=0.$
The approximate null controllability become the minimization of  the functional $J,$ where $(U_l,V_l)$ verify the following system



In this part the fertility $\beta$ is given by:



here $v=1$, $\gamma=5$, $\alpha=7$
 and



and $VectorF=(P_lU_l).^2$.This means that we consider that $F(t)=t^2$ which is globally lipchizt on a compact which is our case.

The system becomes:



Example 2

In this example, we take $ε=0.05$, $\Delta x=0.05$ and $\Delta a= 0.5$, with the initial condition



the following numerical results were obtained for $T=12$ and $\Delta t=120$.

Evolution of the control V between t=0 and t=12.



Video 2. Evolution of the state of controlled system between t=0 and t=12 

We notice that, with a control domain that takes into account the most populated part of the domain, the Hum method applied to the Casadi algorithm gives us an interesting approximative controllability result while maintaining the positivity of the density.
Evolution of the controlled state (density of the population) between t=0 and t=12.




Video 3. Evolution of the control function between t=0 and t=12 

Example 3

Here, we keep the same parameters of the Example 1 but we change the final time (here T=20) , and we take $\Delta x=1/18$, $Δ a=5/18$, $\epsilon=0.05$ the following numerical results were obtained:



Video 4. Evolution of the state of the controlled system between t=0 and t=20 





Video 4. Evolution of the state of the controlled system between t=0 and t=20 

Example 4

In this part we consider a smaller control domain. Indeed we take 
$\Theta =(0,2/5)\times(0,4)\times(0,T)$. 
In addition we also remove $\epsilon=0.001$ and $T=20.$ The rest is identical to the data of example 2.

We obtain the following numerical results:

Evolution of the control V between t=0 and t=20.





Video 4. Evolution of the state of the controlled system between t=0 and t=20 

Here although the result is acceptable, we notice that the state of the controlled system is negative for most of the time.
Evolution of the controlled state (the density of the population) between t=0 and t=20.





Video 5. Evolution of the control function between t=0 and t=20 
We notice here that the solution to the final time tends to 0, but during the time of control much of the state of the system was negative.
We notice that numerically we have approximation and the positivity of the state, if the support of the control covers the most populated part of the domain (space, age).

However it should be noted that we could not take a positivity constraint in our simulations. It should be noted that we have better approximations when we do not consider the cost of control.

References
[1] Dycon Toolbox

[2] CasaDi toolbox

[3] Luca Gerardo-Giorda: NUMERICAL APPROXIMATION OF DENSITY DEPENDENT DIFFUSION IN AGE-STRUCTURED POPULATION DYNAMICS
</description>
        <pubDate>Wed, 30 Oct 2019 00:00:00 +0100</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0012</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp05/P0012</guid>
        
        
        <category>tutorial</category>
        
        <category>WP05</category>
        
      </item>
    
      <item>
        <title>System Identification of PDE equations from data</title>
        <description>En esta entrada veremos como podremos estimar  el sistema dinámico apartir de datos sobre la evolución de este sistema.

Lo primero que haremos es inspeccionar de que datos disponemos
&amp;gt;&amp;gt; whos

  Name               Size                  Bytes  Class     Attributes

  solution         100x200x50            8000000  double              
  tspan              1x200                  1600  double    

En este caso tenemos 100 simulaciones de una ecuación diferencial
</description>
        <pubDate>Tue, 01 Oct 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/ot03/P0001</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/ot03/P0001</guid>
        
        
        <category>tutorial</category>
        
        <category>OT03</category>
        
      </item>
    
      <item>
        <title>Touchdown localization for the MEMS problem with variable dielectric permittivity</title>
        <description>Background and motivation

An idealized version of a MEMS device consists of two conducting plates connected to an electric circuit
(see Figure 1).
The upper plate is rigid and fixed while the lower one is elastic and fixed only at the boundary.
Initially the plates are parallel and at unit distance from each other.
When a voltage (difference of potential between the two plates) is applied, the lower
plate starts to bend and, if the voltage is large enough,
the lower plate eventually touches the upper one, conducting to the so-called  pull-in instability. In the mathematical framework, this phenomenon is known as quenching or  touchdown.
Such device can be used for instance as an actuator, a microvalve (the touching-down part closes the valve),
or a fuse.


  



 Figure 1:  Two-membrane MEMS device


We consider a well-known model for micro-electromechanical systems (MEMS)
with variable dielectric permittivity, based on the following parabolic equation with singular nonlinearity:



where $\Omega$ is a smoothly bounded domain of $\mathbb{R}^2$ and 
 is a Hölder continuous function in .

In this mathematical model, the domain $\Omega$ represents the shape of the elastic plate in the horizontal direction, the solution $u=u(t,x)$ measures its vertical deflection,
while the function $f(x)$ is proportional to the constant voltage and characterizes the varying dielectric permittivity of the elastic plate.
We can write the permittivity profile $f$ as follows:



where $\lambda&amp;gt;0$ is the applied voltage, $\varepsilon_0&amp;gt;0$ is the permittivity of the vacuum and $\varepsilon_1(x)$ is the dielectric permittivity of the material. 
As a key feature, in our model the permittivity of the elastic plate may be inhomogeneous,
and this can be used to trigger the properties of the device. 
We refer to [1],[4],[5] and the references therein for the full details of the model derivation.

It is well known that problem (\ref{quenching problem}) admits a unique maximal classical solution $u$.
We denote its maximal existence time by $T=T_f\in (0,\infty]$. Moreover,
under some largeness assumption on $f$, it is known that the maximum of $u$ reaches the value $1$
at a finite time, so that $u$ ceases to exist in the classical sense. This is what we call  touchdown in finite time $T_f&amp;lt;\infty$.
Actually, if we consider $f(x) = \lambda\dfrac{\varepsilon_0}{\varepsilon_1(x)}$,
it is well-known that there exists a positive $\lambda^\ast$, known as  pull-in voltage, which depends on $\Omega$ and $\varepsilon_1(x)$, such that

$\bullet \quad $ If $\lambda&amp;lt;\lambda^\ast$, then $T_f=\infty$ and the global classical solution converges to the minimal positive steady state.

$\bullet \quad $ If $\lambda&amp;gt;\lambda^\ast$, then $T_f&amp;lt;\infty$, and then touchdown occurs in finite time.

In the actual design of a MEMS device there are several issues that must be considered.
Typically, one of the design goals is to achieve the maximum possible stable steady-state with relatively small applied voltage $\lambda$.  Another consideration may be to increase the stable operating range of the device by increasing the pull-in voltage.
For other devices, such as micropumps and microvalves, where touchdown behavior is explicitly exploited,
it is of interest to be able to localize the touchdown points, or similarly, to be able to avoid touchdown in certain parts of the device.
Our approach to achieve this last goal is to consider a material with varying dielectric permittivity allowing us to localize the touchdown points by a suitable choice of the permittivity profile.

Results

We start by the definition of touchdown point.
A point $x = x_0$ is called a  touchdown or  quenching point if there exists a sequence ${(x_n , t_n )} \in \Omega\times (0, T)$ such that



The set of all such points is called the  touchdown or  quenching set, denoted by $\mathcal{T}=\mathcal{T}_f\subset\overline{\Omega}$.

We show in [2] that touchdown can actually be ruled out in subregions of $\Omega$ 
where $f$ is positive but suitably small, below a positive threshold.

 Theorem 1:
Let $\Omega\subset \mathbb{R}^n$ a smooth bounded domain and $f$ a function satisfying



There exists $\gamma_0&amp;gt;0$ depending only on $\Omega,M,\mu,r$ such that:

(i) $\quad$ For any $x_0\in \Omega$, if $f(x_0) &amp;lt;\gamma_0 {\hskip 1pt} \text{dist}^3 (x_0,\partial\Omega)$, then $x_0$ is not a touchdown point.

(ii) $\quad $ For any $\omega\subset\subset \Omega$, if $\displaystyle\sup_{x\in \overline{\Omega}\setminus \omega} f(x) &amp;lt;
\gamma_0 {\hskip 1pt} \text{dist}^3(\omega,\partial\Omega)$, then the touchdown set 
 is contained in $\omega$.

Roughly speaking, the statement (i) in the above theorem allows one to rule out touchdown in an interior point by choosing a permittivity profile which is sufficiently small at that point, while statement (ii) allows to design devices producing touchdown inside any given subset of $\Omega$ by choosing a permittivity profile concentrated in that subset.

Numerical Simulation 1:  no touchdown at the origin 

In our first example, we consider a circular elastic plate of radius 1, that is $\Omega = B(0,1)\subset\mathbb{R}^2$.
It is well known that if the dielectric permittivity is constant, the unique touchdown point is the center of the disk.

As consequence of Theorem 1 (i), we can prevent touchdown to occur at the origin by choosing a permittivity profile $f$ such that $f(0)$ is sufficiently small.
Let’s assume that the applied voltage $\lambda$, together with the permittivity of the vacuum $\varepsilon_0$ and the permittivity of the material $\varepsilon_1$ are such that



In this case, we might cover the center of the disk with a material with higher permittivity so that the value of $\varepsilon_1(x)$ in $B(0,1/4)$ is (for example) twice its value in $\Omega\setminus B(0,1/4)$.
That is, we consider the following permittivity profile:



The following video represents the evolution of the elastic plate from the rest position to the pull-in instability.
For the numerical simulation we have applied an implicit Crank-Nicolson scheme in polar coordinates with number of meshpoint $N=100$ in the radial interval $[0,1]$.







 Simulation 1:   Evolution of the elastic plate until pull-in instability (touchdown). The solution reaches the value 1 in a circumference and then, touchdown is avoided at the center of the plate.
In the schematic video, we remove the upper plate of the MEMS device in order to see the final profile of the solution.  


Numerical Simulation 2:  touchdown near a prescribed circumference 

Let us suppose now that we want our system to touch down in a circumference of radius near $0.7$.
This time we can use Theorem 1 (ii). We will choose a permittivity profile $f$ sufficiently concentrated near a circumference of radius $0.7$. Consider for example:



The following video represents the evolution of the elastic plate from the rest position to the pull-in instability. 
In Figure 2 below, we plot the radial final touchdown profile.
For the numerical simulation we have applied an implicit Crank-Nicolson scheme in polar coordinates with number of meshpoint $N=100$ in the radial interval $[0,1]$.







 Simulation 2:   Evolution of the elastic plate until pull-in instability (touchdown). The solution reaches the value 1 in a circumference of radius near $0.7$.
In the schematic video, we remove the upper plate of the MEMS device in order to see the final profile of the solution.  





 Figure 2:   Plot of the  radial touchdown profile. Observe that, as expected, touchdown occurs on a circumference of radius between $0.65$ and $0.75$. 


Nontrivial touchdown sets

In view of Theorem 1,
it is a natural question whether such smallness conditions are actually necessary, 
or whether touchdown could be shown to occur only at or near the maximum points of the permittivity profile $f$.
In this connection, using stability properties of the touchdown set,
in [2] we construct radial ‘‘M’‘-shaped profiles giving rise to 
single-point touchdown at the origin.

Numerical simulation 3:

For this example, we have considered the following radial M-shaped profile in a disk of radius 1:



For this profile, the unique touchdown point is at the origin, far away from the maxima of $f$.
Therefore, if we want to prevent touchdown at the origin, we need to choose a permittivity profile $f$ such that $f(0)$ is small enough (below a certain thershold).
For the numerical simulation we have applied an implicit Crank-Nicolson scheme in polar coordinates with number of meshpoint $N=100$ in the radial interval $[0,1]$.







 Simulation 3:   Evolution of the elastic plate until pull-in instability (touchdown). Although we consider a ''M''-shaped permittivity profile, the solution touches down only at the origin, far away from the maximum of $f$.
In the schematic video, we remove the upper plate of the MEMS device in order to see the final profile of the solution.  


Numerical simulation 4:

Another rather surprising example is the following radially increasing profile:



For this example, the unique touchdown point is the origin, which is actually the global minimum of  $f$. In [2], we give a rigorous proof of the existence of this kind of behaviors. It is based on a stability result of the touchdown set combined with the fact that single-point touchdown occurs for constant permittivity profiles.

For the numerical simulation we have applied an implicit Crank-Nicolson scheme in polar coordinates with number of meshpoint $N=100$ in the radial interval $[0,1]$.







 Simulation 4:   Evolution of the elastic plate until pull-in instability (touchdown). Although the permittivity profile is radially increasing,  the unique touchdown point is the origin, the minimum point of $f$.
In the schematic video, we remove the upper plate of the MEMS device in order to see the final profile of the solution.  


Quantitative results in 1 dimension

Motivated by practical considerations of MEMS design, our aim in [3] is to further investigate the 
touchdown localization problem
and to show that in one space dimension, where analytic computations can be made more precise,
one can obtain quite quantitative conditions.
Namely, we look for a lower estimate of the ratio $\rho$ between $f$ and its maximum,
below which no touchdown occurs on a subregion of $\Omega$.
Rather surprisingly, it turns out that, under suitable assumptions on $f$,
our methods yield values of
 the threshold-ratio $\rho$ which are not ‘‘small’’ but can actually be up to the order



which could hence be quite appropriate for robust practical use.

In order to give good estimates of the  ratio $\rho$, we shall consider two typical situations, which roughly correspond to a one-bump or a two-bump shape for the profile $f$. 
 The touchdown is ruled out in a subinterval respectively located between a bump and 
an endpoint of $\Omega$, or between two bumps.
The idea behind this is that the plate can be covered with two dielectric materials, 
one with a high permittivity and the other with a lower permittivity. We then seek for a ratio between the two permittivities, allowing to rule out touchdown in the low permittivity region.

Reduction to a finite-dimensional optimization problem

As a consequence of our method, the threshold-ratio $\rho$  is rigorously obtained as the solution of a suitable finite-dimensional optimization problem, with either three or four parameters. 
An advantage of our results is that they apply to large classes of configurations, so that detailed numerics need not be carried out to localize the touchdown set for particular cases.

For the precise statements of the results, as well as for a detailed study of the optimization problem and numerical estimates of the threshold ratio, we refer the lector to [3].
The Matlab codes to compute numerical estimates of the solution of the optimization problem are availabe at the beginig of the page.

Here we give two concrete examples in order to illustrate 
the results.
The threshold ratio is obtained by a simple numerical procedure applied to the finite-dimensional optimization problem. 
The following two figures represent some typical permittivity profiles $f(x)$ and the localization of the corresponding touchdown sets
 in the one-bump and two-bump cases respectively. 
The touchdown sets are localized in a neighborhood of the bumps, represented by the fat lines.


 



 Figure 3: An illustration of the localization of thouchdown set for a one-bump permittivity profile.
Here, the figure represents the permittivity profile $f$ and  not  the profile of the solution.







 Figure 4: An illustration of the localization of thouchdown set for a two-bump permittivity profile.
Here, the figure represents the permittivity profile $f$ and  not  the profile of the solution.


Numerical simulation 5:

We give an example of a one-bump permittivity profile, similar to the one in Figure 3.
Although our result applies to a large class of profiles, here we consider, for computational simplicity, the following bang-bang profile:



The following video represents  the evolution of a 1-dimensional membrane
with a one-bump permittivity profile $f$. 
For the numerical simulation we have applied an implicit Crank-Nicolson scheme with number of meshpoint $N=1000$ in the interval $[-6,6]$.







 Simulation 5:   Evolution of the elastic 1-dimensional membrane until pull-in instability (touchdown). We see that touchdown is localized in the region where $f$ is big (see Figure 3).  


Numerical simulation 6:

We give an example of a two-bump permittivity profile, similar to the one in Figure 4.
Although our result applies to a large class of profiles, here we consider, for computational simplicity,
the following bang-bang profile:



The following video represents  the evolution of a 1-dimensional membrane
with a two-bump permittivity profile $f$.
For the numerical simulation we have applied an implicit Crank-Nicolson scheme with number of meshpoint $N=1000$ in the interval $[-10,10]$.







 Simulation 6:   Evolution of the elastic 1-dimensional membrane until pull-in instability (touchdown). We see that touchdown is localized in the region where $f$ is big (see Figure 4).  


References

[1] P. Esposito, N. Ghoussoub, Y. Guo,  Mathematical analysis of partial differential equations modeling electrostatic MEMS. Courant Lecture Notes in Mathematics, 20. Courant Institute of Mathematical Sciences, New York; American Mathematical Society, Providence, RI, 2010. xiv+318 pp.

[2] C. Esteve, Ph. Souplet,  No touchdown at points of small permittivity and nontrivial touchdown sets for the MEMS problem. Advances in Differential Equations, Vol 24, Number 7-8(2019), 465-500.

[3] C. Esteve, Ph. Souplet,  Quantitative touchdown localization for the MEMS problem with variable dielectric permittivity. Nonlinearity} 31 4883 (2018).

[4] Ph. Laurençot, Ch. Walker,  Some singular equations modeling MEMS. Bull. Amer. Math. Soc. 54 (2017), 437-479.

[5] J.A. Pelesko, D.H. Bernstein,  Modeling MEMS and NEMS, Chapman Hall and CRC Press, 2002.
</description>
        <pubDate>Mon, 30 Sep 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/P0010</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/P0010</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>Uniform exponential and polynomial stability and approximation in control of a thermoelastic model</title>
        <description>The main objective of this blog is to explain numerically the difference between exponential and polynomial decay in term of energy and spectral properties. We Show also that system with polynomial decay are very  sensitive to the choice of initial data.

Model Problem

We consider the numerical approximation of the following coupled thermoelastic wave models





where $u(x,t)$ is the displacement (longitudinal or transverse, depending upon the application) at position $x$ along a bounded smooth domain $\Omega\subset\mathbb{R}$ and time $t$ , and $\theta(x,t)$ is the temperature deviation from the reference temperature at position $x$ and time $t$, $u_0(x)$, $v_0(x)$ and $\theta_0(x)$ are initial data in a suitable space. The small positive constant $\gamma$ is a thermo-mechanical coupling parameter and is generally small in comparison to 1. System (\ref{eq1}) differs from system $\eqref{eq2}$ at the coupling terms, where we have replaced the strong coupling ($\gamma\theta_x$ and $\gamma u_{tx}$) by a weak coupling ($\gamma\theta$ and $\gamma u_{t}$).

It is well known from literature that system (\ref{eq1}) and (\ref{eq2}) are respectively exponentially and polynomially stable, see [3,7] and [5,6,9].

In this post, we will show by numerical experiments, how the coupling terms affect quantitative and qualitative properties of thermoelastic systems (\ref{eq1}) and (\ref{eq2}). These results could be found in [8,10].

To do this, we consider a semi discretization version of both systems (\ref{eq1}) and (\ref{eq2}), obtained with finite element method, which has the following form



where for all $n\in\mathbb{N}$, $z_n=(u_n,v_n,\theta_n)^T$ is the semi discrete solution, $z_{n0}$ is the discretized initial data, $A_{i,n}$ the discretized dynamic and the subscript $\cdot_i$ refers to system (\ref{eq1}) and (\ref{eq2}) with



and $F_{2,n}=I_n$,



Spectral properties of thermoelastic systems

Figure 1 and Figure 2 show how the coupling terms affect the placement of eigenvalues of the dynamic $A_{n}$. In Figure 1, we see that a uniform distance between the eigenvalues and the imaginary axis is preserved, see Table 1. Another observation is that for fixed $n$, the eigenvalues of higher frequency modes, in particular, the one of the $n^{th}$ mode, are closer to the imaginary axis. Moreover, as the number of modes increases, these eigenvalues bend back towards the vertical line $\lambda=-\frac{\gamma^2}{2}$, a fact which has been already shown in [4]. Therefore, the corresponding spectral element approximation scheme preserves the property of exponential stability.

 Table 1. Distance between $\sigma(A_{1,n})$ and the imaginary axis form the spectral element method


    
        n
        $min \{ -Re(\Lambda),\Lambda \in \sigma(A_{1,n}) \}$
    
    
        8
        $8.9227x10^{-4}$
    
    
        16
        $8.9383x10^{-4}$
    
    
        24
        $8.9402x10^{-4}$
    
    
        32
        $8.9407x10^{-4}$
                


 Location of the complex eigenvalues of the matrix $A_{1,n}$ with the finite element method

error
Nx = 30;
stabexpsem(Nx);


Error using error
Not enough input arguments.

Error in tp1d0d1572_49d1_41a8_914f_f09a199a8ec3 (line 114)
error



In Figure 2, conversely to Figure 1 where a uniform distance between the eigenvalues and the imaginary axis is preserved, we observe that, as the number of modes increases, an asymptotic behaviour appears in the neighborhood of the imaginary axis at $\pm\infty$. This property is mainly related to systems with polynomial decay, see \cite{BEPS2006}.

 Location of the complex eigenvalues of the matrix $A_{2,n}$ with the finite

Nx = 30;
stabpolysem(Nx);


Uniform and polynomial decay of the energy

The discrete energy associated to system (\ref{eq3}) is given by



The discrete energy $E_{1,n}$ associated to system (ref{eq1}) decays exponentially to zero, see Figure 3, in the following sense: $\exists M,\alpha$ positive constants such that



However, the introduction of the weak coupling term in system (ref{eq1}) has changed the dynamic and consequently the behavior of energy (\ref{eq4}). In this case, we say that system (\ref{eq2}) decays polynomially to zero, see Figure 4, in the following sense: $\exists M,\alpha$ positive constants such that



 Exponential decay of $E_{1,n}(t)$

 Polynomial decay of $E_{2,n}(t)$

Effect of smoothness of the initial data on the rate of decay of energy

It has been shown theoretically, see [1,2], that the energy associated to system (\ref{eq2}) is very sensitive to the smoothness of its initial data. This fact, has been also observed numerically, see Figure 6. we use

Nx = 100;
FinalTime = 100;
dt = 0.5;
mode = 1;
Gamma = 0.2;
n = 100;
k= 2;


and we consider the following initial data

u0=zeros(1,n);
x = linspace(0,pi,100);
v0=sqrt(2/pi)*sin(k*x);
teta0=zeros(1,n);


Through Figure 6, we notice that for $j = 1$, the approximate energy $E_{2,n}(t)$ decays to zero as the time $t$ increases. Moreover, we observe that the decay rate depends strongly on $j$. That is, when $j$ increases, initial data are very oscillating. We say in this case that the rate of decay of the discrete energy $E_{2,n}(t)$ is very sensitive to the choice of the initial data. However, the behavior of the energy assosiated to system (\ref{eq1}) remains indifferent to the smoothness of initial data when $n\to\infty$, see Figure 5.

  Exponential decay of $E_{1,n}(t)$

  Polynomial decay of $E_{2,n}(t)$

References

[1] A. B' atkai, K.J. Engel, J. Pr&quot;uss and R. Schnaubelt, Polynomial stability of operator semigroups, Math. Nachr. 279, pp.

[2] A. Borichev and Y. Tomilov, Optimal polynomial decay of functions and operator semigroups, Math. Ann., 347(2), pp.455-478, 2010.

[3] S. W. Hansen, Exponential energy decay in a linear thermoelastic rod. J. Math. Anal. Appli.,167, pp. 429-442, 1992.

[4] F.A. Khodja, A. Benabdallah, and D. Teniou, Stability of coupled systems, Abstr. Appl. Anal. Volume 1, Number 3, 327-340, 1996.

[5] F. A. Khodja, A. Benabdallah and D. Teniou, Dynamical stabilizers and coupled systems}, ESAIM Proceeding,2, pp. 253-262, 1997.

[6] F. A. Khodja, A. Bader and A. Benabdallah, Dynamic stabilization of systems via decoupling techniques, ESAIM: COCV,4,

[7] Z. Liu and S. Zheng, Exponential stability of semigroup associated with thermoelastic system, Quart. Appl. Math, 51, pp.535-545, 1993.

[8] Z. Y. Liu and S. Zheng, Uniform exponential stability and approximation in control of a thermoelastic system, SIAM J. Control Optim. 32, pp. 1226-1246, 1994.

[9] Z. Liu and B. Rao, Characterization of polynomial decay rate for the solution of linear evolution equation. Zeitschrift  angewandte Mathematik und Physik ZAMP,56, pp. 630-644, 2005.

[10] L. Maniar and S. Nafiri, Approximation and uniform polynomial stability of C_0-semigroups,ESAIM: COCV 22, pp. 208-235, 2016.

</description>
        <pubDate>Thu, 18 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/P0009</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/P0009</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
  </channel>
</rss>
