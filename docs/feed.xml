<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DyCon Blog</title>
    <description>Welcome to the web interface of DyCon Toolbox, the computational platform developed within the &lt;a href='https://cmc.deusto.eus/dycon/' target='_blank'&gt;ERC DyCon - Dynamic Control&lt;/a&gt; project.</description>
    <link>https://deustotech.github.io/DyCon-Blog/</link>
    <atom:link href="https://deustotech.github.io/DyCon-Blog/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 20 Jun 2019 09:35:23 +0200</pubDate>
    <lastBuildDate>Thu, 20 Jun 2019 09:35:23 +0200</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>Optimal control of the obstacle problem</title>
        <description>asda
</description>
        <pubDate>Mon, 08 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0031</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0031</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>Rotors imbalance suppression by optimal control</title>
        <description>asda
</description>
        <pubDate>Mon, 08 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0029</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0029</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>Controllability to steady states of a reaction diffusion system and emergence of barriers.</title>
        <description>asda
</description>
        <pubDate>Fri, 05 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0028</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0028</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>Sparse sources identification through adjoint localization algorithm</title>
        <description>Model Problem

We consider the numerical approximation of the inverse problem for the linear advection-diffusion equation,



with $d$ being the diffusivity of the material and $v$ the direction of the advection.

Given a final time $T&amp;gt;0$ and a target function $u^\ast$ the aim is to identify the initial condition $u_0$ such that the solution, at time $t=T$, reaches the target $u^*$ or gets as close as possible to it. We assume that the initial condition $u_0$ is characterized as a combined set of sparse sources. This means that $u_0$ is a linear combination of unitary deltas with certain and possibly different weights, i.e:



We formulate the inverse problem using optimal control techniques. In particular, we consider the minimization of the following functional:



Space and time discretization

Letting $\textbf{u} : [0, T] \rightarrow \mathbb{R}^s$ where $s$ is the number of grid points on $\Omega$, we can write a general finite element (FE) discretization of the diffusion–advection equation in \eqref{modeleq} in a compact form as:



In order to get a time discretized version of the previous equation, we apply implicit Euler method with stepsize $\Delta t := T/N$ where $N$ is the total number of time steps. The numerical approximations to the solution are given by the vectors $\textbf{u}^n \approx \textbf{u}(t_n) \in \mathbb{R}^s$ with respect to the index $n=i\Delta t$ for $i=1,2,..,N$. Therefore, the fully discrete version of model equation is as follows,



Adjoint Algorithm for sparse source identification

The algorithm to be presented in this work for the sparse source identification of the linear diffusion-advection equation based on the adjoint methodology consists of two steps. Firstly, we use the adjoint methodology to identify the locations of the sources. Secondly, a least squares fitting is applied to find the corresponding intensities of the sources.

We have considered here a two-dimensional example with several sources to be identified in a multi-model environment. This means that the left half ($\Omega_1 = [0,1] \times [0,1]$) and the right half ($\Omega_2 = [1,2] \times [0,1]$) of the domain are modelled with different equations. In particular, the heat equation is used on $\Omega_1$ and the diffusion–advection equation is used on $\Omega_2$.

The initialization parameters look as follows:

N=30; %% space discretization points in y-direction
dx=1/(N+1); %% mesh size
t0=0; %% initial time
tf=0.1; %% final time
n=5; %% time discretization points
dt=(tf-t0)/n; %% stepsize
TOL=1e-5; %% stopping tolerance

d1=0.05; %% diffusivity of the material on the left sudomain
d2=0.05; %% diffusivity of the material on the left sudomain

%% advection components
vx=0;
vy=-3;

tau=dx^4; %% regularization parameter
epsilon=0.1; %% stepsize of the gradient descent method


We now compute the FE discretization matrices $M$, $A$ and $V$ that are respectively the mass matrix, the stiffness matrix and the advection matrix. For the FE discretization we assume equidistant structured meshes. In particular we use triangular elements and the classical pyramidal test functions are employed.

[M,A,V] = computeFEmatrices(N,d1,d2,vx,vy); %% Compute FE discretization matrices


A reference initial condition is chosen and we compute using the FE discretization specified above and implicit Euler in time its corresponding final state at time $T$. This final state will be considered the initial data of the inverse problem to be solved and we name it the target function $u^*$ as mentioned previously.

U0_ref = initial_deltas(N); %% computes reference initial condition

[U_target,u_target] = compute_target(U0_ref,N,n,dt,M,A,V); %% Compute target distribution


We now call the algorithm that estimates the initial condition $u_0$ using as a initial data the target function $u^*$. As mentioned before, this algorithm consists of two steps.

Firstly, the classical adjoint methodology that minimizes the functional $J(u_0)$ subject to the diffusion-advection equation is used. The iterative optimization algorithm employed is the classical gradient descent method. However, although this iterative procedure finds quite accurately the locations of the sources, it does not recover the sparse character of the initial condition. This is not suprising because the recovered initial data comes from solving the adjoint problem which is basically a diffusive process that smoothes out its state. Consequently, a second procedure is needed to project the obtained non sparse initial condition into the set of admissible sparse solutions.

As the initial condition $u_0$ is assumed to be a linear combination between the locations and the intensities, once we have fixed the locations using the adjoint methodology we can solve a least squares problem to get the remaining intensities. We assemble a matrix $\textbf{L} \in \mathbb{R}^{s \times l}$ where at each column we have the forward solution for a single unitary delta placed at each of the locations already identified. We then solve the following linear system of equations for the vector of unknowns $\alpha = (\alpha_1, \alpha_2, …, \alpha_l)^T$:



to find the intensities vector $\alpha$.

Adjoint algorithm for sparse source identification (algorithm 4)

U0 = SparseIdentification(u_target,TOL,dt,n,N,M,A,V,epsilon,tau);


Finally, the final state at $T$ is computed using as a initial condition the estimated sparse sources identified with our algorithm.

Compute final state with the recovered initial condition

[UF,u_final] = compute_target(U0,N,n,dt,M,A,V);


We can see the evolution recovered



We now visualize the numerical results. Plots on the left side show the reference initial solution and the given target. Similarly, plots on the right side show the recovered initial condition and the distribution at the final time $T$ produced by the recovered initial sources.

One can observe the difference between the two models (the heat equation on $\Omega_1$ and the diffusion-advection on $\Omega_2$) in the two figures at the bottom where the initial sources on $\Omega_2$ move downwards at the same time as they dissipate while the initial sources on $\Omega_1$ only dissipate without displacement.

xplot = linspace(0,2,2*N+3); %% space grid w.r.t component x
yplot = linspace(0,1,N+2); %% space grid w.r.t component y
%%
figure('unit','norm','pos',[0.25 0.1 0.5 0.8])
subplot(3,2,1)
surf(xplot,yplot,U0_ref)
shading interp;colorbar;colormap jet
title('Reference initial state (front view)')
subplot(3,2,2)
surf(xplot,yplot,U0)
shading interp;colorbar;colormap jet
title('Recovered initial state (front view)')
subplot(3,2,3)
pcolor(xplot,yplot,U0_ref)
shading interp;colorbar;colormap jet
title('Reference initial state (above view)')
subplot(3,2,4)
pcolor(xplot,yplot,U0)
shading interp;colorbar;colormap jet
title('Recovered initial state (above view)')
subplot(3,2,5)
pcolor(xplot,yplot,U_target)
shading interp;colorbar;colormap jet
title('Given target u^*')
subplot(3,2,6)
pcolor(xplot,yplot,UF)
shading interp;colorbar;colormap jet
title('Recovered final state')



</description>
        <pubDate>Fri, 14 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0014</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp04/P0014</guid>
        
        
        <category>tutorial</category>
        
        <category>WP04</category>
        
      </item>
    
      <item>
        <title>Controllability of a Class of Infinite Dimensional Systems with Age Structure</title>
        <description>
 Infinite dimensional dynamical systems coupling age structuring with diffusion appear naturally in
 population dynamics, medicine or epidemiology. A by now classical example is the Lotka-Mckendrick system with spatial diffusion. The
 aim of this blog is to study contaollability properties of such age structured models in an unified manner. 
 


Let $A : \mathcal{D}(A) \to X$  be the generator of a $C^0$ semigroup $\mathbb{S}$ on the Hilbert space $X$ and let $U$ be
another Hilbert space. Both $X$ and $U$ will be identified with their duals. Let $B$ be a (possibly unbounded) linear operator
from $U$ to $X$, which is supposed to be an admissible control operator for  $\mathbb{S}$.
In the examples we have in mind, the above spaces and operators describe the dynamics of a system without age structure.
In particular, $X$ is the state space and $U$ is the control space.
The corresponding age structured system is obtained by first extending these spaces to
\begin{equation} \label{input-space}
\mathcal{X} = L^{2}(0,a_{\dagger}; X), \quad \mathcal{U} = L^{2}(0,a_\dagger;U).
\end{equation} 
where $a_\dagger&amp;gt;0$ denotes the maximal age individuals can attain. Let $p(t) \in \chi$ be the distribution density of the
individuals with respect to age $a\geqslant 0$ and at some time $t \geqslant 0.$  Then the abstract version of the Lotka-McKendrick
system to be considered in this paper writes:
 \begin{equation} \label{eq:main}
\begin{cases}
\displaystyle \frac{\partial p}{\partial t} + \frac{\partial p}{\partial a} - A p  + \mu(a) p =  \mathcal{\chi}_{(a_{1},a_{2})} B u, &amp;amp; t \geqslant 0, a \in (0,a_\dagger), \\
\displaystyle p(t,0)  = \displaystyle \int_{0}^{a_\dagger} \beta(s) p(t,s) \; {\rm d}s, &amp;amp; t \geqslant 0, \\
\displaystyle p(0,a) = p_{0},
\end{cases}
\end{equation} 
where $\mathcal{\chi}$ is the characteristic function of the interval $(a_{1}, a_{2})$ with
$0 \leqslant a_{1} &amp;lt; a_{2} \leqslant a_\dagger$ and $p_{0}$ is the initial population density.
In the above system, the positive function $\mu:[0,a_\dagger] \to \mathbb{R}_{+}$ denotes the
natural mortality rate of individuals of age $a.$ We denote by $\beta: [0,a_\dagger] \to \mathbb{R}_{+}$
the positive function describing the fertility rate at age $a.$ We assume that the fertility rate $\beta$ a
nd the mortality rate $\mu$ satisfy the conditions

(H1) $\beta \in L^\infty[0, a_\dagger], \; \beta \geqslant 0$ for almost every $a \in [0,a_\dagger].$
(H2) $\mu \in L^1_{loc}[0, a_\dagger], \; \mu \geqslant 0$ for almost every $a \in [0,a_\dagger].$
(H3) $\displaystyle \int_0^{a_\dagger} \mu(a) \ {\rm d} a = \infty.$


Before we state our result, let us introduce the notion of null controllability of the pair $(A,B).$

We say that a pair $(A,B)$ is null-controllable in time $\tau,$ if for every $z_{0} \in X$ there exists a control $u \in L^{2}(0,\tau,U)$ such that, the solution of the system
\begin{equation*}
\dot z(t) = A z(t) + Bu(t) \quad t \in [0,\tau], \qquad z(0) = z_{0},
\end{equation*}
satisfies $z(\tau) = 0.$


We prove the following result

Assume that  $\beta$ and $\mu$ satisfy the conditions (H1)-(H3) above. Moreover,
suppose that the fertility rate $\beta$ is such that
\begin{equation} \label{eq:beta}
\beta(a)= 0 \mbox{ for all } a \in (0,a_{b}),
\end{equation}
for some $a_b\in (0,a_\dagger)$ and that $a_1 &amp;lt; a_b$.
Let us assume that the pair $(A,B)$ is null controllable in arbitrary time. 
Then for every $\tau &amp;gt; a_{1} + a_{\dagger}-a_{2}$ and for every $p_{0} \in \chi$ there exists  a control $v \in L^{2}(0,\tau;\mathcal{U})$ such that the solution $p$ of \eqref{eq:main} satisfies
\begin{equation}
p(\tau,a) = 0 \mbox{ for all }  a \in (0,a_\dagger).
\end{equation} 
 

It is well known that null controllability is equivalent to final state observability of the adjoint system
(see for instance [4, Section 11.2]). The adjoint of the above system reads as
\begin{equation} \label{eq:adj}
\begin{cases}
\displaystyle \frac{\partial q}{\partial t} - \frac{\partial p}{\partial a} - A^* p  + \mu(a) p - \beta(a) q(t,0) =  0, &amp;amp; t \geqslant 0, a \in (0,a_\dagger), \\
\displaystyle q(t,a_\dagger)  = 0, &amp;amp; t \geqslant 0, \\
\displaystyle q(0,a) = q_{0},
\end{cases}
\end{equation} 
where $A^*$ is the adjoint of  $A.$  In order to prove Theorem 1, it is enough to prove the following

 Let us assume the hypothesis of Theorem 1. Then for every $\tau &amp;gt; a_1 + a_\dagger - a_2$ there exists $k_\tau &amp;gt; 0$ such that
 the solution $q$ of \eqref{eq:adj} satishfies
 \begin{equation} \label{eq:est-adj}
 \int_0^{a_\dagger} \|q(\tau, a)\|^2_X \ da  \leqslant k_\tau^2 \int_0^\tau \int_{a_1}^{a_2} \left\|B^*q(t,a) \right\|^2_U \ da dt, \qquad \qquad (q_0 \in \mathcal{X}).
 \end{equation}
 
Let us give an idea of the proof. We combine characteristics method with final state observability of the pair $(A^*, B^*).$ For siplicity
in the presentation, let us assume that $\mu = 0,$ $a_1 = 0,$ $a_2 &amp;lt; a_b$ and $\tau = 2a_\dagger.$
The detail proof of Theorem 1, in a slightly more general case, can be found in [3]. Integrating along the characteristic lines,
it is not very difficult to see that
\begin{equation*}
q(t,a) = \int_{t + a - a_\dagger}^{t} e^{(t-s)A^*} \beta(a+ \tau - s) q(s, 0) \ ds, \qquad t &amp;gt; a_\dagger. 
\end{equation*}
Therefore,
\begin{equation} \label{est0}
\int_0^{a_\dagger} \|q(\tau, a)\|^2_X \ da \leqslant C \int_{a_\dagger}^\tau \left\|q(t,0) \right\|^2_X \ dt. 
\end{equation}
Thus to prove \eqref{eq:est-adj}, we need to estimate the right hand side of the above estimate. We now make use of the condition
\eqref{eq:beta}.  Note that, due to this condition, $q$ satisfies
\begin{equation} \label{eq:adj-2}
\displaystyle \frac{\partial q}{\partial t} - \frac{\partial q}{\partial a} - A^* p  + \mu(a) p =  0,  \quad  t \geqslant 0, a \in (0,a_2).
\end{equation}
For a.e. $t \in (a_\dagger, \tau),$ we define $w(s) = q(s, t- s),$ $s \in (t - a_2, t).$ Then $w$ solves
\begin{equation*}
\displaystyle \frac{\partial w}{\partial s} - A^* w = 0, \quad s \in (t - a_2, t). 
\end{equation*}
Since the pair $(A, B)$ is null controllable in any time, or equivalently the pair $(A^*, B^*)$ is final-state observable in any
time, there exists a constant
$C &amp;gt; 0,$ depending only on $a_2, A$ and $B$  such that
\begin{equation*}
\left\| w(t) \right\|_{X}^2 \leqslant C \int_{t-a_2}^t \left\| B^* w(s) \right\|^2_U \ ds. 
\end{equation*}
Coming back to $q$ and integrating over $[a_\dagger, \tau]$ with respect to $t,$ we have that
\begin{equation}
\int_{a_\dagger}^\tau \|q(t,0)\|^2_X \ dt \leqslant \int_{0}^\tau \int_{0}^{a_2} \left\|B^* q(t,a)\right\|^2  \ da dt. 
\end{equation}
Combining the above estimate together with \eqref{est0}, we get \eqref{eq:est-adj}. In the two figures below, we ilustrate the
estimate of $q(t,0)$ and the final-state observability of $q$ in the general case.



  
   
     
  
   Fig.1 - An ilustration of the estimate of $q(t,0).$ We apply final state observability of $(A^*, B^*)$ along
  the characteristics. Since we want to estimate $q(t,0),$ we consider the trajectory $\gamma(s) = (t-s,s),$
  $s \leqslant t \leqslant \tau$ (or equivalently the backward characteristics starting from $(t,0).$) 

    

    
  
   Fig.2 - An illustration of the final-state observability at time $\tau &amp;gt; a_1 + a_\dagger - a_2$: For
  $ a \in (0,a_2 - \varepsilon)$ (blue region) the backward characteristics starting from $t = \tau$ enters the
  observation domain.  For $a \in (a_2 - \varepsilon, a_\dagger)$, the backward characteristics (green region)
  hits the line $a = a_\dagger$, gets renewed by the renewal condition $\beta(a)q(t,0)$ and then enters the observation
  domain (purple region).
 
 
 
 

Examples
We consider two examples :  1) The classical Lotka-McKendrick system and 2) Lotka-Mckendrick system with diffusion.

 1)  The classical Lotka-McKendrick system : Let us choose $X = \mathbb{R},$ $A=0$ and $B=1.$ Then the system \eqref{eq:main} reduces
 to  classical Lotka-McKendrick system. By Theorem 1, this system is null controllable in time $\tau &amp;gt; a_1 + a_\dagger - a_2.$ A
 similar result was obtained in [1]. 



 2)  The Lotka-McKendrick system with spatial diffusion  : Let $\Omega$ be a smooth bounded domain in $\mathbb{R}^3$ and
 $\omega \subseteq \Omega.$ Let us consider 
 \begin{equation*}
 X = L^2(\Omega), \quad A = \Delta , \quad \mathcal{D}(A) =
 \left\{ f \in H^2(\Omega) \mid \displaystyle \frac{\partial f}{\partial n} = 0\right\}, \quad B = \chi_{\omega}.
 \end{equation*}
 This corresponds to the Lotka-McKendrick model with spatial diffusion ([2]). It is known that, the pair $(A, B)$ or equivalently
 the heat equation with localized interior control, is null controllable in any time. Thus we can apply Theorem 1 to conclude that
 the system is null controllable in time $\tau &amp;gt; a_1 + a_\dagger - a_2.$
 
 Several other applications can be found in [3].

References
 [1] D. Maity,  On the Null Controllability of the Lotka-Mckendrick System, Submitted. 
 [2] D. Maity, M. Tucsnak and E. Zuazua,  Controllability and positivity constraints in population dynamics with age
structuring and diffusion , Journal de Math&amp;eacute;matiques Pures et Appliqu&amp;eacute;s. In press, 10.1016/j.matpur.2018.12.006.

 [3] D. Maity, M. Tucsnak and E. Zuazua,  Controllability of a Class of Infinite Dimensional
Systems with Age Structure. Submitted.

 [4] M. Tucsnak and G. Weiss,  Observation and control for operator semigroups,   
Birkh&amp;auml;user Advanced Texts: Basler Lehrbu&amp;uuml;cher. [Birkh&amp;auml;user Advanced Texts: Basel Textbooks], Birkh&amp;auml;user Verlag, Basel, 2009. 

</description>
        <pubDate>Fri, 07 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0030</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0030</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>Finite Element approximation of the one-dimensional fractional Laplacian</title>
        <description>We describe here a Finite Element algorithm for the approximation of the one-dimensional fractional Laplacian $(-d_x^2)^s$ on the interval $(-L,L)$, $L&amp;gt;0$ and for the numerical resolution of the following fractional Poisson equation



This algorithm has also been emploied in [2,3] for the numerical controllability of fractional parabolic problems (see our previous entries in the DyCon Blog, WP3_P0001 and WP3_P0022).

We recall that the fractional Laplacian is defined, for all $s\in(0,1)$ and any function $u$ regular enough, as the following singular integral



with $c_s$ an explicit normalization constant given by



$\Gamma$ being the usual Euler Gamma function.

The starting point of the FE method is the definition of a bilinear form associated to the fractional Laplace operator $(-d_x^2)^s$ and the introduction of the variational formulation corresponding to the elliptic problem \eqref{Fl_Poisson}.

This variational formulation is given as follows: find $u\in H_0^s(-L,L)$ such that the identity



is satisfied for any function $v\in H_0^s(-L,L)$. In \eqref{variational}, with $H_0^s(-L,L)$ we indicate the space



$H^s(\mathbb{R})$ being the usual fractional Sobolev space. Moreover, the bilinear form



is defined as



Let us describe how, starting from the above bilinear form, we can obtain our FE approximation. For simplicity, in what follows we will take $L=1$, although the methodology remains the same for any real $L&amp;gt;0$.

Let us take a uniform partition of the interval $(-1,1)$ as follows:



with $x_{i+1}=x_i+h$, $i=0,\ldots N$. We call $\mathfrak{M}$ the mesh composed by the points ${x_i\,:\, i=1,\ldots,N}$, while the set of the boundary points is denoted $\partial\mathfrak{M}:={x_0,x_{N+1}}$.

Now, define $K_i:=[x_i,x_{i+1}]$ and consider the discrete space



where $\mathcal{P}^1$ is the space of the continuous and piece-wise linear functions. Hence, we approximate \eqref{variational} with the following discrete problem: find $u_h\in V_h$ such that



for all $v_h\in V_h$. If now we indicate with



a basis of $V_h$, it will be sufficient that the above equality is satisfied for all the functions of the basis, since any element of $V_h$ is a linear combination of them. Therefore the problem takes the following form



Clearly, since $u_h\in V_h$, we have $u_h(x) = \sum_{j=1}^N u_j\phi_j(x)$, where the coefficients $u_j$ are, a priori, unknown. In this way, \eqref{WFD} is reduced to solve the linear system $\mathcal A_h u=F$, where the stiffness matrix $\mathcal A_h\in \mathbb{R}^{N\times N}$ has components



while the vector $F\in\mathbb{R}^N$ is given by $F=(F_1,\ldots,F_N)$ with



Moreover, the basis



that we will employ is the classical one in which each $\phi_i$ is the tent function with $supp(\phi_i)=(x_{i-1},x_{i+1})$ and verifying $\phi_i(x_j)=\delta_{i,j}$. In particular, for $x\in{x_{i-1},x_i,x_{i+1}}$ the $i^{th}$ function of the basis is explicitly defined as (see Figure 1)




Figure 1. Basis function $\phi_i$ on its support $(x_{i-1},x_{i+1})$.

We now start building the stiffness matrix $\mathcal A_h$ approximating the fractional Laplacian. This will be done in three steps, since the values of the matrix can be computed differentiating among three well defined regions: the upper triangle, corresponding to $j\geq i+2$, the upper diagonal corresponding to $j=i+1$ and the diagonal, corresponding to $j=i$. In each of these regions the intersections among the support of the basis functions are different, thus generating different values of the bilinear form.

We present below an abridged explanation of how to compute the entries of $\mathcal{A}_h$. Complete details may be found in [2].

Step 1: $j\geq i+2$

In this case we have $supp(\phi_i)\cap supp(\phi_j) =\emptyset$ (see also Figure 2). Hence, \eqref{stiffness_nc} is reduced to computing only the integral




Figure 2. Basis functions $\phi_i(x)$ and $\phi_j(x)$ for $j\geq i + 1$. The supports are disjoint.

Taking into account the definition of the basis function \eqref{basis_fun}, the integral \eqref{elem_noint_app} becomes



Let us introduce the following change of variables:



Then, rewriting (with some abuse of notations since there is no possibility of confusion) $\hat{x}=x$ and $\hat{y}=y$, we get



This integral can be computed explicitly, and we obtain



Notice that, when $s=1/2$, both the numerator and the denominator of the expression above are zero. In this case, the value of $a_{i,j}$ can be obtained by taking the limit $s\to 1/2$ and we get



if $k\neq 2$ and



Step 2: $j= i+1$
This is the most cumbersome case, since it is the one with the most interactions between the basis functions (see Figure 3).


Figure 3. Basis functions $\phi_i(x)$ and $\phi_{i+1}(x)$. In this case, the intersection of the supports is the interval $[x_i,x_{i+1}]$.

Using the symmetry of the integral with respect to the bisector $y=x$, we have



Also in this case, the terms $Q_i$, $i=1,\ldots,6$, can be computed explicitely, by noticing also the following facts:


  $Q_1=Q_6=0$ since $\phi_i = 0$ on the domain of integration.
  $Q_2=Q_5$ due to symmetry.


Then, the elements $a_{i,i+1}$ are given by the sum $2Q_2+Q_3+Q_4$ and we have



Step 3: $j= i$
As a last step, we fill the diagonal of the matrix $\mathcal A_h$, which collects the values corresponding to $\phi_i(x)=\phi_j(x)$ (see Figure 4).


Figure 4. Basis functions $\phi_i(x)=\phi_j(x)$.

In this case, we have



Once again, the terms $R_i$, $i=1,\ldots,7$ can be computed explicitely, by taking also into account that $R_1=R_3=R_6=R_7=0$ because the corresponding integration domains are all away from the support of the basis functions.

The result of these computations gives the values



Step 4: building of $\mathcal A_h$

Summarizing, we have the following values for the elements of the stiffness matrix $\mathcal{A}_h$: for $s\neq 1/2$



For $s=1/2$, instead, we have



Numerical results

We present the numerical simulations corresponding to the algorithm previously described.

First of all, we test numerically the accuracy of our method for the resolution of the elliptic equation \eqref{Fl_Poisson} by applying it to the following problem



In this particular case, the unique solution $u$ can be computed exactly and it is given by



where $\chi_{(-1,1)}$ indicates the characteristic function of the interval $(-1,1)$.

The solution of \eqref{poisson} in the case  $s=0.1$ and $N=50$ is computed with the following script which emploies the function FEFractionalLaplacian.m ginving the FE discretization of $(-d_x^2)^s$.

s = 0.1;
N = 50;
L = 1;

x = linspace(-L,L,N+2);
x = x(2:end-1);
h = x(2)-x(1);

f = @(x) 1+0*x;
Phi = @(x) 1-abs(x);

F = zeros(N,1);

for i=1:N
    xx = linspace(x(i)-h,x(i)+h,N+1);
    xx = 0.5*(xx(2:end)+xx(1:end-1));
    B1 = f(xx).*(Phi((xx-x(i))/h));
    F(i) = ((2*h)/N)*sum(B1); 
end

A = FEFractionalLaplacian(s,L,N);
sol = A\F;


In Figure 5, we show a comparison for different values of $s$ between the exact solution \eqref{real_sol} and the computed numerical approximation.


Figure 5. Real and numerical solution.

One can notice that when $s=0.1$ (and also for other small values of s), the computed solution is to a certain extent different from the exact solution. Notwithstanding, it is well-known that the notion of trace is not defined for the spaces $H^s(-1,1)$ with $s\leq 1/2$. Hence, it is somehow natural that we cannot expect a point-wise convergence in this case.

Furthermore, the accuracy of our algorithm is validated by a simple error analysis.

The computation of the error in the space $H_0^s(-1,1)$ can be readily done by using the definition of the bilinear form, namely



where have used the orthogonality condition $a(v_h,u-u_h)=0$ for all $v_h \in V_h$.

For this particular test, since $f\equiv 1$ in $(-1,1)$, the problem is therefore reduced to



where the right-hand side can be easily computed, since we have the closed formula



and the term corresponding to $\int_{-1}^1u_h$ can be carried out numerically. Moreover, we have the following convergence result.

Theorem [2] For the solution $u$ of \eqref{WFD} and its FE approximation $u_h$ given by \eqref{WFD}, if $h$ is sufficiently small, the following estimates hold



where $\mathcal{C}$ is a positive constant not depending on $h$.

In Figure 6, we present the computational errors evaluated for different values of $s$ and $h$, which can be obtained with the following function.

function [h,e] = error_fl(s,N)

x = linspace(-1,1,N+2);
x = x(2:end-1);
h = x(2)-x(1);

f = @(x) 1+0*x;
Phi = @(x) 1-abs(x);

F = zeros(N,1);

for i = 1:N
    xx = linspace(x(i)-h,x(i)+h,N+1);
    xx = 0.5*(xx(2:end)+xx(1:end-1));
    B1 = f(xx).*(Phi((xx-x(i))/h));
    F(i) = ((2*h)/N)*sum(B1); 
end

A = FEFractionalLaplacian(s,1,N);
sol = A\F;
val = pi/(2^(2*s)*gamma(s+0.5)*gamma(s+1.5));
valnum = h*sum(sol);
e = sqrt(val-valnum);



Figure 6. Computational error in logarithmic scale in terms for different values of $s$.

The rates of convergence shown are of order (in $h$) of $1/2$, and this convergence rate is maintained also for small values of $s$. This confirms the accuracy of our approximation. In particular, the behavior shown in Figure 6 is not in contrast with the known theoretical results.

References

[1] G. Acosta, F. Bersetche and J. P. Borthagaray, A short FE implementation for a 2d homogeneous Dirichlet problem of a Fractional Laplacian. Comput. Math. Appl., Vol. 74, No. 4 (2017), pp. 784-816.

[2] U. Biccari and V. Hernández-Santamarı́a, Controllability of a one-dimensional fractional heat equation: theoretical and
numerical aspects. IMA J. Math. Control. Inf, to appear, 2018.

[3] U. Biccari, M. Warma and E. Zuazua, Controllability of the one-dimensional fractional heat equation under positivity constraints. Submitted.
</description>
        <pubDate>Fri, 07 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp05/WP99-P0024</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp05/WP99-P0024</guid>
        
        
        <category>tutorial</category>
        
        <category>WP05</category>
        
      </item>
    
      <item>
        <title>Propagation of one and two-dimensional discrete waves under finite difference approximation</title>
        <description>asda
</description>
        <pubDate>Fri, 07 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0023</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0023</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>A numerical method for solving an age structured virus model</title>
        <description>The aim of this tutorial is to give a numerical method for solving an age structured virus model.

Introduction

The virus infection mathematical models are proposing and studying for a long time (see for example C.L. Althaus, R.J. DE Boer [1] and F. Brauer, C. Castillo-Chavez [2]. In particular case of an HIV infection model (see for P. W. Nelson and al. [6]), the corresponding model is usually divided into three classes called  uninfected cells, $T$,  infected cells, $i$ and free virus particles, $V$.



schematic representation of HIV dynamic.

We refer the reader to [4] and [5] for more general class on nonlinear incidence rates that take into account the saturation phenomenon.

We consider an age-structured HIV infection model with a very general nonlinear infection function



with the boundary and initial conditions



We denote by



The number $R_0$ represents the expected number of secondary infections produced by a single infected cell during its lifetime,



The complete global stability analysis for the system (\ref{A}) has been studied in [4]. The system (\ref{A}) admits at most two equilibrium, from Theorem 3.1 and Theorem 5.2 in [4], we obtain the following result:


  
    If $R_0 \leqslant 1$, the disease free equilibrium $E_0=(\frac{A}{\mu},0,0)$ is globally asymptotically stable.
  
  
    If $R_0&amp;gt;1$, the positive infection equilibrium $E^{\ast}=(T^\ast,i^\ast,V^\ast)$ is globally asymptotically stable.
  


Numerical method

We consider the Beddington-Deangelis function $f$  defined by



In this case, the basic reproduction number ${\cal R}_0$  is given by



Where $\pi(a)=\exp^{-\int_{0}^{a} \delta (s) ds}$ and $N=\int_{0}^{\infty} p(a) \pi(a) da$.

The numerical method to solve this system of equation is based on the upwind method for solving hyperbolic partial differential equation, (see [3]) called also the FTBS method (Forward-Time-Backward-Space), has first-order accuracy in both space and time. The CFL condition is necessary for the stability of numerical solutions. The ODEs are solving by explicit Euler method.

we use a grid with points $(x_j,t_n)$ defined by



with age step $\Delta a$ and time step $\Delta t$. Denoting, respectively, by $T^n$, $i^n_j$ and $V^n$  the numerical approximation of $T(t_n)$, $i(t_n,a_j)$ and $V(t_n)$, moreover,

 we thus obtain the difference scheme of hyperbolic PDE



with $\lambda = \frac{\Delta t}{\Delta a}$. We fix the following values of parameters



with the initial conditions



The functions $p$ is given by



We change the values of $\tau_1$ in order to have $R_0 \leq 1$ or to have $R_0 &amp;gt; 1$.  If we choose $ \tau_1 = 3 $ then $ R_0 = 0.5417 &amp;lt; 1 $,

 

And if we choose $ \tau_1 = 0.5 $ then $ R_0 = 1.4216 &amp;gt; 1 $,

 

clear all,close all
a1=0;
a2=60;
Tf=300;
I0=@(t)4*exp(-0.3*t);
T0=20;
V0=5;
A0=2; mu=0.02; muc=0.4;
beta=0.1;
alpha1=0.1;
alpha2=0.2;
delta=0.4;
fct=@(x,y) (beta*x*y)/(1+alpha1*x+alpha2*y);
N=199;M=1200;
h=(a2-a1)/N;
k=Tf/M;
a=a1+(1:N)*h;
ap=[0,a];
t=0+(0:M)*k;
lambda=k/h;
C=eye(N);
A=(1-lambda)*C+lambda*diag(ones(1,N-1),-1);


The reproduction number $R_0$

R0=tauxR(N,h,a,delta,beta,muc,mu,A0,alpha1)



R0 =

    1.4216




T(1)=T0;
V(1)=V0;
U= I0(a(1:N))';  %% initial values
Up=[fct(T0,V0); U]; %% Initial value + Boundary condition
Uf=Up;

F=zeros(N,1);

UI=zeros(1,M);;

for j=1:M
    Uold=U;
      UI(j)=h*fct(T(j),V(j));
    for o=1:N
    UI(j)=UI(j)+h*Uold(o);
    end
    B=[lambda*fct(T(j),V(j)) ;zeros(N-1,1)];
    F=- delta*Uold ;
    U=A*Uold+B+k*F;
    val=feval(@int,Uold,N-1,h,a);
    T(j+1)=T(j)+k*(A0-mu*T(j)-fct(T(j),V(j)));
    V(j+1)=V(j)+k*(val - muc *V(j));
    Up=zeros(N+1,1);
    Up=[fct(T(j+1),V(j+1)); U];
    Uf=[Uf,Up];
end


 figure(1);
    [X , Y] = meshgrid( ap ,t);
 mesh (X , Y , Uf')
 title('The evolution of solution i(t,a)')
 xlabel('Age')
 ylabel('time')
 figure(2)
 plot(t,T','b',t,[UI UI(N+2)],'r',t,V','g')
 legend('S(t)','I(t)=\int i(t,a)da','R(t)')
 xlabel('Time')






References

[1]  R. J. De Boer C. L. Althaus. Dynamics of immune escape during hiv/siv infection, PloS Comput. Biol, 2008.

[2] F. Brauer and C. Castillo-Chavez. Mathematical Models in Population Biology and Epidemiology Springer, New York, 2000.

[3] L. Edsberg. Introduction to Computation and Modeling for Differential Equations, 2nd Edition. Wiley, 288 Pages, 2016.

[4] M. N. Frioui S. E. Miri, T. M. Touaoula. Unified lyapunov functional for an age-structured virus model with very general nonlinear infection response. J. Appl. Math. Comput, pages 1–27, 2017.

[5]  T. Kuniya J. Wang, R. Zhang.. Mathematical analysis for an age-structured hiv infection model with saturation infection rate, Elect. J. Diff. Eq, pages 1–19, 2015.

[6]  A. S. Perelson P. W. Nelson. Mathematical analysis of delay differential equation models of hiv-1 infection. Math. Biosc, 179, pages 73–94, 2002.

</description>
        <pubDate>Tue, 04 Jun 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/P0025</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/P0025</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
      <item>
        <title>Controllability of the one-dimensional fractional heat equation under positivity constraints</title>
        <description>In [2], we analyzed the controllablity properties under non-negative control and state constraints of the following heat-like equation involving the fractional Laplacian on $(-1,1)$



In \ref{frac_heat}, $\omega\subset (-1,1)$ is the control region in which the distributed control $u$ acts. Moreover, we denote by $(-d_x^2)^s$ the fractional Laplace operator defined, for all $s\in(0,1)$, as the following singular integral



with $c_s$ an explicit normalization constant given by



Gamma being the usual Euler Gamma function.

The main result we established are the following results:


  
    For any $s&amp;gt;1/2$, there exists $T&amp;gt;0$ such that the fractional heat equation \ref{frac_heat} is controllable to positive trajectories by means of a non-negative control $u\in L^\infty(\omega\times(0,T))$. Moreover, if the initial datum $z_0\geq 0$ is non-negative, we also have $z(x,t)\geq 0$ for every $(x,t)\in (-1,1)\times (0,T)$.
  
  
    If we define the minimal controllability time by
  




we have $T_{min}&amp;gt;0$.


  For $T = T_{min}$, there exists a non-negative control $u\in \mathcal M(\omega\times(0,T_{min}))$, the space of Radon measures
on $\omega\times(0,T_{min})$, such that the corresponding solution $z$ of \ref{frac_heat} satisfies $z(x,T) = \widehat{z}(x,T)$ a.e.
in $(-1,1)$.


These results extend to the fractional case the ones previously obtained by our team in the context of the linear and semi-linear heat equation (see our previous entries in the DyCon Blog, WP3_P0001 and WP3_P0002).

In this post, we present some numerical development in order to find the minimal controllability time for the discretized
fractional heat equation with non-negative control constraint and to confirm our theoretical results.

In particular, we will consider the problem of steering the initial datum



to the target trajectroy $\widehat{z}$ solution of \ref{frac_heat} with initial datum



and right-hand side $\widehat{u}\equiv 1$.

We choose $s=0.8$ and $\omega=(-0.3,0.8)\subset (-1,1)$ as the control region. The approximation of the minimal controllability time is obtained by solving the following constrained minimization problem.



subject to



To solve this problem numerically, we employ the expert interior-point optimization routine IpOpt combined with automatic differentiation and the modeling language AMPL. The interest of using AMPL together with IpOpt is that the gradient of the cost function and the constraints is automatically generated. Solving problems with IpOpt and AMPL can be made online through the NEOS solvers.

To perform our simulations, we apply a FE method for the space discretization of the fractional Laplacian (see [1]) on a uniform space-grid



with $N_x=20$ . Moreover, we use an explicit Euler scheme for the time integration on the time-grid



with $N_t$ satisfying the Courant-Friedrich-Lewy condition. In particular, we choose here $N_t=100$.

The AMPL code for solving this minimation problem is included below. In it, the matrices defining the dynamics are computed through specific functions implemented in Matlab and are given as parameters.

It is important to remark that we are interested in the controllability to the trajectory $\widehat{z}(\cdot,T)$ but, at the same time, $T$ is a variable in our code since it is the cost functional we aim to minimize. In view of that, our final target changes during the minimization process. Nevertheless this issue can be bypassed by taking advance of the linear nature of our equation and solving the traslated constrained minimization problem consisting in finding the minimial time for steering the inital datum $z_0-\widehat{z}_0$ by employing a control $u\geq\widehat{u}$ ($\widehat{z}_0$ and $\widehat{u}$ are the same given above).

# Minimal time for the constrained controllability of the fractional heat equation.

# 1: define the parameters

param Nx = 20;               # number of spatial discretization points

param Nt = 100;              # number of time discretization points

param y0 {1..Nx};            # initial condition

param y1 = 0;                # target

param dx = 2/Nx;             # Space step

param C = 1;                 # Bound on the controls

param A {1..Nx,1..Nx};       # Stiffness or rigidity matrix

param B {1..Nx,1..Nx};       # Control matrix

param M {1..Nx,1..Nx};       # Mass matrix  

# 2: define the variables

var y {j in 0..Nt, i in 1..Nx};       # State
var u {j in 0..Nt, i in 1..Nx}&amp;gt;=-C;   # Control
var T &amp;gt;=0;                            # Time horizon
var dt = T/Nt;                        # Time step

# 3: define the data

data;

# Initial datum

param y0: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 :=
1 -0.000000 -0.905270 -1.785847 -2.617711 -3.378170 -4.046482 -4.604416 -5.036753 -5.331701 -5.481215 -5.481215 -5.331701 -5.036753 -4.604416 -4.046482 -3.378170 -2.617711 -1.785847 -0.905270 -0.000000;

# Stiffness or rigidity matrix A

param A: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 :=
1 -5.551728 2.242487 0.359689 0.077115 0.033148 0.017829 0.010871 0.007193 0.005044 0.003694 0.002798 0.002178 0.001733 0.001405 0.001158 0.000966 0.000816 0.000697 0.000600 0.000521
...
20 0.000521 0.000600 0.000697 0.000816 0.000966 0.001158 0.001405 0.001733 0.002178 0.002798 0.003694 0.005044 0.007193 0.010871 0.017829 0.033148 0.077115 0.359689 2.242487 -5.551728;


# Control matrix B

param B: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 :=
1 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
...
20 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000;


# Mass matrix M

param M: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 :=
1 0.070175 0.017544 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
...
20 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.017544 0.070175;


# 4: define the cost functional to minimize

minimize cost: T;

# 5: define the constraints

# 5.a: dynamics y' = Ay + Bu, implemented through an Explicit Euler method.

subject to y_dyn {j in 1..Nt, i in 2..Nx-1}:
sum {l in 1..Nx} M[i,l]*y[j,l] = sum {l in 1..Nx}M[i,l]*y[j-1,l] + dt*sum {l in 1..Nx}(A[i,l]*y[j-1,l] + B[i,l]*u[j-1,l]);

# 5.b: homogeneous Dirichlet boundary conditions in -1 and 1.

subject to left_boundary  {j in 0..Nt}: y[j,1] = 0;
subject to right_boundary {j in 0..Nt}: y[j,Nx] = 0;

# 5.c: initial condition.

subject to y_init {i in 1..Nx}: y[0,i] = y0[i];

# 5.d: target.

subject to y_end1 {i in 1..Nx}: y[Nt,i] = y1;

# 6: solve the problem with IpOpt

option solver ipopt;
option ipopt_options &quot;max_iter=100000 linear_solver=mumps hessian_approximation=exact halt_on_ampl_error yes&quot;;
solve;

# 7: print the results.

printf: &quot;T  = %24.16e\n&quot;, T;
printf: &quot;Nx = %d\n&quot;, Nx;
printf: &quot;Nt = %d\n&quot;, Nt;
printf {j in 0..Nt, i in 1..Nx}: &quot; %24.16e\n&quot;, y[j,i];
printf {j in 0..Nt, i in 1..Nx}: &quot; %24.16e\n&quot;, u[j,i];

end;


Once the minimization is concluded, we save the results in a file “data.txt” and we use Matlab to reshape the solution and the control so to obtain two $N_x\times(N_t+1)$ matrices for the plots.

This can be done through the following script:

close all
% Read the data from the external file data.txt

fid= fopen('data.txt','r');
C = fscanf(fid,'%f',Inf);
T = C(1);
Nx = C(2);
Nt = C(3);
y = C(4:(Nt+1)*Nx+3);
u = C((Nt+1)*Nx+4:end);
fclose(fid);

% Reshape the state y and the control u into two Nx times Nt+1 matrices
y = reshape(y,Nx,Nt+1);
u = reshape(u,Nx,Nt+1);


From the reshaped solution and control, we can generate the plots. For instance, the m-file plot_control.m is the one generating Figure 2 below.

The minimal time that we obtain from our minimization process is $T_{min}\simeq 0,2101$. Our simulations show that in this time horizon the fractional heat equation \ref{frac_heat} is controllable from the initial datum $z_0$ to the desired trajectory $\widehat{z}(\cdot,T)$ by maintaining the positivity of the solution (as it is expected since the initial datum is positive in $(-1,1)$, see Figure 1).


Figure 1. Controllability of the fractional heat equation \ref{frac_heat}in the minimal time $T_{min}=0.2101$.

Moreover, as it is observed also in Figure 2, the control has an impulsional behavior.


Figure 2. Minimal-time control. In the $(t,x)$ plane in blue the time $t$ varies from $t = 0$ (left) to $t = T_{min}$ (right).

This behavior of the control is not surprising. Indeed, as it was already observed in our previous works [3,4], the minimal-time controls are expected to be atomic measures, in particular linear combinations of Dirac deltas. Our simulations are thus consistent with the aforementioned papers.

The impulsional behavior of the control is then lost when extending the time horizon beyond $T_{min}$. This is shown in Figure 3, in which we display the behavior of the control steering the solution of the fractional heat equation \ref{frac_heat} from the initial datum $z_0$ to the target $\widehat{z}(\cdot,T)$ in the time horizon $T=0.4$.


Figure 3. Behavior of the control in time $T = 0.4$. The white lines delimit the control region $\omega = (-0.3, 0.8)$. The regions in which the control is active are marked in yellow. The atomic nature is lost.

This control has been computed by employing once again IpOpt for solving the following minimization problem:



subject to



As we can observe, the action of this control is now more distributed in $\omega$. Neverthelss, in accordance with our theoretical results, the equation is still controllable in the prescribed time horizon (see Figure 4)


Figure 4. Controllability of the fractional heat equation \ref{frac_heat}in time $T = 0.4$. The atomic behavior of the control is lost.

Finally, we consider the case of a time horizon $T&amp;lt;T_{min}$, in which constrained controllability is expected to fail. This time, we employ a classical conjugate gradient method implemented in the DyCon Computational Toolbox for solving the above optimization problem.

As before, we apply a FE method for the space discretization of the fractional Laplacian on a uniform space-grid with $N_x=20$ points and we use an explicit Euler scheme for the time integration on a time-grid with $N_t=100$ points. Furthermore, we choose a time horizon $T=0.15$, which is below the minimal controllability time $T_{min}$.

Our simulation then show that the solution of \ref{frac_heat} fails to be controlled. In fact, Figure 5 shows that the state computed by employing the tools of the DyCon Computational Toolbox does not totally match the desired target in the time horizon prescribed.


Figure 5. Evolution in the time interval $(0,0.15)$ of the solution of \ref{frac_heat} with $s = 0.8$ under the positivity control constraint $u\geq 0$. The equation is not controllable.

References

[1] U. Biccari and V. Hernández-Santamarı́a, Controllability of a one-dimensional fractional heat equation: theoretical and
numerical aspects. IMA J. Math. Control. Inf, to appear, 2018.

[2] U. Biccari, M. Warma and E. Zuazua, Controllability of the one-dimensional fractional heat equation under positivity constraints. Submitted.

[3] J. Loheac, E. Trélat, and E. Zuazua, Minimal controllability time for the heat equation under unilateral state or control
constraints. Math. Models Methods Appl. Sci., Vol. 27, No. 9 (2017), pp 1587-1644.

[4] D. Pighin and E. Zuazua, Controllability under positivity constraints of semilinear heat equations. Math. Control. Relat.
Fields, Vol. 8, No. 3,4 (2018), pp. 935-964.
</description>
        <pubDate>Fri, 31 May 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp03/WP03-P0022</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp03/WP03-P0022</guid>
        
        
        <category>tutorial</category>
        
        <category>WP03</category>
        
      </item>
    
      <item>
        <title>Optimal strategies for guidance-by-repulsion model with IpOpt and AMPL</title>
        <description>A sample result



This video describes an optimal control steering red dots(evaders) to the position $(4,4)$, which is calculated by IpOpt with AMPL. See the post explaining IpOpt and AMPL for detailed description.

The guidance-by-repulsion model

Let $u_{ei}$ and $u_{dj}$ be the positions of the evaders $(i=1,\ldots,N)$ and drivers $(j=1,\ldots,M)$, respectively, in ${\mathbb R}^2$. We consider the following ODE system:







where $\kappa_j(t)$ is the control interface and the interaction functions are given by



In the dynamics, the evaders always get forced from all of the drivers, while the drivers wants to keep a stable distance ($f_d(1)-f_e(1)=0$). By choosing proper $\kappa_j(t)$, we wants to steer the evaders into a predetermined region.

The objective of the control is given by the cost function with the fixed final time $t_f&amp;gt;0$,



where $\delta_1$ is a regularization coefficient, $0.1$ in this post.

AMPL code for solving the optimal control problem

Let us explain an AMPL code step by step. First, we need to set relative parameters.
# GBR_fixedtime.mod

# This file solves the Guidance-by-repulsion model with 2 drivers and 16 evaders to 

# the target point [4;4] in a fixed final time T=10.

# Define the parameters of the problem

param pi      = 3.141592653589793238462643; 

param Nt      = 100;      # number of discretized points in time

param M_sqrt  = 4;        # sqrt of Number of evaders

param M_e     = M_sqrt^2; # Number of evaders

param M_d     = 2;        # Number of drivers

param T       = 10;

param M_kappa = 5;        # Bound on the control

# Target point

param uf1 = 4;
param uf2 = 4;


For the initial condition, we use uniform distribution of evaders in a square $[-1,1]\times[-1,1]$, and the drivers are in a circle with radius $5$.
# Initial values

param ue_zero {k in 1..M_e, j in 1..2};
for {k1 in 1..M_sqrt, k2 in 1..M_sqrt, j in 1..2} {
	let ue_zero[M_sqrt*(k1-1)+k2,1] := ((k1-1)/(M_sqrt-1))*2-1;
	let ue_zero[M_sqrt*(k1-1)+k2,2] := ((k2-1)/(M_sqrt-1))*2-1;
}
param ud_zero {l in 1..M_d, j in 1..2};
for {l in 1..M_d, j in 1..2} {
	let ud_zero[l,1] := 5*cos(2*pi/M_d*(l-1));
	let ud_zero[l,2] := 5*sin(2*pi/M_d*(l-1));
}

# State variables

var ue {k in 1..M_e, i in 0..Nt, j in 1..2};
var ve {k in 1..M_e, i in 0..Nt, j in 1..2};
var ud {l in 1..M_d, i in 0..Nt, j in 1..2};
var vd {l in 1..M_d, i in 0..Nt, j in 1..2};
var uec {i in 0..Nt, j in 1..2} = 1/M_e*(sum {k in 1..M_e} (ue[k,i,j]));

# initialize

subject to ue_init {k in 1..M_e, j in 1..2} : ue[k,0,j] = ue_zero[k,j];
subject to ud_init {l in 1..M_d, j in 1..2} : ud[l,0,j] = ud_zero[l,j];
subject to vd_init {k in 1..M_e, j in 1..2} : ve[k,0,j] = 0;
subject to ve_init {l in 1..M_d, j in 1..2} : vd[l,0,j] = 0;  
let {k in 1..M_e, i in 0..Nt, j in 1..2} ue[k,i,j] := ue_zero[k,j];
let {l in 1..M_d, i in 0..Nt, j in 1..2} ud[l,i,j] := ud_zero[l,j];
let {k in 1..M_e, i in 0..Nt, j in 1..2} ve[k,i,j] := 0;
let {l in 1..M_d, i in 0..Nt, j in 1..2} vd[l,i,j] := 0;   

For the initial guess, we also put the initial data for the whole timeline. If we don’t specify this, then the default values are zero, which can make redundant errors or iterations.

Now, we define the controls and cost.
# The control function

var kappa {l in 1..M_d, i in 0..Nt}, default 2.8;  
subject to kappa_bounds {l in 1..M_d, i in 0..Nt} : -M_kappa &amp;lt;= kappa[l,i] &amp;lt;= M_kappa;
# initial guess on control

let {l in 1..M_d, i in 0..Nt} kappa[l,i] := 2.8;

# The cost function

minimize cost: 
 1/M_e*(sum {k in 1..M_e} ((ue[k,Nt+1,1]-uf1)^2+(ue[k,Nt+1,2]-uf2)^2)) + 0.1/M_d/(Nt+1)*( sum {l in 1..M_d, i in 0..Nt} (( kappa[l,i]^2)) );

The dynamics need to be described in the form of restriction condition of states and control variables. In order to avoid divide-by-zero, we additionally put the restriction on the distance. Since our equation has unbounded interaction kernels, it is convenient to use Euler’s forward method. Backward or central method may result unexpected high velocities by closing to the infinite values.
# Restriction on distance

subject to distance {k in 1..M_e, l in 1..M_d, i in 0..Nt} :
		(ue[k,i,1]-ud[l,i,1])^2+(ue[k,i,2]-ud[l,i,2])^2 &amp;gt;= 0.001;
# Dynamics

subject to ue_dyn {k in 1..M_e, i in 0..Nt-1, j in 1..2} :
		(ue[k,i+1,j]-ue[k,i,j])*Nt/T = ve[k,i,j];
subject to ud_dyn {l in 1..M_d, i in 0..Nt-1, j in 1..2} :
		(ud[l,i+1,j]-ud[l,i,j])*Nt/T = vd[l,i,j];
subject to ve_dyn {k in 1..M_e, i in 0..Nt-1, j in 1..2} :
		(ve[k,i+1,j]-ve[k,i,j])*Nt/T = sum {l in 1..M_d} ( -2/((ud[l,i,1] - ue[k,i,1])^2+(ud[l,i,2] - ue[k,i,2])^2)*(ud[l,i,j] - ue[k,i,j]) )  - 2*ve[k,i,j];
subject to vd1_dyn {l in 1..M_d, i in 0..Nt-1} :
		(vd[l,i+1,1]-vd[l,i,1])*Nt/T = (-5.5/((ud[l,i,1] - uec[i,1])^2+(ud[l,i,2] - uec[i,2])^2)+10/(((ud[l,i,1] - uec[i,1])^2+(ud[l,i,2] - uec[i,2])^2)^2) -2)*(ud[l,i,1] - uec[i,1]) + kappa[l,i] * (-(ud[l,i,2]-uec[i,2])) - 2*vd[l,i,1];
subject to vd2_dyn {l in 1..M_d, i in 0..Nt-1} :
		(vd[l,i+1,2]-vd[l,i,2])*Nt/T = (-5.5/((ud[l,i,1] - uec[i,1])^2+(ud[l,i,2] - uec[i,2])^2)+10/(((ud[l,i,1] - uec[i,1])^2+(ud[l,i,2] - uec[i,2])^2)^2) -2)*(ud[l,i,2] - uec[i,2]) + kappa[l,i] * ((ud[l,i,1]-uec[i,1])) - 2*vd[l,i,2];

The next step is to solve and get the output. It is convenient to describe the parameters of the problem to visualize later.
# Solve with IpOpt

option solver ipopt;
option ipopt_options &quot;max_iter=20000 linear_solver=mumps hessian_approximation=limited-memory halt_on_ampl_error yes&quot;;
solve;
# Display solution

printf : &quot;%24.16e\n&quot;, T;
printf : &quot;%d\n&quot;, Nt;
printf : &quot;%d\n&quot;, M_d;
printf : &quot;%d\n&quot;, M_e;
printf : &quot;%24.16e\n&quot;, uf1;
printf : &quot;%24.16e\n&quot;, uf2;

printf {l in 1..M_d, i in 0..Nt} : &quot;%24.16e\n&quot;, kappa[l,i];
printf {k in 1..M_e, i in 0..Nt, j in 1..2} : &quot;%24.16e\n&quot;, ue[k,i,j];
printf {l in 1..M_d, i in 0..Nt, j in 1..2} : &quot;%24.16e\n&quot;, ud[l,i,j];
printf {k in 1..M_e, i in 0..Nt, j in 1..2} : &quot;%24.16e\n&quot;, ve[k,i,j];
printf {l in 1..M_d, i in 0..Nt, j in 1..2} : &quot;%24.16e\n&quot;, vd[l,i,j];
printf : &quot;End. \n&quot;;
end;



Finally, we used MATLAB to show the trajectories. After copying the result to a file ‘output.txt’, we read it with the following code.

fid= fopen('output.txt','r');            % Open out.txt
temp = fscanf(fid,'%f');
M_d = 2; M_e = 9; index1 = 1;
T = temp(index1); index1 = index1+1;
Nt = temp(index1); index1 = index1+1;
M_d = temp(index1); index1 = index1+1;
M_e = temp(index1); index1 = index1+1;
uf1 = temp(index1); index1 = index1+1;
uf2 = temp(index1); index1 = index1+1; index2 = index1+M_d*(Nt+1)-1;
kappa = temp(index1:index2); kappa = reshape(kappa, [Nt+1 M_d]); index1 = index2+1; index2 = index1+2*(Nt+1)*M_e-1;
ue = temp(index1:index2); ue = reshape(ue, [2 Nt+1 M_e]); index1 = index2+1; index2 = index1+2*(Nt+1)*M_d-1;
ud = temp(index1:index2); ud = reshape(ud, [2 Nt+1 M_d]); index1 = index2+1; index2 = index1+2*(Nt+1)*M_e-1;
ve = temp(index1:index2); ve = reshape(ve, [2 Nt+1 M_e]); index1 = index2+1; index2 = index1+2*(Nt+1)*M_d-1;
vd = temp(index1:index2); vd = reshape(vd, [2 Nt+1 M_d]); 
index2 == length(temp)      % Check the file is properly read.
tline = linspace(0,T,Nt+1);

fclose(fid);


%% Cost calculation

u_f = [uf1;uf2];
Final_Time = tline(end);
Final_Position = reshape(ue(:,end,:),[2 M_e]);
Final_cost = sum( (Final_Position(1,:) - u_f(1)).^2+(Final_Position(2,:) - u_f(2)).^2 )/M_e;
Running_cost = 0.001*trapz(tline,mean(kappa(:,1:M_d).^2,2))/M_d;

%% Visualize the trajectories

f1 = figure('position', [0, 0, 1000, 400]);
subplot(1,2,1)
hold on
for k = 1:M_d
	plot(ud(1,:,k),ud(2,:,k),'b--','LineWidth',1.3);
end
for l = 1:M_e
	plot(ue(1,:,l),ue(2,:,l),'r-','LineWidth',1.5);
end
xlabel('abscissa')
ylabel('ordinate')
title(['Position error = ', num2str(Final_cost)])
grid on


Then, one can get the following trajectories and optimal control solution.



subplot(1,2,2)
plot(tline,kappa','LineWidth',1.3);
xlabel('Time')
ylabel('Control \kappa(t)')
title(['Total Time = ',num2str(tline(end)),' and running cost = ',num2str(Running_cost)])
grid on



</description>
        <pubDate>Mon, 27 May 2019 00:00:00 +0200</pubDate>
        <link>https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0026</link>
        <guid isPermaLink="true">https://deustotech.github.io/DyCon-Blog/tutorial/wp99/WP99-P0026</guid>
        
        
        <category>tutorial</category>
        
        <category>WP99</category>
        
      </item>
    
  </channel>
</rss>
